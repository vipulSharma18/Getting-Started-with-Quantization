
TREE_GUARD_MANAGER:
+- RootGuardManager
| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:520 in init_ambient_guards
| +- GLOBAL_STATE: ___check_global_state()
| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
| +- GuardManager: source=L['self'], accessed_by=FrameLocalsGuardAccessor(key='self', framelocals_idx=0)
| | +- TYPE_MATCH: ___check_type_id(L['self'], 924965632)                      
| | +- GuardManager: source=L['self'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | +- GuardManager: source=L['self']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules, 21447360)              
| | | | +- GuardManager: source=L['self']._modules['model'], accessed_by=DictGetItemGuardAccessor('model')
| | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model'], 924963856)    
| | | | | +- GuardManager: source=L['self']._modules['model'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model'].__dict__)
| | | | | | +- GuardManager: source=L['self']._modules['model'].config, accessed_by=DictGetItemGuardAccessor('config')
| | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model'].config, 924954896)
| | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn'].config
| | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn'].config
| | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn'].config
| | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn'].config
| | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn'].config
| | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn'].config
| | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn'].config
| | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn'].config
| | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn'].config
| | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn'].config
| | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn'].config
| | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn'].config
| | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn'].config
| | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn'].config
| | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn'].config
| | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn'].config
| | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn'].config
| | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn'].config
| | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn'].config
| | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn'].config
| | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn'].config
| | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn'].config
| | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn'].config
| | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn'].config
| | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn'].config
| | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn'].config
| | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn'].config
| | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn'].config
| | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn'].config
| | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn'].config
| | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn'].config
| | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn'].config
| | | | | | | +- GuardManager: source=object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'), accessed_by=GenericGetAttrGuardAccessor(attribute_map)
| | | | | | | | +- TYPE_MATCH: ___check_type_id(object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'), 21447360)
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('num_hidden_layers', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('_attn_implementation', object.__getattribute__(L['self']._modules['model'].config, 'attribute_map'))
| | | | | | | +- GuardManager: source=L['self']._modules['model'].config.__getattribute__, accessed_by=GetAttrGuardAccessor(__getattribute__)
| | | | | | | | +- GuardManager: source=L['self']._modules['model'].config.__getattribute__.__closure__, accessed_by=GetAttrGuardAccessor(__closure__)
| | | | | | | | | +- GuardManager: source=L['self']._modules['model'].config.__getattribute__.__closure__[0], accessed_by=TupleGetItemGuardAccessor(0)
| | | | | | | | | | +- GuardManager: source=L['self']._modules['model'].config.__getattribute__.__closure__[0].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents)
| | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model'].config.__getattribute__.__closure__[0].cell_contents, 829718800)
| | | | | | | +- GuardManager: source=object.__getattribute__(L['self']._modules['model'].config, 'num_hidden_layers'), accessed_by=GenericGetAttrGuardAccessor(num_hidden_layers)
| | | | | | | | +- TYPE_MATCH: ___check_type_id(object.__getattribute__(L['self']._modules['model'].config, 'num_hidden_layers'), 21441248)
| | | | | | | +- GuardManager: source=object.__getattribute__(L['self']._modules['model'].config, '_attn_implementation'), accessed_by=GenericGetAttrGuardAccessor(_attn_implementation)
| | | | | | | | +- EQUALS_MATCH: object.__getattribute__(L['self']._modules['model'].config, '_attn_implementation') == 'sdpa'
| | | | | | +- GuardManager: source=L['self']._modules['model']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules, 21447360)
| | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['norm'], accessed_by=DictGetItemGuardAccessor('norm')
| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['norm'], 865890160)
| | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['norm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['norm'].__dict__)
| | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['norm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['norm'].offset == 0.0  
| | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['norm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['norm'].in_place, 21370792)
| | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['norm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['norm'].row_mode, 21458960)
| | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['norm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['norm']._parameters, 21447360)
| | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['norm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['norm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['norm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['norm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['norm'].casting_mode == 'llama'
| | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['norm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['norm'].variance_epsilon == 1e-05
| | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers'], accessed_by=DictGetItemGuardAccessor('layers')
| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers'], 805087424)
| | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers'].__class__, accessed_by=GetAttrGuardAccessor(__class__)
| | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers'].__class__.call_super_init, accessed_by=GetAttrGuardAccessor(call_super_init)
| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers'].__class__.call_super_init, 21370824)
| | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | +- DictGuardManager: source=L['self']._modules['model']._modules['layers']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | +- KeyValueManager pair at index=0
| | | | | | | | | | | +- KeyManager: GuardManager: source=list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[0]
| | | | | | | | | | | | +- EQUALS_MATCH: list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[0] == '0'
| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']
| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['0'], 866524544)
| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['0'].__dict__)
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['0']._modules, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp'], accessed_by=DictGetItemGuardAccessor('mlp')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp'], 866551056)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['act_fn'], accessed_by=DictGetItemGuardAccessor('act_fn')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['act_fn'], 805311888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['act_fn'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['act_fn'].inplace, accessed_by=DictGetItemGuardAccessor('inplace')
| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['act_fn'].inplace, 21370824)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['up_proj'], accessed_by=DictGetItemGuardAccessor('up_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['up_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['up_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['up_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['up_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['up_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['up_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['up_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['up_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['up_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['down_proj'], accessed_by=DictGetItemGuardAccessor('down_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['down_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['down_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['down_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['down_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['down_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['down_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['down_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['down_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['down_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 14336], stride=[14336, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['gate_proj'], accessed_by=DictGetItemGuardAccessor('gate_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['gate_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['gate_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['gate_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['gate_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['gate_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['gate_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['gate_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['gate_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._modules['gate_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['mlp']._parameters, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn'], accessed_by=DictGetItemGuardAccessor('self_attn')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn'], 866522768)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn'].scaling, accessed_by=DictGetItemGuardAccessor('scaling')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn'].scaling == 0.08838834764831845
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['k_proj'], accessed_by=DictGetItemGuardAccessor('k_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['k_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['k_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['k_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['k_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['k_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['k_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['k_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['k_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['k_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['o_proj'], accessed_by=DictGetItemGuardAccessor('o_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['o_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['o_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['o_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['o_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['o_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['o_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['o_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['o_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['o_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['q_proj'], accessed_by=DictGetItemGuardAccessor('q_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['q_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['q_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['q_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['q_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['q_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['q_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['q_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['q_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['q_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['v_proj'], accessed_by=DictGetItemGuardAccessor('v_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['v_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['v_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['v_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['v_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['v_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['v_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['v_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['v_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._modules['v_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn'].head_dim, accessed_by=DictGetItemGuardAccessor('head_dim')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn'].head_dim == 128
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn'].training, accessed_by=DictGetItemGuardAccessor('training')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn'].training, 21370824)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn'].layer_idx, accessed_by=DictGetItemGuardAccessor('layer_idx')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn'].layer_idx == 0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn']._parameters, 21447360)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn'].num_key_value_groups, accessed_by=DictGetItemGuardAccessor('num_key_value_groups')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn'].num_key_value_groups == 4
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn'].config, accessed_by=DictGetItemGuardAccessor('config')
| | | | | | | | | | | | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['0']._modules['self_attn'].config
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['input_layernorm'], accessed_by=DictGetItemGuardAccessor('input_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['input_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['input_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['0']._modules['input_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['input_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['0']._modules['input_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['input_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['input_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['input_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['input_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['input_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['input_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['input_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['0']._modules['input_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['input_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['input_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['0']._modules['input_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['input_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['0']._modules['input_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['post_attention_layernorm'], accessed_by=DictGetItemGuardAccessor('post_attention_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['post_attention_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['post_attention_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['0']._modules['post_attention_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['post_attention_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['0']._modules['post_attention_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['post_attention_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['post_attention_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['post_attention_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['post_attention_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['post_attention_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['0']._modules['post_attention_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['post_attention_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['0']._modules['post_attention_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['post_attention_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['post_attention_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['0']._modules['post_attention_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._modules['post_attention_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['0']._modules['post_attention_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['0']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['0']._parameters, 21447360)
| | | | | | | | | | +- KeyValueManager pair at index=1
| | | | | | | | | | | +- KeyManager: GuardManager: source=list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[1]
| | | | | | | | | | | | +- EQUALS_MATCH: list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[1] == '1'
| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']
| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['1'], 866524544)
| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['1'].__dict__)
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['1']._modules, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp'], accessed_by=DictGetItemGuardAccessor('mlp')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp'], 866551056)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['act_fn'], accessed_by=DictGetItemGuardAccessor('act_fn')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['act_fn'], 805311888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['act_fn'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['act_fn'].inplace, accessed_by=DictGetItemGuardAccessor('inplace')
| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['act_fn'].inplace, 21370824)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['up_proj'], accessed_by=DictGetItemGuardAccessor('up_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['up_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['up_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['up_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['up_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['up_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['up_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['up_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['up_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['up_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['down_proj'], accessed_by=DictGetItemGuardAccessor('down_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['down_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['down_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['down_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['down_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['down_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['down_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['down_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['down_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['down_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 14336], stride=[14336, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['gate_proj'], accessed_by=DictGetItemGuardAccessor('gate_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['gate_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['gate_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['gate_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['gate_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['gate_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['gate_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['gate_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['gate_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._modules['gate_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['mlp']._parameters, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn'], accessed_by=DictGetItemGuardAccessor('self_attn')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn'], 866522768)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn'].scaling, accessed_by=DictGetItemGuardAccessor('scaling')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn'].scaling == 0.08838834764831845
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['k_proj'], accessed_by=DictGetItemGuardAccessor('k_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['k_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['k_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['k_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['k_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['k_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['k_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['k_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['k_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['k_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['o_proj'], accessed_by=DictGetItemGuardAccessor('o_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['o_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['o_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['o_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['o_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['o_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['o_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['o_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['o_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['o_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['q_proj'], accessed_by=DictGetItemGuardAccessor('q_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['q_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['q_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['q_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['q_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['q_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['q_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['q_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['q_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['q_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['v_proj'], accessed_by=DictGetItemGuardAccessor('v_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['v_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['v_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['v_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['v_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['v_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['v_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['v_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['v_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._modules['v_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn'].head_dim, accessed_by=DictGetItemGuardAccessor('head_dim')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn'].head_dim == 128
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn'].training, accessed_by=DictGetItemGuardAccessor('training')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn'].training, 21370824)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn'].layer_idx, accessed_by=DictGetItemGuardAccessor('layer_idx')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn'].layer_idx == 1
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn']._parameters, 21447360)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn'].num_key_value_groups, accessed_by=DictGetItemGuardAccessor('num_key_value_groups')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn'].num_key_value_groups == 4
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn'].config, accessed_by=DictGetItemGuardAccessor('config')
| | | | | | | | | | | | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['1']._modules['self_attn'].config
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['input_layernorm'], accessed_by=DictGetItemGuardAccessor('input_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['input_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['input_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['1']._modules['input_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['input_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['1']._modules['input_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['input_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['input_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['input_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['input_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['input_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['input_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['input_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['1']._modules['input_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['input_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['input_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['1']._modules['input_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['input_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['1']._modules['input_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['post_attention_layernorm'], accessed_by=DictGetItemGuardAccessor('post_attention_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['post_attention_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['post_attention_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['1']._modules['post_attention_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['post_attention_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['1']._modules['post_attention_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['post_attention_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['post_attention_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['post_attention_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['post_attention_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['post_attention_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['1']._modules['post_attention_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['post_attention_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['1']._modules['post_attention_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['post_attention_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['post_attention_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['1']._modules['post_attention_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._modules['post_attention_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['1']._modules['post_attention_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['1']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['1']._parameters, 21447360)
| | | | | | | | | | +- KeyValueManager pair at index=2
| | | | | | | | | | | +- KeyManager: GuardManager: source=list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[2]
| | | | | | | | | | | | +- EQUALS_MATCH: list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[2] == '2'
| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']
| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['2'], 866524544)
| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['2'].__dict__)
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['2']._modules, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp'], accessed_by=DictGetItemGuardAccessor('mlp')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp'], 866551056)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['act_fn'], accessed_by=DictGetItemGuardAccessor('act_fn')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['act_fn'], 805311888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['act_fn'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['act_fn'].inplace, accessed_by=DictGetItemGuardAccessor('inplace')
| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['act_fn'].inplace, 21370824)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['up_proj'], accessed_by=DictGetItemGuardAccessor('up_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['up_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['up_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['up_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['up_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['up_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['up_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['up_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['up_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['up_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['down_proj'], accessed_by=DictGetItemGuardAccessor('down_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['down_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['down_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['down_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['down_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['down_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['down_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['down_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['down_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['down_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 14336], stride=[14336, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['gate_proj'], accessed_by=DictGetItemGuardAccessor('gate_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['gate_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['gate_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['gate_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['gate_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['gate_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['gate_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['gate_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['gate_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._modules['gate_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['mlp']._parameters, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn'], accessed_by=DictGetItemGuardAccessor('self_attn')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn'], 866522768)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn'].scaling, accessed_by=DictGetItemGuardAccessor('scaling')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn'].scaling == 0.08838834764831845
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['k_proj'], accessed_by=DictGetItemGuardAccessor('k_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['k_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['k_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['k_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['k_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['k_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['k_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['k_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['k_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['k_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['o_proj'], accessed_by=DictGetItemGuardAccessor('o_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['o_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['o_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['o_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['o_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['o_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['o_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['o_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['o_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['o_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['q_proj'], accessed_by=DictGetItemGuardAccessor('q_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['q_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['q_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['q_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['q_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['q_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['q_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['q_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['q_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['q_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['v_proj'], accessed_by=DictGetItemGuardAccessor('v_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['v_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['v_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['v_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['v_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['v_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['v_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['v_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['v_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._modules['v_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn'].head_dim, accessed_by=DictGetItemGuardAccessor('head_dim')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn'].head_dim == 128
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn'].training, accessed_by=DictGetItemGuardAccessor('training')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn'].training, 21370824)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn'].layer_idx, accessed_by=DictGetItemGuardAccessor('layer_idx')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn'].layer_idx == 2
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn']._parameters, 21447360)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn'].num_key_value_groups, accessed_by=DictGetItemGuardAccessor('num_key_value_groups')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn'].num_key_value_groups == 4
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn'].config, accessed_by=DictGetItemGuardAccessor('config')
| | | | | | | | | | | | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['2']._modules['self_attn'].config
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['input_layernorm'], accessed_by=DictGetItemGuardAccessor('input_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['input_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['input_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['2']._modules['input_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['input_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['2']._modules['input_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['input_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['input_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['input_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['input_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['input_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['input_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['input_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['2']._modules['input_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['input_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['input_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['2']._modules['input_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['input_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['2']._modules['input_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['post_attention_layernorm'], accessed_by=DictGetItemGuardAccessor('post_attention_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['post_attention_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['post_attention_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['2']._modules['post_attention_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['post_attention_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['2']._modules['post_attention_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['post_attention_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['post_attention_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['post_attention_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['post_attention_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['post_attention_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['2']._modules['post_attention_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['post_attention_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['2']._modules['post_attention_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['post_attention_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['post_attention_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['2']._modules['post_attention_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._modules['post_attention_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['2']._modules['post_attention_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['2']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['2']._parameters, 21447360)
| | | | | | | | | | +- KeyValueManager pair at index=3
| | | | | | | | | | | +- KeyManager: GuardManager: source=list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[3]
| | | | | | | | | | | | +- EQUALS_MATCH: list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[3] == '3'
| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']
| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['3'], 866524544)
| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['3'].__dict__)
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['3']._modules, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp'], accessed_by=DictGetItemGuardAccessor('mlp')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp'], 866551056)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['act_fn'], accessed_by=DictGetItemGuardAccessor('act_fn')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['act_fn'], 805311888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['act_fn'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['act_fn'].inplace, accessed_by=DictGetItemGuardAccessor('inplace')
| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['act_fn'].inplace, 21370824)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['up_proj'], accessed_by=DictGetItemGuardAccessor('up_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['up_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['up_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['up_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['up_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['up_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['up_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['up_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['up_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['up_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['down_proj'], accessed_by=DictGetItemGuardAccessor('down_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['down_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['down_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['down_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['down_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['down_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['down_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['down_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['down_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['down_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 14336], stride=[14336, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['gate_proj'], accessed_by=DictGetItemGuardAccessor('gate_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['gate_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['gate_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['gate_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['gate_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['gate_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['gate_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['gate_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['gate_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._modules['gate_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['mlp']._parameters, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn'], accessed_by=DictGetItemGuardAccessor('self_attn')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn'], 866522768)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn'].scaling, accessed_by=DictGetItemGuardAccessor('scaling')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn'].scaling == 0.08838834764831845
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['k_proj'], accessed_by=DictGetItemGuardAccessor('k_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['k_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['k_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['k_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['k_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['k_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['k_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['k_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['k_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['k_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['o_proj'], accessed_by=DictGetItemGuardAccessor('o_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['o_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['o_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['o_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['o_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['o_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['o_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['o_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['o_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['o_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['q_proj'], accessed_by=DictGetItemGuardAccessor('q_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['q_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['q_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['q_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['q_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['q_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['q_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['q_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['q_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['q_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['v_proj'], accessed_by=DictGetItemGuardAccessor('v_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['v_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['v_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['v_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['v_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['v_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['v_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['v_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['v_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._modules['v_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn'].head_dim, accessed_by=DictGetItemGuardAccessor('head_dim')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn'].head_dim == 128
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn'].training, accessed_by=DictGetItemGuardAccessor('training')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn'].training, 21370824)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn'].layer_idx, accessed_by=DictGetItemGuardAccessor('layer_idx')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn'].layer_idx == 3
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn']._parameters, 21447360)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn'].num_key_value_groups, accessed_by=DictGetItemGuardAccessor('num_key_value_groups')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn'].num_key_value_groups == 4
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn'].config, accessed_by=DictGetItemGuardAccessor('config')
| | | | | | | | | | | | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['3']._modules['self_attn'].config
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['input_layernorm'], accessed_by=DictGetItemGuardAccessor('input_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['input_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['input_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['3']._modules['input_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['input_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['3']._modules['input_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['input_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['input_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['input_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['input_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['input_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['input_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['input_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['3']._modules['input_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['input_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['input_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['3']._modules['input_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['input_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['3']._modules['input_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['post_attention_layernorm'], accessed_by=DictGetItemGuardAccessor('post_attention_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['post_attention_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['post_attention_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['3']._modules['post_attention_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['post_attention_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['3']._modules['post_attention_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['post_attention_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['post_attention_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['post_attention_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['post_attention_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['post_attention_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['3']._modules['post_attention_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['post_attention_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['3']._modules['post_attention_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['post_attention_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['post_attention_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['3']._modules['post_attention_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._modules['post_attention_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['3']._modules['post_attention_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['3']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['3']._parameters, 21447360)
| | | | | | | | | | +- KeyValueManager pair at index=4
| | | | | | | | | | | +- KeyManager: GuardManager: source=list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[4]
| | | | | | | | | | | | +- EQUALS_MATCH: list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[4] == '4'
| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']
| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['4'], 866524544)
| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['4'].__dict__)
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['4']._modules, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp'], accessed_by=DictGetItemGuardAccessor('mlp')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp'], 866551056)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['act_fn'], accessed_by=DictGetItemGuardAccessor('act_fn')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['act_fn'], 805311888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['act_fn'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['act_fn'].inplace, accessed_by=DictGetItemGuardAccessor('inplace')
| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['act_fn'].inplace, 21370824)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['up_proj'], accessed_by=DictGetItemGuardAccessor('up_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['up_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['up_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['up_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['up_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['up_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['up_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['up_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['up_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['up_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['down_proj'], accessed_by=DictGetItemGuardAccessor('down_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['down_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['down_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['down_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['down_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['down_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['down_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['down_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['down_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['down_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 14336], stride=[14336, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['gate_proj'], accessed_by=DictGetItemGuardAccessor('gate_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['gate_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['gate_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['gate_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['gate_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['gate_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['gate_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['gate_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['gate_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._modules['gate_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['mlp']._parameters, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn'], accessed_by=DictGetItemGuardAccessor('self_attn')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn'], 866522768)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn'].scaling, accessed_by=DictGetItemGuardAccessor('scaling')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn'].scaling == 0.08838834764831845
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['k_proj'], accessed_by=DictGetItemGuardAccessor('k_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['k_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['k_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['k_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['k_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['k_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['k_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['k_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['k_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['k_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['o_proj'], accessed_by=DictGetItemGuardAccessor('o_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['o_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['o_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['o_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['o_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['o_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['o_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['o_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['o_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['o_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['q_proj'], accessed_by=DictGetItemGuardAccessor('q_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['q_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['q_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['q_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['q_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['q_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['q_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['q_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['q_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['q_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['v_proj'], accessed_by=DictGetItemGuardAccessor('v_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['v_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['v_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['v_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['v_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['v_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['v_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['v_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['v_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._modules['v_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn'].head_dim, accessed_by=DictGetItemGuardAccessor('head_dim')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn'].head_dim == 128
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn'].training, accessed_by=DictGetItemGuardAccessor('training')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn'].training, 21370824)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn'].layer_idx, accessed_by=DictGetItemGuardAccessor('layer_idx')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn'].layer_idx == 4
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn']._parameters, 21447360)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn'].num_key_value_groups, accessed_by=DictGetItemGuardAccessor('num_key_value_groups')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn'].num_key_value_groups == 4
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn'].config, accessed_by=DictGetItemGuardAccessor('config')
| | | | | | | | | | | | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['4']._modules['self_attn'].config
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['input_layernorm'], accessed_by=DictGetItemGuardAccessor('input_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['input_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['input_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['4']._modules['input_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['input_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['4']._modules['input_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['input_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['input_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['input_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['input_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['input_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['input_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['input_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['4']._modules['input_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['input_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['input_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['4']._modules['input_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['input_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['4']._modules['input_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['post_attention_layernorm'], accessed_by=DictGetItemGuardAccessor('post_attention_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['post_attention_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['post_attention_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['4']._modules['post_attention_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['post_attention_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['4']._modules['post_attention_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['post_attention_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['post_attention_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['post_attention_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['post_attention_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['post_attention_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['4']._modules['post_attention_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['post_attention_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['4']._modules['post_attention_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['post_attention_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['post_attention_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['4']._modules['post_attention_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._modules['post_attention_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['4']._modules['post_attention_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['4']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['4']._parameters, 21447360)
| | | | | | | | | | +- KeyValueManager pair at index=5
| | | | | | | | | | | +- KeyManager: GuardManager: source=list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[5]
| | | | | | | | | | | | +- EQUALS_MATCH: list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[5] == '5'
| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']
| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['5'], 866524544)
| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['5'].__dict__)
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['5']._modules, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp'], accessed_by=DictGetItemGuardAccessor('mlp')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp'], 866551056)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['act_fn'], accessed_by=DictGetItemGuardAccessor('act_fn')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['act_fn'], 805311888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['act_fn'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['act_fn'].inplace, accessed_by=DictGetItemGuardAccessor('inplace')
| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['act_fn'].inplace, 21370824)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['up_proj'], accessed_by=DictGetItemGuardAccessor('up_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['up_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['up_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['up_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['up_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['up_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['up_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['up_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['up_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['up_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['down_proj'], accessed_by=DictGetItemGuardAccessor('down_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['down_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['down_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['down_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['down_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['down_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['down_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['down_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['down_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['down_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 14336], stride=[14336, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['gate_proj'], accessed_by=DictGetItemGuardAccessor('gate_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['gate_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['gate_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['gate_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['gate_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['gate_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['gate_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['gate_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['gate_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._modules['gate_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['mlp']._parameters, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn'], accessed_by=DictGetItemGuardAccessor('self_attn')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn'], 866522768)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn'].scaling, accessed_by=DictGetItemGuardAccessor('scaling')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn'].scaling == 0.08838834764831845
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['k_proj'], accessed_by=DictGetItemGuardAccessor('k_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['k_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['k_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['k_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['k_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['k_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['k_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['k_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['k_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['k_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['o_proj'], accessed_by=DictGetItemGuardAccessor('o_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['o_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['o_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['o_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['o_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['o_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['o_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['o_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['o_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['o_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['q_proj'], accessed_by=DictGetItemGuardAccessor('q_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['q_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['q_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['q_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['q_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['q_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['q_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['q_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['q_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['q_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['v_proj'], accessed_by=DictGetItemGuardAccessor('v_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['v_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['v_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['v_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['v_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['v_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['v_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['v_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['v_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._modules['v_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn'].head_dim, accessed_by=DictGetItemGuardAccessor('head_dim')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn'].head_dim == 128
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn'].training, accessed_by=DictGetItemGuardAccessor('training')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn'].training, 21370824)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn'].layer_idx, accessed_by=DictGetItemGuardAccessor('layer_idx')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn'].layer_idx == 5
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn']._parameters, 21447360)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn'].num_key_value_groups, accessed_by=DictGetItemGuardAccessor('num_key_value_groups')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn'].num_key_value_groups == 4
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn'].config, accessed_by=DictGetItemGuardAccessor('config')
| | | | | | | | | | | | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['5']._modules['self_attn'].config
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['input_layernorm'], accessed_by=DictGetItemGuardAccessor('input_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['input_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['input_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['5']._modules['input_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['input_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['5']._modules['input_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['input_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['input_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['input_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['input_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['input_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['input_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['input_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['5']._modules['input_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['input_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['input_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['5']._modules['input_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['input_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['5']._modules['input_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['post_attention_layernorm'], accessed_by=DictGetItemGuardAccessor('post_attention_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['post_attention_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['post_attention_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['5']._modules['post_attention_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['post_attention_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['5']._modules['post_attention_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['post_attention_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['post_attention_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['post_attention_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['post_attention_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['post_attention_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['5']._modules['post_attention_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['post_attention_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['5']._modules['post_attention_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['post_attention_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['post_attention_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['5']._modules['post_attention_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._modules['post_attention_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['5']._modules['post_attention_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['5']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['5']._parameters, 21447360)
| | | | | | | | | | +- KeyValueManager pair at index=6
| | | | | | | | | | | +- KeyManager: GuardManager: source=list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[6]
| | | | | | | | | | | | +- EQUALS_MATCH: list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[6] == '6'
| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']
| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['6'], 866524544)
| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['6'].__dict__)
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['6']._modules, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp'], accessed_by=DictGetItemGuardAccessor('mlp')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp'], 866551056)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['act_fn'], accessed_by=DictGetItemGuardAccessor('act_fn')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['act_fn'], 805311888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['act_fn'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['act_fn'].inplace, accessed_by=DictGetItemGuardAccessor('inplace')
| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['act_fn'].inplace, 21370824)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['up_proj'], accessed_by=DictGetItemGuardAccessor('up_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['up_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['up_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['up_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['up_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['up_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['up_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['up_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['up_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['up_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['down_proj'], accessed_by=DictGetItemGuardAccessor('down_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['down_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['down_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['down_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['down_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['down_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['down_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['down_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['down_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['down_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 14336], stride=[14336, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['gate_proj'], accessed_by=DictGetItemGuardAccessor('gate_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['gate_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['gate_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['gate_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['gate_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['gate_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['gate_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['gate_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['gate_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._modules['gate_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['mlp']._parameters, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn'], accessed_by=DictGetItemGuardAccessor('self_attn')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn'], 866522768)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn'].scaling, accessed_by=DictGetItemGuardAccessor('scaling')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn'].scaling == 0.08838834764831845
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['k_proj'], accessed_by=DictGetItemGuardAccessor('k_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['k_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['k_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['k_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['k_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['k_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['k_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['k_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['k_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['k_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['o_proj'], accessed_by=DictGetItemGuardAccessor('o_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['o_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['o_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['o_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['o_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['o_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['o_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['o_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['o_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['o_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['q_proj'], accessed_by=DictGetItemGuardAccessor('q_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['q_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['q_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['q_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['q_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['q_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['q_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['q_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['q_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['q_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['v_proj'], accessed_by=DictGetItemGuardAccessor('v_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['v_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['v_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['v_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['v_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['v_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['v_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['v_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['v_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._modules['v_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn'].head_dim, accessed_by=DictGetItemGuardAccessor('head_dim')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn'].head_dim == 128
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn'].training, accessed_by=DictGetItemGuardAccessor('training')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn'].training, 21370824)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn'].layer_idx, accessed_by=DictGetItemGuardAccessor('layer_idx')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn'].layer_idx == 6
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn']._parameters, 21447360)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn'].num_key_value_groups, accessed_by=DictGetItemGuardAccessor('num_key_value_groups')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn'].num_key_value_groups == 4
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn'].config, accessed_by=DictGetItemGuardAccessor('config')
| | | | | | | | | | | | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['6']._modules['self_attn'].config
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['input_layernorm'], accessed_by=DictGetItemGuardAccessor('input_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['input_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['input_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['6']._modules['input_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['input_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['6']._modules['input_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['input_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['input_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['input_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['input_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['input_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['input_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['input_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['6']._modules['input_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['input_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['input_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['6']._modules['input_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['input_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['6']._modules['input_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['post_attention_layernorm'], accessed_by=DictGetItemGuardAccessor('post_attention_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['post_attention_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['post_attention_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['6']._modules['post_attention_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['post_attention_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['6']._modules['post_attention_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['post_attention_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['post_attention_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['post_attention_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['post_attention_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['post_attention_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['6']._modules['post_attention_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['post_attention_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['6']._modules['post_attention_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['post_attention_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['post_attention_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['6']._modules['post_attention_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._modules['post_attention_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['6']._modules['post_attention_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['6']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['6']._parameters, 21447360)
| | | | | | | | | | +- KeyValueManager pair at index=7
| | | | | | | | | | | +- KeyManager: GuardManager: source=list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[7]
| | | | | | | | | | | | +- EQUALS_MATCH: list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[7] == '7'
| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']
| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['7'], 866524544)
| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['7'].__dict__)
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['7']._modules, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp'], accessed_by=DictGetItemGuardAccessor('mlp')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp'], 866551056)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['act_fn'], accessed_by=DictGetItemGuardAccessor('act_fn')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['act_fn'], 805311888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['act_fn'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['act_fn'].inplace, accessed_by=DictGetItemGuardAccessor('inplace')
| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['act_fn'].inplace, 21370824)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['up_proj'], accessed_by=DictGetItemGuardAccessor('up_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['up_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['up_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['up_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['up_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['up_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['up_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['up_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['up_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['up_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['down_proj'], accessed_by=DictGetItemGuardAccessor('down_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['down_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['down_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['down_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['down_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['down_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['down_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['down_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['down_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['down_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 14336], stride=[14336, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['gate_proj'], accessed_by=DictGetItemGuardAccessor('gate_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['gate_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['gate_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['gate_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['gate_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['gate_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['gate_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['gate_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['gate_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._modules['gate_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['mlp']._parameters, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn'], accessed_by=DictGetItemGuardAccessor('self_attn')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn'], 866522768)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn'].scaling, accessed_by=DictGetItemGuardAccessor('scaling')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn'].scaling == 0.08838834764831845
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['k_proj'], accessed_by=DictGetItemGuardAccessor('k_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['k_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['k_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['k_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['k_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['k_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['k_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['k_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['k_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['k_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['o_proj'], accessed_by=DictGetItemGuardAccessor('o_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['o_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['o_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['o_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['o_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['o_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['o_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['o_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['o_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['o_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['q_proj'], accessed_by=DictGetItemGuardAccessor('q_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['q_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['q_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['q_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['q_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['q_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['q_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['q_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['q_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['q_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['v_proj'], accessed_by=DictGetItemGuardAccessor('v_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['v_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['v_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['v_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['v_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['v_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['v_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['v_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['v_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._modules['v_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn'].head_dim, accessed_by=DictGetItemGuardAccessor('head_dim')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn'].head_dim == 128
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn'].training, accessed_by=DictGetItemGuardAccessor('training')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn'].training, 21370824)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn'].layer_idx, accessed_by=DictGetItemGuardAccessor('layer_idx')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn'].layer_idx == 7
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn']._parameters, 21447360)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn'].num_key_value_groups, accessed_by=DictGetItemGuardAccessor('num_key_value_groups')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn'].num_key_value_groups == 4
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn'].config, accessed_by=DictGetItemGuardAccessor('config')
| | | | | | | | | | | | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['7']._modules['self_attn'].config
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['input_layernorm'], accessed_by=DictGetItemGuardAccessor('input_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['input_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['input_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['7']._modules['input_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['input_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['7']._modules['input_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['input_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['input_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['input_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['input_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['input_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['input_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['input_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['7']._modules['input_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['input_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['input_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['7']._modules['input_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['input_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['7']._modules['input_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['post_attention_layernorm'], accessed_by=DictGetItemGuardAccessor('post_attention_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['post_attention_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['post_attention_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['7']._modules['post_attention_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['post_attention_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['7']._modules['post_attention_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['post_attention_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['post_attention_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['post_attention_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['post_attention_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['post_attention_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['7']._modules['post_attention_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['post_attention_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['7']._modules['post_attention_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['post_attention_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['post_attention_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['7']._modules['post_attention_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._modules['post_attention_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['7']._modules['post_attention_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['7']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['7']._parameters, 21447360)
| | | | | | | | | | +- KeyValueManager pair at index=8
| | | | | | | | | | | +- KeyManager: GuardManager: source=list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[8]
| | | | | | | | | | | | +- EQUALS_MATCH: list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[8] == '8'
| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']
| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['8'], 866524544)
| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['8'].__dict__)
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['8']._modules, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp'], accessed_by=DictGetItemGuardAccessor('mlp')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp'], 866551056)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['act_fn'], accessed_by=DictGetItemGuardAccessor('act_fn')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['act_fn'], 805311888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['act_fn'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['act_fn'].inplace, accessed_by=DictGetItemGuardAccessor('inplace')
| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['act_fn'].inplace, 21370824)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['up_proj'], accessed_by=DictGetItemGuardAccessor('up_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['up_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['up_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['up_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['up_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['up_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['up_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['up_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['up_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['up_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['down_proj'], accessed_by=DictGetItemGuardAccessor('down_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['down_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['down_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['down_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['down_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['down_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['down_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['down_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['down_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['down_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 14336], stride=[14336, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['gate_proj'], accessed_by=DictGetItemGuardAccessor('gate_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['gate_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['gate_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['gate_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['gate_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['gate_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['gate_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['gate_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['gate_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._modules['gate_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['mlp']._parameters, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn'], accessed_by=DictGetItemGuardAccessor('self_attn')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn'], 866522768)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn'].scaling, accessed_by=DictGetItemGuardAccessor('scaling')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn'].scaling == 0.08838834764831845
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['k_proj'], accessed_by=DictGetItemGuardAccessor('k_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['k_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['k_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['k_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['k_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['k_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['k_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['k_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['k_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['k_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['o_proj'], accessed_by=DictGetItemGuardAccessor('o_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['o_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['o_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['o_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['o_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['o_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['o_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['o_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['o_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['o_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['q_proj'], accessed_by=DictGetItemGuardAccessor('q_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['q_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['q_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['q_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['q_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['q_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['q_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['q_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['q_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['q_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['v_proj'], accessed_by=DictGetItemGuardAccessor('v_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['v_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['v_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['v_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['v_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['v_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['v_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['v_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['v_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._modules['v_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn'].head_dim, accessed_by=DictGetItemGuardAccessor('head_dim')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn'].head_dim == 128
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn'].training, accessed_by=DictGetItemGuardAccessor('training')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn'].training, 21370824)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn'].layer_idx, accessed_by=DictGetItemGuardAccessor('layer_idx')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn'].layer_idx == 8
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn']._parameters, 21447360)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn'].num_key_value_groups, accessed_by=DictGetItemGuardAccessor('num_key_value_groups')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn'].num_key_value_groups == 4
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn'].config, accessed_by=DictGetItemGuardAccessor('config')
| | | | | | | | | | | | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['8']._modules['self_attn'].config
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['input_layernorm'], accessed_by=DictGetItemGuardAccessor('input_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['input_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['input_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['8']._modules['input_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['input_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['8']._modules['input_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['input_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['input_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['input_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['input_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['input_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['input_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['input_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['8']._modules['input_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['input_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['input_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['8']._modules['input_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['input_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['8']._modules['input_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['post_attention_layernorm'], accessed_by=DictGetItemGuardAccessor('post_attention_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['post_attention_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['post_attention_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['8']._modules['post_attention_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['post_attention_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['8']._modules['post_attention_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['post_attention_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['post_attention_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['post_attention_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['post_attention_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['post_attention_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['8']._modules['post_attention_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['post_attention_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['8']._modules['post_attention_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['post_attention_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['post_attention_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['8']._modules['post_attention_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._modules['post_attention_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['8']._modules['post_attention_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['8']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['8']._parameters, 21447360)
| | | | | | | | | | +- KeyValueManager pair at index=9
| | | | | | | | | | | +- KeyManager: GuardManager: source=list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[9]
| | | | | | | | | | | | +- EQUALS_MATCH: list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[9] == '9'
| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']
| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['9'], 866524544)
| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['9'].__dict__)
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['9']._modules, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp'], accessed_by=DictGetItemGuardAccessor('mlp')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp'], 866551056)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['act_fn'], accessed_by=DictGetItemGuardAccessor('act_fn')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['act_fn'], 805311888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['act_fn'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['act_fn'].inplace, accessed_by=DictGetItemGuardAccessor('inplace')
| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['act_fn'].inplace, 21370824)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['up_proj'], accessed_by=DictGetItemGuardAccessor('up_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['up_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['up_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['up_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['up_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['up_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['up_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['up_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['up_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['up_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['down_proj'], accessed_by=DictGetItemGuardAccessor('down_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['down_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['down_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['down_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['down_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['down_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['down_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['down_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['down_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['down_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 14336], stride=[14336, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['gate_proj'], accessed_by=DictGetItemGuardAccessor('gate_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['gate_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['gate_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['gate_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['gate_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['gate_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['gate_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['gate_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['gate_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._modules['gate_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['mlp']._parameters, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn'], accessed_by=DictGetItemGuardAccessor('self_attn')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn'], 866522768)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn'].scaling, accessed_by=DictGetItemGuardAccessor('scaling')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn'].scaling == 0.08838834764831845
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['k_proj'], accessed_by=DictGetItemGuardAccessor('k_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['k_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['k_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['k_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['k_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['k_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['k_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['k_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['k_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['k_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['o_proj'], accessed_by=DictGetItemGuardAccessor('o_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['o_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['o_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['o_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['o_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['o_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['o_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['o_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['o_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['o_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['q_proj'], accessed_by=DictGetItemGuardAccessor('q_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['q_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['q_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['q_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['q_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['q_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['q_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['q_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['q_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['q_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['v_proj'], accessed_by=DictGetItemGuardAccessor('v_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['v_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['v_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['v_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['v_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['v_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['v_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['v_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['v_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._modules['v_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn'].head_dim, accessed_by=DictGetItemGuardAccessor('head_dim')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn'].head_dim == 128
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn'].training, accessed_by=DictGetItemGuardAccessor('training')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn'].training, 21370824)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn'].layer_idx, accessed_by=DictGetItemGuardAccessor('layer_idx')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn'].layer_idx == 9
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn']._parameters, 21447360)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn'].num_key_value_groups, accessed_by=DictGetItemGuardAccessor('num_key_value_groups')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn'].num_key_value_groups == 4
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn'].config, accessed_by=DictGetItemGuardAccessor('config')
| | | | | | | | | | | | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['9']._modules['self_attn'].config
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['input_layernorm'], accessed_by=DictGetItemGuardAccessor('input_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['input_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['input_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['9']._modules['input_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['input_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['9']._modules['input_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['input_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['input_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['input_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['input_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['input_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['input_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['input_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['9']._modules['input_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['input_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['input_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['9']._modules['input_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['input_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['9']._modules['input_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['post_attention_layernorm'], accessed_by=DictGetItemGuardAccessor('post_attention_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['post_attention_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['post_attention_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['9']._modules['post_attention_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['post_attention_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['9']._modules['post_attention_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['post_attention_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['post_attention_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['post_attention_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['post_attention_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['post_attention_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['9']._modules['post_attention_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['post_attention_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['9']._modules['post_attention_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['post_attention_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['post_attention_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['9']._modules['post_attention_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._modules['post_attention_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['9']._modules['post_attention_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['9']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['9']._parameters, 21447360)
| | | | | | | | | | +- KeyValueManager pair at index=10
| | | | | | | | | | | +- KeyManager: GuardManager: source=list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[10]
| | | | | | | | | | | | +- EQUALS_MATCH: list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[10] == '10'
| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']
| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['10'], 866524544)
| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['10'].__dict__)
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['10']._modules, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp'], accessed_by=DictGetItemGuardAccessor('mlp')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp'], 866551056)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['act_fn'], accessed_by=DictGetItemGuardAccessor('act_fn')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['act_fn'], 805311888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['act_fn'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['act_fn'].inplace, accessed_by=DictGetItemGuardAccessor('inplace')
| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['act_fn'].inplace, 21370824)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['up_proj'], accessed_by=DictGetItemGuardAccessor('up_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['up_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['up_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['up_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['up_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['up_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['up_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['up_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['up_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['up_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['down_proj'], accessed_by=DictGetItemGuardAccessor('down_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['down_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['down_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['down_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['down_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['down_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['down_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['down_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['down_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['down_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 14336], stride=[14336, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['gate_proj'], accessed_by=DictGetItemGuardAccessor('gate_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['gate_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['gate_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['gate_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['gate_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['gate_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['gate_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['gate_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['gate_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._modules['gate_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['mlp']._parameters, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn'], accessed_by=DictGetItemGuardAccessor('self_attn')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn'], 866522768)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn'].scaling, accessed_by=DictGetItemGuardAccessor('scaling')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn'].scaling == 0.08838834764831845
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['k_proj'], accessed_by=DictGetItemGuardAccessor('k_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['k_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['k_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['k_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['k_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['k_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['k_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['k_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['k_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['k_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['o_proj'], accessed_by=DictGetItemGuardAccessor('o_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['o_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['o_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['o_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['o_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['o_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['o_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['o_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['o_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['o_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['q_proj'], accessed_by=DictGetItemGuardAccessor('q_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['q_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['q_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['q_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['q_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['q_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['q_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['q_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['q_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['q_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['v_proj'], accessed_by=DictGetItemGuardAccessor('v_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['v_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['v_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['v_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['v_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['v_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['v_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['v_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['v_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._modules['v_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn'].head_dim, accessed_by=DictGetItemGuardAccessor('head_dim')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn'].head_dim == 128
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn'].training, accessed_by=DictGetItemGuardAccessor('training')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn'].training, 21370824)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn'].layer_idx, accessed_by=DictGetItemGuardAccessor('layer_idx')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn'].layer_idx == 10
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn']._parameters, 21447360)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn'].num_key_value_groups, accessed_by=DictGetItemGuardAccessor('num_key_value_groups')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn'].num_key_value_groups == 4
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn'].config, accessed_by=DictGetItemGuardAccessor('config')
| | | | | | | | | | | | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['10']._modules['self_attn'].config
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['input_layernorm'], accessed_by=DictGetItemGuardAccessor('input_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['input_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['input_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['10']._modules['input_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['input_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['10']._modules['input_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['input_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['input_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['input_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['input_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['input_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['input_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['input_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['10']._modules['input_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['input_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['input_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['10']._modules['input_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['input_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['10']._modules['input_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['post_attention_layernorm'], accessed_by=DictGetItemGuardAccessor('post_attention_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['post_attention_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['post_attention_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['10']._modules['post_attention_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['post_attention_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['10']._modules['post_attention_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['post_attention_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['post_attention_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['post_attention_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['post_attention_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['post_attention_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['10']._modules['post_attention_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['post_attention_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['10']._modules['post_attention_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['post_attention_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['post_attention_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['10']._modules['post_attention_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._modules['post_attention_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['10']._modules['post_attention_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['10']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['10']._parameters, 21447360)
| | | | | | | | | | +- KeyValueManager pair at index=11
| | | | | | | | | | | +- KeyManager: GuardManager: source=list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[11]
| | | | | | | | | | | | +- EQUALS_MATCH: list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[11] == '11'
| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']
| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['11'], 866524544)
| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['11'].__dict__)
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['11']._modules, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp'], accessed_by=DictGetItemGuardAccessor('mlp')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp'], 866551056)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['act_fn'], accessed_by=DictGetItemGuardAccessor('act_fn')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['act_fn'], 805311888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['act_fn'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['act_fn'].inplace, accessed_by=DictGetItemGuardAccessor('inplace')
| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['act_fn'].inplace, 21370824)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['up_proj'], accessed_by=DictGetItemGuardAccessor('up_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['up_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['up_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['up_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['up_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['up_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['up_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['up_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['up_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['up_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['down_proj'], accessed_by=DictGetItemGuardAccessor('down_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['down_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['down_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['down_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['down_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['down_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['down_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['down_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['down_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['down_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 14336], stride=[14336, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['gate_proj'], accessed_by=DictGetItemGuardAccessor('gate_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['gate_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['gate_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['gate_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['gate_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['gate_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['gate_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['gate_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['gate_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._modules['gate_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['mlp']._parameters, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn'], accessed_by=DictGetItemGuardAccessor('self_attn')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn'], 866522768)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn'].scaling, accessed_by=DictGetItemGuardAccessor('scaling')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn'].scaling == 0.08838834764831845
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['k_proj'], accessed_by=DictGetItemGuardAccessor('k_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['k_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['k_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['k_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['k_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['k_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['k_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['k_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['k_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['k_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['o_proj'], accessed_by=DictGetItemGuardAccessor('o_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['o_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['o_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['o_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['o_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['o_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['o_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['o_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['o_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['o_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['q_proj'], accessed_by=DictGetItemGuardAccessor('q_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['q_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['q_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['q_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['q_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['q_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['q_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['q_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['q_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['q_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['v_proj'], accessed_by=DictGetItemGuardAccessor('v_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['v_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['v_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['v_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['v_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['v_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['v_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['v_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['v_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._modules['v_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn'].head_dim, accessed_by=DictGetItemGuardAccessor('head_dim')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn'].head_dim == 128
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn'].training, accessed_by=DictGetItemGuardAccessor('training')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn'].training, 21370824)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn'].layer_idx, accessed_by=DictGetItemGuardAccessor('layer_idx')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn'].layer_idx == 11
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn']._parameters, 21447360)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn'].num_key_value_groups, accessed_by=DictGetItemGuardAccessor('num_key_value_groups')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn'].num_key_value_groups == 4
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn'].config, accessed_by=DictGetItemGuardAccessor('config')
| | | | | | | | | | | | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['11']._modules['self_attn'].config
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['input_layernorm'], accessed_by=DictGetItemGuardAccessor('input_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['input_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['input_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['11']._modules['input_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['input_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['11']._modules['input_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['input_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['input_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['input_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['input_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['input_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['input_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['input_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['11']._modules['input_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['input_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['input_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['11']._modules['input_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['input_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['11']._modules['input_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['post_attention_layernorm'], accessed_by=DictGetItemGuardAccessor('post_attention_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['post_attention_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['post_attention_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['11']._modules['post_attention_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['post_attention_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['11']._modules['post_attention_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['post_attention_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['post_attention_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['post_attention_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['post_attention_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['post_attention_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['11']._modules['post_attention_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['post_attention_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['11']._modules['post_attention_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['post_attention_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['post_attention_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['11']._modules['post_attention_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._modules['post_attention_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['11']._modules['post_attention_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['11']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['11']._parameters, 21447360)
| | | | | | | | | | +- KeyValueManager pair at index=12
| | | | | | | | | | | +- KeyManager: GuardManager: source=list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[12]
| | | | | | | | | | | | +- EQUALS_MATCH: list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[12] == '12'
| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']
| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['12'], 866524544)
| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['12'].__dict__)
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['12']._modules, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp'], accessed_by=DictGetItemGuardAccessor('mlp')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp'], 866551056)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['act_fn'], accessed_by=DictGetItemGuardAccessor('act_fn')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['act_fn'], 805311888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['act_fn'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['act_fn'].inplace, accessed_by=DictGetItemGuardAccessor('inplace')
| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['act_fn'].inplace, 21370824)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['up_proj'], accessed_by=DictGetItemGuardAccessor('up_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['up_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['up_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['up_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['up_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['up_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['up_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['up_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['up_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['up_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['down_proj'], accessed_by=DictGetItemGuardAccessor('down_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['down_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['down_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['down_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['down_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['down_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['down_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['down_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['down_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['down_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 14336], stride=[14336, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['gate_proj'], accessed_by=DictGetItemGuardAccessor('gate_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['gate_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['gate_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['gate_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['gate_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['gate_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['gate_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['gate_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['gate_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._modules['gate_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['mlp']._parameters, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn'], accessed_by=DictGetItemGuardAccessor('self_attn')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn'], 866522768)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn'].scaling, accessed_by=DictGetItemGuardAccessor('scaling')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn'].scaling == 0.08838834764831845
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['k_proj'], accessed_by=DictGetItemGuardAccessor('k_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['k_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['k_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['k_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['k_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['k_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['k_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['k_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['k_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['k_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['o_proj'], accessed_by=DictGetItemGuardAccessor('o_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['o_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['o_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['o_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['o_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['o_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['o_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['o_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['o_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['o_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['q_proj'], accessed_by=DictGetItemGuardAccessor('q_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['q_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['q_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['q_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['q_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['q_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['q_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['q_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['q_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['q_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['v_proj'], accessed_by=DictGetItemGuardAccessor('v_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['v_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['v_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['v_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['v_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['v_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['v_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['v_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['v_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._modules['v_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn'].head_dim, accessed_by=DictGetItemGuardAccessor('head_dim')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn'].head_dim == 128
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn'].training, accessed_by=DictGetItemGuardAccessor('training')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn'].training, 21370824)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn'].layer_idx, accessed_by=DictGetItemGuardAccessor('layer_idx')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn'].layer_idx == 12
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn']._parameters, 21447360)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn'].num_key_value_groups, accessed_by=DictGetItemGuardAccessor('num_key_value_groups')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn'].num_key_value_groups == 4
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn'].config, accessed_by=DictGetItemGuardAccessor('config')
| | | | | | | | | | | | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['12']._modules['self_attn'].config
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['input_layernorm'], accessed_by=DictGetItemGuardAccessor('input_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['input_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['input_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['12']._modules['input_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['input_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['12']._modules['input_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['input_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['input_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['input_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['input_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['input_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['input_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['input_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['12']._modules['input_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['input_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['input_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['12']._modules['input_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['input_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['12']._modules['input_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['post_attention_layernorm'], accessed_by=DictGetItemGuardAccessor('post_attention_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['post_attention_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['post_attention_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['12']._modules['post_attention_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['post_attention_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['12']._modules['post_attention_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['post_attention_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['post_attention_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['post_attention_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['post_attention_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['post_attention_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['12']._modules['post_attention_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['post_attention_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['12']._modules['post_attention_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['post_attention_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['post_attention_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['12']._modules['post_attention_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._modules['post_attention_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['12']._modules['post_attention_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['12']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['12']._parameters, 21447360)
| | | | | | | | | | +- KeyValueManager pair at index=13
| | | | | | | | | | | +- KeyManager: GuardManager: source=list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[13]
| | | | | | | | | | | | +- EQUALS_MATCH: list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[13] == '13'
| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']
| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['13'], 866524544)
| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['13'].__dict__)
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['13']._modules, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp'], accessed_by=DictGetItemGuardAccessor('mlp')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp'], 866551056)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['act_fn'], accessed_by=DictGetItemGuardAccessor('act_fn')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['act_fn'], 805311888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['act_fn'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['act_fn'].inplace, accessed_by=DictGetItemGuardAccessor('inplace')
| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['act_fn'].inplace, 21370824)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['up_proj'], accessed_by=DictGetItemGuardAccessor('up_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['up_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['up_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['up_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['up_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['up_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['up_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['up_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['up_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['up_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['down_proj'], accessed_by=DictGetItemGuardAccessor('down_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['down_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['down_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['down_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['down_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['down_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['down_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['down_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['down_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['down_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 14336], stride=[14336, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['gate_proj'], accessed_by=DictGetItemGuardAccessor('gate_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['gate_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['gate_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['gate_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['gate_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['gate_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['gate_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['gate_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['gate_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._modules['gate_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['mlp']._parameters, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn'], accessed_by=DictGetItemGuardAccessor('self_attn')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn'], 866522768)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn'].scaling, accessed_by=DictGetItemGuardAccessor('scaling')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn'].scaling == 0.08838834764831845
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['k_proj'], accessed_by=DictGetItemGuardAccessor('k_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['k_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['k_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['k_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['k_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['k_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['k_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['k_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['k_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['k_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['o_proj'], accessed_by=DictGetItemGuardAccessor('o_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['o_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['o_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['o_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['o_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['o_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['o_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['o_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['o_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['o_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['q_proj'], accessed_by=DictGetItemGuardAccessor('q_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['q_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['q_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['q_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['q_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['q_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['q_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['q_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['q_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['q_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['v_proj'], accessed_by=DictGetItemGuardAccessor('v_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['v_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['v_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['v_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['v_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['v_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['v_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['v_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['v_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._modules['v_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn'].head_dim, accessed_by=DictGetItemGuardAccessor('head_dim')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn'].head_dim == 128
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn'].training, accessed_by=DictGetItemGuardAccessor('training')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn'].training, 21370824)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn'].layer_idx, accessed_by=DictGetItemGuardAccessor('layer_idx')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn'].layer_idx == 13
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn']._parameters, 21447360)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn'].num_key_value_groups, accessed_by=DictGetItemGuardAccessor('num_key_value_groups')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn'].num_key_value_groups == 4
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn'].config, accessed_by=DictGetItemGuardAccessor('config')
| | | | | | | | | | | | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['13']._modules['self_attn'].config
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['input_layernorm'], accessed_by=DictGetItemGuardAccessor('input_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['input_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['input_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['13']._modules['input_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['input_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['13']._modules['input_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['input_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['input_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['input_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['input_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['input_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['input_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['input_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['13']._modules['input_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['input_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['input_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['13']._modules['input_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['input_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['13']._modules['input_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['post_attention_layernorm'], accessed_by=DictGetItemGuardAccessor('post_attention_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['post_attention_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['post_attention_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['13']._modules['post_attention_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['post_attention_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['13']._modules['post_attention_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['post_attention_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['post_attention_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['post_attention_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['post_attention_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['post_attention_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['13']._modules['post_attention_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['post_attention_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['13']._modules['post_attention_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['post_attention_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['post_attention_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['13']._modules['post_attention_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._modules['post_attention_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['13']._modules['post_attention_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['13']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['13']._parameters, 21447360)
| | | | | | | | | | +- KeyValueManager pair at index=14
| | | | | | | | | | | +- KeyManager: GuardManager: source=list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[14]
| | | | | | | | | | | | +- EQUALS_MATCH: list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[14] == '14'
| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']
| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['14'], 866524544)
| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['14'].__dict__)
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['14']._modules, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp'], accessed_by=DictGetItemGuardAccessor('mlp')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp'], 866551056)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['act_fn'], accessed_by=DictGetItemGuardAccessor('act_fn')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['act_fn'], 805311888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['act_fn'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['act_fn'].inplace, accessed_by=DictGetItemGuardAccessor('inplace')
| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['act_fn'].inplace, 21370824)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['up_proj'], accessed_by=DictGetItemGuardAccessor('up_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['up_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['up_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['up_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['up_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['up_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['up_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['up_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['up_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['up_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['down_proj'], accessed_by=DictGetItemGuardAccessor('down_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['down_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['down_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['down_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['down_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['down_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['down_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['down_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['down_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['down_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 14336], stride=[14336, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['gate_proj'], accessed_by=DictGetItemGuardAccessor('gate_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['gate_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['gate_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['gate_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['gate_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['gate_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['gate_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['gate_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['gate_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._modules['gate_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['mlp']._parameters, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn'], accessed_by=DictGetItemGuardAccessor('self_attn')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn'], 866522768)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn'].scaling, accessed_by=DictGetItemGuardAccessor('scaling')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn'].scaling == 0.08838834764831845
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['k_proj'], accessed_by=DictGetItemGuardAccessor('k_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['k_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['k_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['k_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['k_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['k_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['k_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['k_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['k_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['k_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['o_proj'], accessed_by=DictGetItemGuardAccessor('o_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['o_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['o_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['o_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['o_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['o_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['o_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['o_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['o_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['o_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['q_proj'], accessed_by=DictGetItemGuardAccessor('q_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['q_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['q_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['q_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['q_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['q_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['q_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['q_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['q_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['q_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['v_proj'], accessed_by=DictGetItemGuardAccessor('v_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['v_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['v_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['v_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['v_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['v_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['v_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['v_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['v_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._modules['v_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn'].head_dim, accessed_by=DictGetItemGuardAccessor('head_dim')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn'].head_dim == 128
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn'].training, accessed_by=DictGetItemGuardAccessor('training')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn'].training, 21370824)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn'].layer_idx, accessed_by=DictGetItemGuardAccessor('layer_idx')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn'].layer_idx == 14
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn']._parameters, 21447360)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn'].num_key_value_groups, accessed_by=DictGetItemGuardAccessor('num_key_value_groups')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn'].num_key_value_groups == 4
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn'].config, accessed_by=DictGetItemGuardAccessor('config')
| | | | | | | | | | | | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['14']._modules['self_attn'].config
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['input_layernorm'], accessed_by=DictGetItemGuardAccessor('input_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['input_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['input_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['14']._modules['input_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['input_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['14']._modules['input_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['input_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['input_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['input_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['input_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['input_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['input_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['input_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['14']._modules['input_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['input_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['input_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['14']._modules['input_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['input_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['14']._modules['input_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['post_attention_layernorm'], accessed_by=DictGetItemGuardAccessor('post_attention_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['post_attention_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['post_attention_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['14']._modules['post_attention_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['post_attention_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['14']._modules['post_attention_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['post_attention_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['post_attention_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['post_attention_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['post_attention_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['post_attention_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['14']._modules['post_attention_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['post_attention_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['14']._modules['post_attention_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['post_attention_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['post_attention_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['14']._modules['post_attention_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._modules['post_attention_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['14']._modules['post_attention_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['14']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['14']._parameters, 21447360)
| | | | | | | | | | +- KeyValueManager pair at index=15
| | | | | | | | | | | +- KeyManager: GuardManager: source=list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[15]
| | | | | | | | | | | | +- EQUALS_MATCH: list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[15] == '15'
| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']
| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['15'], 866524544)
| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['15'].__dict__)
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['15']._modules, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp'], accessed_by=DictGetItemGuardAccessor('mlp')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp'], 866551056)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['act_fn'], accessed_by=DictGetItemGuardAccessor('act_fn')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['act_fn'], 805311888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['act_fn'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['act_fn'].inplace, accessed_by=DictGetItemGuardAccessor('inplace')
| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['act_fn'].inplace, 21370824)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['up_proj'], accessed_by=DictGetItemGuardAccessor('up_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['up_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['up_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['up_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['up_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['up_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['up_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['up_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['up_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['up_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['down_proj'], accessed_by=DictGetItemGuardAccessor('down_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['down_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['down_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['down_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['down_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['down_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['down_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['down_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['down_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['down_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 14336], stride=[14336, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['gate_proj'], accessed_by=DictGetItemGuardAccessor('gate_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['gate_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['gate_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['gate_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['gate_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['gate_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['gate_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['gate_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['gate_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._modules['gate_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['mlp']._parameters, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn'], accessed_by=DictGetItemGuardAccessor('self_attn')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn'], 866522768)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn'].scaling, accessed_by=DictGetItemGuardAccessor('scaling')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn'].scaling == 0.08838834764831845
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['k_proj'], accessed_by=DictGetItemGuardAccessor('k_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['k_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['k_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['k_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['k_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['k_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['k_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['k_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['k_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['k_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['o_proj'], accessed_by=DictGetItemGuardAccessor('o_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['o_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['o_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['o_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['o_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['o_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['o_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['o_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['o_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['o_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['q_proj'], accessed_by=DictGetItemGuardAccessor('q_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['q_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['q_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['q_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['q_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['q_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['q_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['q_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['q_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['q_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['v_proj'], accessed_by=DictGetItemGuardAccessor('v_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['v_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['v_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['v_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['v_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['v_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['v_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['v_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['v_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._modules['v_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn'].head_dim, accessed_by=DictGetItemGuardAccessor('head_dim')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn'].head_dim == 128
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn'].training, accessed_by=DictGetItemGuardAccessor('training')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn'].training, 21370824)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn'].layer_idx, accessed_by=DictGetItemGuardAccessor('layer_idx')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn'].layer_idx == 15
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn']._parameters, 21447360)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn'].num_key_value_groups, accessed_by=DictGetItemGuardAccessor('num_key_value_groups')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn'].num_key_value_groups == 4
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn'].config, accessed_by=DictGetItemGuardAccessor('config')
| | | | | | | | | | | | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['15']._modules['self_attn'].config
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['input_layernorm'], accessed_by=DictGetItemGuardAccessor('input_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['input_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['input_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['15']._modules['input_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['input_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['15']._modules['input_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['input_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['input_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['input_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['input_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['input_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['input_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['input_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['15']._modules['input_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['input_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['input_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['15']._modules['input_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['input_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['15']._modules['input_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['post_attention_layernorm'], accessed_by=DictGetItemGuardAccessor('post_attention_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['post_attention_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['post_attention_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['15']._modules['post_attention_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['post_attention_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['15']._modules['post_attention_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['post_attention_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['post_attention_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['post_attention_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['post_attention_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['post_attention_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['15']._modules['post_attention_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['post_attention_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['15']._modules['post_attention_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['post_attention_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['post_attention_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['15']._modules['post_attention_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._modules['post_attention_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['15']._modules['post_attention_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['15']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['15']._parameters, 21447360)
| | | | | | | | | | +- KeyValueManager pair at index=16
| | | | | | | | | | | +- KeyManager: GuardManager: source=list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[16]
| | | | | | | | | | | | +- EQUALS_MATCH: list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[16] == '16'
| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']
| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['16'], 866524544)
| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['16'].__dict__)
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['16']._modules, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp'], accessed_by=DictGetItemGuardAccessor('mlp')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp'], 866551056)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['act_fn'], accessed_by=DictGetItemGuardAccessor('act_fn')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['act_fn'], 805311888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['act_fn'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['act_fn'].inplace, accessed_by=DictGetItemGuardAccessor('inplace')
| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['act_fn'].inplace, 21370824)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['up_proj'], accessed_by=DictGetItemGuardAccessor('up_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['up_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['up_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['up_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['up_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['up_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['up_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['up_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['up_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['up_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['down_proj'], accessed_by=DictGetItemGuardAccessor('down_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['down_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['down_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['down_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['down_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['down_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['down_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['down_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['down_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['down_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 14336], stride=[14336, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['gate_proj'], accessed_by=DictGetItemGuardAccessor('gate_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['gate_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['gate_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['gate_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['gate_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['gate_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['gate_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['gate_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['gate_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._modules['gate_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['mlp']._parameters, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn'], accessed_by=DictGetItemGuardAccessor('self_attn')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn'], 866522768)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn'].scaling, accessed_by=DictGetItemGuardAccessor('scaling')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn'].scaling == 0.08838834764831845
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['k_proj'], accessed_by=DictGetItemGuardAccessor('k_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['k_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['k_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['k_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['k_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['k_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['k_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['k_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['k_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['k_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['o_proj'], accessed_by=DictGetItemGuardAccessor('o_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['o_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['o_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['o_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['o_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['o_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['o_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['o_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['o_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['o_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['q_proj'], accessed_by=DictGetItemGuardAccessor('q_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['q_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['q_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['q_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['q_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['q_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['q_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['q_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['q_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['q_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['v_proj'], accessed_by=DictGetItemGuardAccessor('v_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['v_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['v_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['v_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['v_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['v_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['v_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['v_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['v_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._modules['v_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn'].head_dim, accessed_by=DictGetItemGuardAccessor('head_dim')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn'].head_dim == 128
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn'].training, accessed_by=DictGetItemGuardAccessor('training')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn'].training, 21370824)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn'].layer_idx, accessed_by=DictGetItemGuardAccessor('layer_idx')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn'].layer_idx == 16
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn']._parameters, 21447360)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn'].num_key_value_groups, accessed_by=DictGetItemGuardAccessor('num_key_value_groups')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn'].num_key_value_groups == 4
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn'].config, accessed_by=DictGetItemGuardAccessor('config')
| | | | | | | | | | | | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['16']._modules['self_attn'].config
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['input_layernorm'], accessed_by=DictGetItemGuardAccessor('input_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['input_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['input_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['16']._modules['input_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['input_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['16']._modules['input_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['input_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['input_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['input_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['input_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['input_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['input_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['input_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['16']._modules['input_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['input_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['input_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['16']._modules['input_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['input_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['16']._modules['input_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['post_attention_layernorm'], accessed_by=DictGetItemGuardAccessor('post_attention_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['post_attention_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['post_attention_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['16']._modules['post_attention_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['post_attention_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['16']._modules['post_attention_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['post_attention_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['post_attention_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['post_attention_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['post_attention_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['post_attention_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['16']._modules['post_attention_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['post_attention_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['16']._modules['post_attention_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['post_attention_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['post_attention_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['16']._modules['post_attention_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._modules['post_attention_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['16']._modules['post_attention_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['16']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['16']._parameters, 21447360)
| | | | | | | | | | +- KeyValueManager pair at index=17
| | | | | | | | | | | +- KeyManager: GuardManager: source=list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[17]
| | | | | | | | | | | | +- EQUALS_MATCH: list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[17] == '17'
| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']
| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['17'], 866524544)
| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['17'].__dict__)
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['17']._modules, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp'], accessed_by=DictGetItemGuardAccessor('mlp')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp'], 866551056)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['act_fn'], accessed_by=DictGetItemGuardAccessor('act_fn')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['act_fn'], 805311888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['act_fn'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['act_fn'].inplace, accessed_by=DictGetItemGuardAccessor('inplace')
| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['act_fn'].inplace, 21370824)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['up_proj'], accessed_by=DictGetItemGuardAccessor('up_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['up_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['up_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['up_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['up_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['up_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['up_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['up_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['up_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['up_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['down_proj'], accessed_by=DictGetItemGuardAccessor('down_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['down_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['down_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['down_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['down_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['down_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['down_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['down_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['down_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['down_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 14336], stride=[14336, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['gate_proj'], accessed_by=DictGetItemGuardAccessor('gate_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['gate_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['gate_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['gate_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['gate_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['gate_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['gate_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['gate_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['gate_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._modules['gate_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['mlp']._parameters, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn'], accessed_by=DictGetItemGuardAccessor('self_attn')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn'], 866522768)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn'].scaling, accessed_by=DictGetItemGuardAccessor('scaling')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn'].scaling == 0.08838834764831845
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['k_proj'], accessed_by=DictGetItemGuardAccessor('k_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['k_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['k_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['k_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['k_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['k_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['k_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['k_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['k_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['k_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['o_proj'], accessed_by=DictGetItemGuardAccessor('o_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['o_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['o_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['o_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['o_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['o_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['o_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['o_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['o_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['o_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['q_proj'], accessed_by=DictGetItemGuardAccessor('q_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['q_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['q_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['q_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['q_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['q_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['q_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['q_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['q_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['q_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['v_proj'], accessed_by=DictGetItemGuardAccessor('v_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['v_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['v_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['v_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['v_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['v_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['v_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['v_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['v_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._modules['v_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn'].head_dim, accessed_by=DictGetItemGuardAccessor('head_dim')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn'].head_dim == 128
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn'].training, accessed_by=DictGetItemGuardAccessor('training')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn'].training, 21370824)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn'].layer_idx, accessed_by=DictGetItemGuardAccessor('layer_idx')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn'].layer_idx == 17
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn']._parameters, 21447360)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn'].num_key_value_groups, accessed_by=DictGetItemGuardAccessor('num_key_value_groups')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn'].num_key_value_groups == 4
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn'].config, accessed_by=DictGetItemGuardAccessor('config')
| | | | | | | | | | | | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['17']._modules['self_attn'].config
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['input_layernorm'], accessed_by=DictGetItemGuardAccessor('input_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['input_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['input_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['17']._modules['input_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['input_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['17']._modules['input_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['input_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['input_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['input_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['input_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['input_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['input_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['input_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['17']._modules['input_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['input_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['input_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['17']._modules['input_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['input_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['17']._modules['input_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['post_attention_layernorm'], accessed_by=DictGetItemGuardAccessor('post_attention_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['post_attention_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['post_attention_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['17']._modules['post_attention_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['post_attention_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['17']._modules['post_attention_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['post_attention_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['post_attention_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['post_attention_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['post_attention_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['post_attention_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['17']._modules['post_attention_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['post_attention_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['17']._modules['post_attention_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['post_attention_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['post_attention_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['17']._modules['post_attention_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._modules['post_attention_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['17']._modules['post_attention_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['17']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['17']._parameters, 21447360)
| | | | | | | | | | +- KeyValueManager pair at index=18
| | | | | | | | | | | +- KeyManager: GuardManager: source=list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[18]
| | | | | | | | | | | | +- EQUALS_MATCH: list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[18] == '18'
| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']
| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['18'], 866524544)
| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['18'].__dict__)
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['18']._modules, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp'], accessed_by=DictGetItemGuardAccessor('mlp')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp'], 866551056)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['act_fn'], accessed_by=DictGetItemGuardAccessor('act_fn')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['act_fn'], 805311888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['act_fn'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['act_fn'].inplace, accessed_by=DictGetItemGuardAccessor('inplace')
| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['act_fn'].inplace, 21370824)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['up_proj'], accessed_by=DictGetItemGuardAccessor('up_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['up_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['up_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['up_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['up_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['up_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['up_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['up_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['up_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['up_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['down_proj'], accessed_by=DictGetItemGuardAccessor('down_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['down_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['down_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['down_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['down_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['down_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['down_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['down_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['down_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['down_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 14336], stride=[14336, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['gate_proj'], accessed_by=DictGetItemGuardAccessor('gate_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['gate_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['gate_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['gate_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['gate_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['gate_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['gate_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['gate_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['gate_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._modules['gate_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['mlp']._parameters, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn'], accessed_by=DictGetItemGuardAccessor('self_attn')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn'], 866522768)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn'].scaling, accessed_by=DictGetItemGuardAccessor('scaling')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn'].scaling == 0.08838834764831845
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['k_proj'], accessed_by=DictGetItemGuardAccessor('k_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['k_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['k_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['k_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['k_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['k_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['k_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['k_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['k_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['k_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['o_proj'], accessed_by=DictGetItemGuardAccessor('o_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['o_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['o_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['o_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['o_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['o_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['o_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['o_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['o_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['o_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['q_proj'], accessed_by=DictGetItemGuardAccessor('q_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['q_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['q_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['q_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['q_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['q_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['q_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['q_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['q_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['q_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['v_proj'], accessed_by=DictGetItemGuardAccessor('v_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['v_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['v_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['v_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['v_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['v_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['v_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['v_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['v_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._modules['v_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn'].head_dim, accessed_by=DictGetItemGuardAccessor('head_dim')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn'].head_dim == 128
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn'].training, accessed_by=DictGetItemGuardAccessor('training')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn'].training, 21370824)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn'].layer_idx, accessed_by=DictGetItemGuardAccessor('layer_idx')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn'].layer_idx == 18
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn']._parameters, 21447360)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn'].num_key_value_groups, accessed_by=DictGetItemGuardAccessor('num_key_value_groups')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn'].num_key_value_groups == 4
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn'].config, accessed_by=DictGetItemGuardAccessor('config')
| | | | | | | | | | | | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['18']._modules['self_attn'].config
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['input_layernorm'], accessed_by=DictGetItemGuardAccessor('input_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['input_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['input_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['18']._modules['input_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['input_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['18']._modules['input_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['input_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['input_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['input_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['input_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['input_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['input_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['input_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['18']._modules['input_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['input_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['input_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['18']._modules['input_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['input_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['18']._modules['input_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['post_attention_layernorm'], accessed_by=DictGetItemGuardAccessor('post_attention_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['post_attention_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['post_attention_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['18']._modules['post_attention_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['post_attention_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['18']._modules['post_attention_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['post_attention_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['post_attention_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['post_attention_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['post_attention_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['post_attention_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['18']._modules['post_attention_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['post_attention_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['18']._modules['post_attention_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['post_attention_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['post_attention_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['18']._modules['post_attention_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._modules['post_attention_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['18']._modules['post_attention_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['18']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['18']._parameters, 21447360)
| | | | | | | | | | +- KeyValueManager pair at index=19
| | | | | | | | | | | +- KeyManager: GuardManager: source=list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[19]
| | | | | | | | | | | | +- EQUALS_MATCH: list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[19] == '19'
| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']
| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['19'], 866524544)
| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['19'].__dict__)
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['19']._modules, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp'], accessed_by=DictGetItemGuardAccessor('mlp')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp'], 866551056)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['act_fn'], accessed_by=DictGetItemGuardAccessor('act_fn')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['act_fn'], 805311888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['act_fn'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['act_fn'].inplace, accessed_by=DictGetItemGuardAccessor('inplace')
| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['act_fn'].inplace, 21370824)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['up_proj'], accessed_by=DictGetItemGuardAccessor('up_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['up_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['up_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['up_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['up_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['up_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['up_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['up_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['up_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['up_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['down_proj'], accessed_by=DictGetItemGuardAccessor('down_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['down_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['down_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['down_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['down_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['down_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['down_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['down_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['down_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['down_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 14336], stride=[14336, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['gate_proj'], accessed_by=DictGetItemGuardAccessor('gate_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['gate_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['gate_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['gate_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['gate_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['gate_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['gate_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['gate_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['gate_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._modules['gate_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['mlp']._parameters, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn'], accessed_by=DictGetItemGuardAccessor('self_attn')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn'], 866522768)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn'].scaling, accessed_by=DictGetItemGuardAccessor('scaling')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn'].scaling == 0.08838834764831845
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['k_proj'], accessed_by=DictGetItemGuardAccessor('k_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['k_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['k_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['k_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['k_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['k_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['k_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['k_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['k_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['k_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['o_proj'], accessed_by=DictGetItemGuardAccessor('o_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['o_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['o_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['o_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['o_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['o_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['o_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['o_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['o_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['o_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['q_proj'], accessed_by=DictGetItemGuardAccessor('q_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['q_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['q_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['q_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['q_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['q_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['q_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['q_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['q_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['q_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['v_proj'], accessed_by=DictGetItemGuardAccessor('v_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['v_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['v_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['v_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['v_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['v_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['v_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['v_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['v_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._modules['v_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn'].head_dim, accessed_by=DictGetItemGuardAccessor('head_dim')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn'].head_dim == 128
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn'].training, accessed_by=DictGetItemGuardAccessor('training')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn'].training, 21370824)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn'].layer_idx, accessed_by=DictGetItemGuardAccessor('layer_idx')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn'].layer_idx == 19
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn']._parameters, 21447360)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn'].num_key_value_groups, accessed_by=DictGetItemGuardAccessor('num_key_value_groups')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn'].num_key_value_groups == 4
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn'].config, accessed_by=DictGetItemGuardAccessor('config')
| | | | | | | | | | | | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['19']._modules['self_attn'].config
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['input_layernorm'], accessed_by=DictGetItemGuardAccessor('input_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['input_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['input_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['19']._modules['input_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['input_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['19']._modules['input_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['input_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['input_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['input_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['input_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['input_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['input_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['input_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['19']._modules['input_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['input_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['input_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['19']._modules['input_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['input_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['19']._modules['input_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['post_attention_layernorm'], accessed_by=DictGetItemGuardAccessor('post_attention_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['post_attention_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['post_attention_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['19']._modules['post_attention_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['post_attention_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['19']._modules['post_attention_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['post_attention_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['post_attention_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['post_attention_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['post_attention_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['post_attention_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['19']._modules['post_attention_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['post_attention_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['19']._modules['post_attention_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['post_attention_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['post_attention_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['19']._modules['post_attention_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._modules['post_attention_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['19']._modules['post_attention_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['19']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['19']._parameters, 21447360)
| | | | | | | | | | +- KeyValueManager pair at index=20
| | | | | | | | | | | +- KeyManager: GuardManager: source=list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[20]
| | | | | | | | | | | | +- EQUALS_MATCH: list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[20] == '20'
| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']
| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['20'], 866524544)
| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['20'].__dict__)
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['20']._modules, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp'], accessed_by=DictGetItemGuardAccessor('mlp')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp'], 866551056)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['act_fn'], accessed_by=DictGetItemGuardAccessor('act_fn')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['act_fn'], 805311888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['act_fn'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['act_fn'].inplace, accessed_by=DictGetItemGuardAccessor('inplace')
| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['act_fn'].inplace, 21370824)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['up_proj'], accessed_by=DictGetItemGuardAccessor('up_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['up_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['up_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['up_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['up_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['up_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['up_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['up_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['up_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['up_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['down_proj'], accessed_by=DictGetItemGuardAccessor('down_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['down_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['down_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['down_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['down_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['down_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['down_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['down_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['down_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['down_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 14336], stride=[14336, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['gate_proj'], accessed_by=DictGetItemGuardAccessor('gate_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['gate_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['gate_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['gate_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['gate_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['gate_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['gate_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['gate_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['gate_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._modules['gate_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['mlp']._parameters, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn'], accessed_by=DictGetItemGuardAccessor('self_attn')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn'], 866522768)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn'].scaling, accessed_by=DictGetItemGuardAccessor('scaling')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn'].scaling == 0.08838834764831845
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['k_proj'], accessed_by=DictGetItemGuardAccessor('k_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['k_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['k_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['k_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['k_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['k_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['k_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['k_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['k_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['k_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['o_proj'], accessed_by=DictGetItemGuardAccessor('o_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['o_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['o_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['o_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['o_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['o_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['o_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['o_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['o_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['o_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['q_proj'], accessed_by=DictGetItemGuardAccessor('q_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['q_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['q_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['q_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['q_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['q_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['q_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['q_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['q_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['q_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['v_proj'], accessed_by=DictGetItemGuardAccessor('v_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['v_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['v_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['v_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['v_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['v_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['v_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['v_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['v_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._modules['v_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn'].head_dim, accessed_by=DictGetItemGuardAccessor('head_dim')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn'].head_dim == 128
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn'].training, accessed_by=DictGetItemGuardAccessor('training')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn'].training, 21370824)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn'].layer_idx, accessed_by=DictGetItemGuardAccessor('layer_idx')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn'].layer_idx == 20
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn']._parameters, 21447360)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn'].num_key_value_groups, accessed_by=DictGetItemGuardAccessor('num_key_value_groups')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn'].num_key_value_groups == 4
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn'].config, accessed_by=DictGetItemGuardAccessor('config')
| | | | | | | | | | | | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['20']._modules['self_attn'].config
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['input_layernorm'], accessed_by=DictGetItemGuardAccessor('input_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['input_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['input_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['20']._modules['input_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['input_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['20']._modules['input_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['input_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['input_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['input_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['input_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['input_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['input_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['input_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['20']._modules['input_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['input_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['input_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['20']._modules['input_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['input_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['20']._modules['input_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['post_attention_layernorm'], accessed_by=DictGetItemGuardAccessor('post_attention_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['post_attention_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['post_attention_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['20']._modules['post_attention_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['post_attention_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['20']._modules['post_attention_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['post_attention_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['post_attention_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['post_attention_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['post_attention_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['post_attention_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['20']._modules['post_attention_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['post_attention_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['20']._modules['post_attention_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['post_attention_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['post_attention_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['20']._modules['post_attention_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._modules['post_attention_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['20']._modules['post_attention_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['20']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['20']._parameters, 21447360)
| | | | | | | | | | +- KeyValueManager pair at index=21
| | | | | | | | | | | +- KeyManager: GuardManager: source=list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[21]
| | | | | | | | | | | | +- EQUALS_MATCH: list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[21] == '21'
| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']
| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['21'], 866524544)
| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['21'].__dict__)
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['21']._modules, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp'], accessed_by=DictGetItemGuardAccessor('mlp')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp'], 866551056)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['act_fn'], accessed_by=DictGetItemGuardAccessor('act_fn')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['act_fn'], 805311888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['act_fn'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['act_fn'].inplace, accessed_by=DictGetItemGuardAccessor('inplace')
| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['act_fn'].inplace, 21370824)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['up_proj'], accessed_by=DictGetItemGuardAccessor('up_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['up_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['up_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['up_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['up_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['up_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['up_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['up_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['up_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['up_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['down_proj'], accessed_by=DictGetItemGuardAccessor('down_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['down_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['down_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['down_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['down_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['down_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['down_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['down_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['down_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['down_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 14336], stride=[14336, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['gate_proj'], accessed_by=DictGetItemGuardAccessor('gate_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['gate_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['gate_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['gate_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['gate_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['gate_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['gate_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['gate_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['gate_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._modules['gate_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['mlp']._parameters, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn'], accessed_by=DictGetItemGuardAccessor('self_attn')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn'], 866522768)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn'].scaling, accessed_by=DictGetItemGuardAccessor('scaling')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn'].scaling == 0.08838834764831845
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['k_proj'], accessed_by=DictGetItemGuardAccessor('k_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['k_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['k_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['k_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['k_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['k_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['k_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['k_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['k_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['k_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['o_proj'], accessed_by=DictGetItemGuardAccessor('o_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['o_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['o_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['o_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['o_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['o_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['o_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['o_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['o_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['o_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['q_proj'], accessed_by=DictGetItemGuardAccessor('q_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['q_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['q_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['q_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['q_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['q_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['q_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['q_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['q_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['q_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['v_proj'], accessed_by=DictGetItemGuardAccessor('v_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['v_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['v_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['v_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['v_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['v_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['v_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['v_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['v_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._modules['v_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn'].head_dim, accessed_by=DictGetItemGuardAccessor('head_dim')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn'].head_dim == 128
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn'].training, accessed_by=DictGetItemGuardAccessor('training')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn'].training, 21370824)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn'].layer_idx, accessed_by=DictGetItemGuardAccessor('layer_idx')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn'].layer_idx == 21
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn']._parameters, 21447360)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn'].num_key_value_groups, accessed_by=DictGetItemGuardAccessor('num_key_value_groups')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn'].num_key_value_groups == 4
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn'].config, accessed_by=DictGetItemGuardAccessor('config')
| | | | | | | | | | | | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['21']._modules['self_attn'].config
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['input_layernorm'], accessed_by=DictGetItemGuardAccessor('input_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['input_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['input_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['21']._modules['input_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['input_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['21']._modules['input_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['input_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['input_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['input_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['input_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['input_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['input_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['input_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['21']._modules['input_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['input_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['input_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['21']._modules['input_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['input_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['21']._modules['input_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['post_attention_layernorm'], accessed_by=DictGetItemGuardAccessor('post_attention_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['post_attention_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['post_attention_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['21']._modules['post_attention_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['post_attention_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['21']._modules['post_attention_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['post_attention_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['post_attention_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['post_attention_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['post_attention_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['post_attention_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['21']._modules['post_attention_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['post_attention_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['21']._modules['post_attention_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['post_attention_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['post_attention_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['21']._modules['post_attention_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._modules['post_attention_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['21']._modules['post_attention_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['21']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['21']._parameters, 21447360)
| | | | | | | | | | +- KeyValueManager pair at index=22
| | | | | | | | | | | +- KeyManager: GuardManager: source=list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[22]
| | | | | | | | | | | | +- EQUALS_MATCH: list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[22] == '22'
| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']
| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['22'], 866524544)
| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['22'].__dict__)
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['22']._modules, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp'], accessed_by=DictGetItemGuardAccessor('mlp')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp'], 866551056)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['act_fn'], accessed_by=DictGetItemGuardAccessor('act_fn')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['act_fn'], 805311888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['act_fn'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['act_fn'].inplace, accessed_by=DictGetItemGuardAccessor('inplace')
| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['act_fn'].inplace, 21370824)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['up_proj'], accessed_by=DictGetItemGuardAccessor('up_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['up_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['up_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['up_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['up_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['up_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['up_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['up_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['up_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['up_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['down_proj'], accessed_by=DictGetItemGuardAccessor('down_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['down_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['down_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['down_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['down_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['down_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['down_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['down_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['down_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['down_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 14336], stride=[14336, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['gate_proj'], accessed_by=DictGetItemGuardAccessor('gate_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['gate_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['gate_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['gate_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['gate_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['gate_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['gate_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['gate_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['gate_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._modules['gate_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['mlp']._parameters, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn'], accessed_by=DictGetItemGuardAccessor('self_attn')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn'], 866522768)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn'].scaling, accessed_by=DictGetItemGuardAccessor('scaling')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn'].scaling == 0.08838834764831845
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['k_proj'], accessed_by=DictGetItemGuardAccessor('k_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['k_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['k_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['k_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['k_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['k_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['k_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['k_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['k_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['k_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['o_proj'], accessed_by=DictGetItemGuardAccessor('o_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['o_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['o_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['o_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['o_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['o_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['o_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['o_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['o_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['o_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['q_proj'], accessed_by=DictGetItemGuardAccessor('q_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['q_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['q_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['q_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['q_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['q_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['q_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['q_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['q_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['q_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['v_proj'], accessed_by=DictGetItemGuardAccessor('v_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['v_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['v_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['v_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['v_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['v_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['v_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['v_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['v_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._modules['v_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn'].head_dim, accessed_by=DictGetItemGuardAccessor('head_dim')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn'].head_dim == 128
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn'].training, accessed_by=DictGetItemGuardAccessor('training')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn'].training, 21370824)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn'].layer_idx, accessed_by=DictGetItemGuardAccessor('layer_idx')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn'].layer_idx == 22
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn']._parameters, 21447360)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn'].num_key_value_groups, accessed_by=DictGetItemGuardAccessor('num_key_value_groups')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn'].num_key_value_groups == 4
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn'].config, accessed_by=DictGetItemGuardAccessor('config')
| | | | | | | | | | | | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['22']._modules['self_attn'].config
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['input_layernorm'], accessed_by=DictGetItemGuardAccessor('input_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['input_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['input_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['22']._modules['input_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['input_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['22']._modules['input_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['input_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['input_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['input_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['input_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['input_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['input_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['input_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['22']._modules['input_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['input_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['input_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['22']._modules['input_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['input_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['22']._modules['input_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['post_attention_layernorm'], accessed_by=DictGetItemGuardAccessor('post_attention_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['post_attention_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['post_attention_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['22']._modules['post_attention_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['post_attention_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['22']._modules['post_attention_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['post_attention_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['post_attention_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['post_attention_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['post_attention_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['post_attention_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['22']._modules['post_attention_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['post_attention_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['22']._modules['post_attention_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['post_attention_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['post_attention_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['22']._modules['post_attention_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._modules['post_attention_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['22']._modules['post_attention_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['22']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['22']._parameters, 21447360)
| | | | | | | | | | +- KeyValueManager pair at index=23
| | | | | | | | | | | +- KeyManager: GuardManager: source=list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[23]
| | | | | | | | | | | | +- EQUALS_MATCH: list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[23] == '23'
| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']
| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['23'], 866524544)
| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['23'].__dict__)
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['23']._modules, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp'], accessed_by=DictGetItemGuardAccessor('mlp')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp'], 866551056)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['act_fn'], accessed_by=DictGetItemGuardAccessor('act_fn')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['act_fn'], 805311888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['act_fn'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['act_fn'].inplace, accessed_by=DictGetItemGuardAccessor('inplace')
| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['act_fn'].inplace, 21370824)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['up_proj'], accessed_by=DictGetItemGuardAccessor('up_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['up_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['up_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['up_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['up_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['up_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['up_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['up_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['up_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['up_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['down_proj'], accessed_by=DictGetItemGuardAccessor('down_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['down_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['down_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['down_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['down_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['down_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['down_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['down_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['down_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['down_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 14336], stride=[14336, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['gate_proj'], accessed_by=DictGetItemGuardAccessor('gate_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['gate_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['gate_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['gate_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['gate_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['gate_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['gate_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['gate_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['gate_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._modules['gate_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['mlp']._parameters, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn'], accessed_by=DictGetItemGuardAccessor('self_attn')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn'], 866522768)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn'].scaling, accessed_by=DictGetItemGuardAccessor('scaling')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn'].scaling == 0.08838834764831845
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['k_proj'], accessed_by=DictGetItemGuardAccessor('k_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['k_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['k_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['k_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['k_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['k_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['k_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['k_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['k_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['k_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['o_proj'], accessed_by=DictGetItemGuardAccessor('o_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['o_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['o_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['o_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['o_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['o_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['o_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['o_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['o_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['o_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['q_proj'], accessed_by=DictGetItemGuardAccessor('q_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['q_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['q_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['q_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['q_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['q_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['q_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['q_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['q_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['q_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['v_proj'], accessed_by=DictGetItemGuardAccessor('v_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['v_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['v_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['v_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['v_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['v_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['v_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['v_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['v_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._modules['v_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn'].head_dim, accessed_by=DictGetItemGuardAccessor('head_dim')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn'].head_dim == 128
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn'].training, accessed_by=DictGetItemGuardAccessor('training')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn'].training, 21370824)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn'].layer_idx, accessed_by=DictGetItemGuardAccessor('layer_idx')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn'].layer_idx == 23
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn']._parameters, 21447360)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn'].num_key_value_groups, accessed_by=DictGetItemGuardAccessor('num_key_value_groups')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn'].num_key_value_groups == 4
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn'].config, accessed_by=DictGetItemGuardAccessor('config')
| | | | | | | | | | | | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['23']._modules['self_attn'].config
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['input_layernorm'], accessed_by=DictGetItemGuardAccessor('input_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['input_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['input_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['23']._modules['input_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['input_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['23']._modules['input_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['input_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['input_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['input_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['input_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['input_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['input_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['input_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['23']._modules['input_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['input_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['input_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['23']._modules['input_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['input_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['23']._modules['input_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['post_attention_layernorm'], accessed_by=DictGetItemGuardAccessor('post_attention_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['post_attention_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['post_attention_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['23']._modules['post_attention_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['post_attention_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['23']._modules['post_attention_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['post_attention_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['post_attention_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['post_attention_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['post_attention_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['post_attention_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['23']._modules['post_attention_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['post_attention_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['23']._modules['post_attention_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['post_attention_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['post_attention_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['23']._modules['post_attention_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._modules['post_attention_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['23']._modules['post_attention_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['23']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['23']._parameters, 21447360)
| | | | | | | | | | +- KeyValueManager pair at index=24
| | | | | | | | | | | +- KeyManager: GuardManager: source=list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[24]
| | | | | | | | | | | | +- EQUALS_MATCH: list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[24] == '24'
| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']
| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['24'], 866524544)
| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['24'].__dict__)
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['24']._modules, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp'], accessed_by=DictGetItemGuardAccessor('mlp')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp'], 866551056)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['act_fn'], accessed_by=DictGetItemGuardAccessor('act_fn')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['act_fn'], 805311888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['act_fn'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['act_fn'].inplace, accessed_by=DictGetItemGuardAccessor('inplace')
| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['act_fn'].inplace, 21370824)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['up_proj'], accessed_by=DictGetItemGuardAccessor('up_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['up_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['up_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['up_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['up_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['up_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['up_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['up_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['up_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['up_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['down_proj'], accessed_by=DictGetItemGuardAccessor('down_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['down_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['down_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['down_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['down_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['down_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['down_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['down_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['down_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['down_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 14336], stride=[14336, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['gate_proj'], accessed_by=DictGetItemGuardAccessor('gate_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['gate_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['gate_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['gate_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['gate_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['gate_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['gate_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['gate_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['gate_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._modules['gate_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['mlp']._parameters, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn'], accessed_by=DictGetItemGuardAccessor('self_attn')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn'], 866522768)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn'].scaling, accessed_by=DictGetItemGuardAccessor('scaling')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn'].scaling == 0.08838834764831845
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['k_proj'], accessed_by=DictGetItemGuardAccessor('k_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['k_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['k_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['k_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['k_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['k_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['k_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['k_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['k_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['k_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['o_proj'], accessed_by=DictGetItemGuardAccessor('o_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['o_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['o_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['o_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['o_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['o_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['o_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['o_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['o_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['o_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['q_proj'], accessed_by=DictGetItemGuardAccessor('q_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['q_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['q_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['q_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['q_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['q_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['q_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['q_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['q_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['q_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['v_proj'], accessed_by=DictGetItemGuardAccessor('v_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['v_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['v_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['v_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['v_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['v_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['v_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['v_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['v_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._modules['v_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn'].head_dim, accessed_by=DictGetItemGuardAccessor('head_dim')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn'].head_dim == 128
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn'].training, accessed_by=DictGetItemGuardAccessor('training')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn'].training, 21370824)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn'].layer_idx, accessed_by=DictGetItemGuardAccessor('layer_idx')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn'].layer_idx == 24
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn']._parameters, 21447360)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn'].num_key_value_groups, accessed_by=DictGetItemGuardAccessor('num_key_value_groups')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn'].num_key_value_groups == 4
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn'].config, accessed_by=DictGetItemGuardAccessor('config')
| | | | | | | | | | | | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['24']._modules['self_attn'].config
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['input_layernorm'], accessed_by=DictGetItemGuardAccessor('input_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['input_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['input_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['24']._modules['input_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['input_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['24']._modules['input_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['input_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['input_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['input_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['input_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['input_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['input_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['input_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['24']._modules['input_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['input_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['input_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['24']._modules['input_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['input_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['24']._modules['input_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['post_attention_layernorm'], accessed_by=DictGetItemGuardAccessor('post_attention_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['post_attention_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['post_attention_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['24']._modules['post_attention_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['post_attention_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['24']._modules['post_attention_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['post_attention_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['post_attention_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['post_attention_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['post_attention_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['post_attention_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['24']._modules['post_attention_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['post_attention_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['24']._modules['post_attention_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['post_attention_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['post_attention_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['24']._modules['post_attention_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._modules['post_attention_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['24']._modules['post_attention_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['24']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['24']._parameters, 21447360)
| | | | | | | | | | +- KeyValueManager pair at index=25
| | | | | | | | | | | +- KeyManager: GuardManager: source=list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[25]
| | | | | | | | | | | | +- EQUALS_MATCH: list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[25] == '25'
| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']
| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['25'], 866524544)
| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['25'].__dict__)
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['25']._modules, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp'], accessed_by=DictGetItemGuardAccessor('mlp')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp'], 866551056)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['act_fn'], accessed_by=DictGetItemGuardAccessor('act_fn')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['act_fn'], 805311888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['act_fn'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['act_fn'].inplace, accessed_by=DictGetItemGuardAccessor('inplace')
| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['act_fn'].inplace, 21370824)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['up_proj'], accessed_by=DictGetItemGuardAccessor('up_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['up_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['up_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['up_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['up_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['up_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['up_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['up_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['up_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['up_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['down_proj'], accessed_by=DictGetItemGuardAccessor('down_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['down_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['down_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['down_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['down_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['down_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['down_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['down_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['down_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['down_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 14336], stride=[14336, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['gate_proj'], accessed_by=DictGetItemGuardAccessor('gate_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['gate_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['gate_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['gate_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['gate_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['gate_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['gate_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['gate_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['gate_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._modules['gate_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['mlp']._parameters, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn'], accessed_by=DictGetItemGuardAccessor('self_attn')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn'], 866522768)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn'].scaling, accessed_by=DictGetItemGuardAccessor('scaling')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn'].scaling == 0.08838834764831845
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['k_proj'], accessed_by=DictGetItemGuardAccessor('k_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['k_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['k_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['k_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['k_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['k_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['k_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['k_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['k_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['k_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['o_proj'], accessed_by=DictGetItemGuardAccessor('o_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['o_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['o_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['o_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['o_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['o_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['o_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['o_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['o_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['o_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['q_proj'], accessed_by=DictGetItemGuardAccessor('q_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['q_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['q_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['q_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['q_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['q_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['q_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['q_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['q_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['q_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['v_proj'], accessed_by=DictGetItemGuardAccessor('v_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['v_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['v_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['v_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['v_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['v_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['v_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['v_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['v_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._modules['v_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn'].head_dim, accessed_by=DictGetItemGuardAccessor('head_dim')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn'].head_dim == 128
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn'].training, accessed_by=DictGetItemGuardAccessor('training')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn'].training, 21370824)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn'].layer_idx, accessed_by=DictGetItemGuardAccessor('layer_idx')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn'].layer_idx == 25
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn']._parameters, 21447360)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn'].num_key_value_groups, accessed_by=DictGetItemGuardAccessor('num_key_value_groups')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn'].num_key_value_groups == 4
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn'].config, accessed_by=DictGetItemGuardAccessor('config')
| | | | | | | | | | | | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['25']._modules['self_attn'].config
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['input_layernorm'], accessed_by=DictGetItemGuardAccessor('input_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['input_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['input_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['25']._modules['input_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['input_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['25']._modules['input_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['input_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['input_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['input_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['input_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['input_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['input_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['input_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['25']._modules['input_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['input_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['input_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['25']._modules['input_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['input_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['25']._modules['input_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['post_attention_layernorm'], accessed_by=DictGetItemGuardAccessor('post_attention_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['post_attention_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['post_attention_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['25']._modules['post_attention_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['post_attention_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['25']._modules['post_attention_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['post_attention_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['post_attention_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['post_attention_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['post_attention_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['post_attention_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['25']._modules['post_attention_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['post_attention_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['25']._modules['post_attention_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['post_attention_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['post_attention_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['25']._modules['post_attention_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._modules['post_attention_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['25']._modules['post_attention_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['25']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['25']._parameters, 21447360)
| | | | | | | | | | +- KeyValueManager pair at index=26
| | | | | | | | | | | +- KeyManager: GuardManager: source=list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[26]
| | | | | | | | | | | | +- EQUALS_MATCH: list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[26] == '26'
| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']
| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['26'], 866524544)
| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['26'].__dict__)
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['26']._modules, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp'], accessed_by=DictGetItemGuardAccessor('mlp')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp'], 866551056)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['act_fn'], accessed_by=DictGetItemGuardAccessor('act_fn')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['act_fn'], 805311888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['act_fn'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['act_fn'].inplace, accessed_by=DictGetItemGuardAccessor('inplace')
| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['act_fn'].inplace, 21370824)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['up_proj'], accessed_by=DictGetItemGuardAccessor('up_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['up_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['up_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['up_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['up_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['up_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['up_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['up_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['up_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['up_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['down_proj'], accessed_by=DictGetItemGuardAccessor('down_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['down_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['down_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['down_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['down_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['down_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['down_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['down_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['down_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['down_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 14336], stride=[14336, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['gate_proj'], accessed_by=DictGetItemGuardAccessor('gate_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['gate_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['gate_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['gate_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['gate_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['gate_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['gate_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['gate_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['gate_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._modules['gate_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['mlp']._parameters, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn'], accessed_by=DictGetItemGuardAccessor('self_attn')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn'], 866522768)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn'].scaling, accessed_by=DictGetItemGuardAccessor('scaling')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn'].scaling == 0.08838834764831845
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['k_proj'], accessed_by=DictGetItemGuardAccessor('k_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['k_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['k_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['k_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['k_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['k_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['k_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['k_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['k_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['k_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['o_proj'], accessed_by=DictGetItemGuardAccessor('o_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['o_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['o_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['o_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['o_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['o_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['o_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['o_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['o_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['o_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['q_proj'], accessed_by=DictGetItemGuardAccessor('q_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['q_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['q_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['q_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['q_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['q_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['q_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['q_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['q_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['q_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['v_proj'], accessed_by=DictGetItemGuardAccessor('v_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['v_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['v_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['v_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['v_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['v_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['v_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['v_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['v_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._modules['v_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn'].head_dim, accessed_by=DictGetItemGuardAccessor('head_dim')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn'].head_dim == 128
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn'].training, accessed_by=DictGetItemGuardAccessor('training')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn'].training, 21370824)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn'].layer_idx, accessed_by=DictGetItemGuardAccessor('layer_idx')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn'].layer_idx == 26
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn']._parameters, 21447360)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn'].num_key_value_groups, accessed_by=DictGetItemGuardAccessor('num_key_value_groups')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn'].num_key_value_groups == 4
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn'].config, accessed_by=DictGetItemGuardAccessor('config')
| | | | | | | | | | | | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['26']._modules['self_attn'].config
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['input_layernorm'], accessed_by=DictGetItemGuardAccessor('input_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['input_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['input_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['26']._modules['input_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['input_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['26']._modules['input_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['input_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['input_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['input_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['input_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['input_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['input_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['input_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['26']._modules['input_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['input_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['input_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['26']._modules['input_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['input_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['26']._modules['input_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['post_attention_layernorm'], accessed_by=DictGetItemGuardAccessor('post_attention_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['post_attention_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['post_attention_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['26']._modules['post_attention_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['post_attention_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['26']._modules['post_attention_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['post_attention_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['post_attention_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['post_attention_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['post_attention_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['post_attention_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['26']._modules['post_attention_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['post_attention_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['26']._modules['post_attention_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['post_attention_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['post_attention_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['26']._modules['post_attention_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._modules['post_attention_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['26']._modules['post_attention_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['26']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['26']._parameters, 21447360)
| | | | | | | | | | +- KeyValueManager pair at index=27
| | | | | | | | | | | +- KeyManager: GuardManager: source=list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[27]
| | | | | | | | | | | | +- EQUALS_MATCH: list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[27] == '27'
| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']
| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['27'], 866524544)
| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['27'].__dict__)
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['27']._modules, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp'], accessed_by=DictGetItemGuardAccessor('mlp')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp'], 866551056)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['act_fn'], accessed_by=DictGetItemGuardAccessor('act_fn')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['act_fn'], 805311888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['act_fn'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['act_fn'].inplace, accessed_by=DictGetItemGuardAccessor('inplace')
| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['act_fn'].inplace, 21370824)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['up_proj'], accessed_by=DictGetItemGuardAccessor('up_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['up_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['up_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['up_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['up_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['up_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['up_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['up_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['up_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['up_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['down_proj'], accessed_by=DictGetItemGuardAccessor('down_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['down_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['down_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['down_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['down_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['down_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['down_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['down_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['down_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['down_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 14336], stride=[14336, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['gate_proj'], accessed_by=DictGetItemGuardAccessor('gate_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['gate_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['gate_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['gate_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['gate_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['gate_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['gate_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['gate_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['gate_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._modules['gate_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['mlp']._parameters, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn'], accessed_by=DictGetItemGuardAccessor('self_attn')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn'], 866522768)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn'].scaling, accessed_by=DictGetItemGuardAccessor('scaling')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn'].scaling == 0.08838834764831845
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['k_proj'], accessed_by=DictGetItemGuardAccessor('k_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['k_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['k_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['k_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['k_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['k_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['k_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['k_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['k_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['k_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['o_proj'], accessed_by=DictGetItemGuardAccessor('o_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['o_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['o_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['o_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['o_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['o_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['o_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['o_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['o_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['o_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['q_proj'], accessed_by=DictGetItemGuardAccessor('q_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['q_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['q_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['q_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['q_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['q_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['q_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['q_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['q_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['q_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['v_proj'], accessed_by=DictGetItemGuardAccessor('v_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['v_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['v_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['v_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['v_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['v_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['v_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['v_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['v_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._modules['v_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn'].head_dim, accessed_by=DictGetItemGuardAccessor('head_dim')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn'].head_dim == 128
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn'].training, accessed_by=DictGetItemGuardAccessor('training')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn'].training, 21370824)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn'].layer_idx, accessed_by=DictGetItemGuardAccessor('layer_idx')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn'].layer_idx == 27
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn']._parameters, 21447360)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn'].num_key_value_groups, accessed_by=DictGetItemGuardAccessor('num_key_value_groups')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn'].num_key_value_groups == 4
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn'].config, accessed_by=DictGetItemGuardAccessor('config')
| | | | | | | | | | | | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['27']._modules['self_attn'].config
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['input_layernorm'], accessed_by=DictGetItemGuardAccessor('input_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['input_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['input_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['27']._modules['input_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['input_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['27']._modules['input_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['input_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['input_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['input_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['input_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['input_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['input_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['input_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['27']._modules['input_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['input_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['input_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['27']._modules['input_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['input_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['27']._modules['input_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['post_attention_layernorm'], accessed_by=DictGetItemGuardAccessor('post_attention_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['post_attention_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['post_attention_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['27']._modules['post_attention_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['post_attention_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['27']._modules['post_attention_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['post_attention_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['post_attention_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['post_attention_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['post_attention_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['post_attention_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['27']._modules['post_attention_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['post_attention_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['27']._modules['post_attention_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['post_attention_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['post_attention_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['27']._modules['post_attention_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._modules['post_attention_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['27']._modules['post_attention_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['27']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['27']._parameters, 21447360)
| | | | | | | | | | +- KeyValueManager pair at index=28
| | | | | | | | | | | +- KeyManager: GuardManager: source=list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[28]
| | | | | | | | | | | | +- EQUALS_MATCH: list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[28] == '28'
| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']
| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['28'], 866524544)
| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['28'].__dict__)
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['28']._modules, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp'], accessed_by=DictGetItemGuardAccessor('mlp')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp'], 866551056)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['act_fn'], accessed_by=DictGetItemGuardAccessor('act_fn')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['act_fn'], 805311888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['act_fn'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['act_fn'].inplace, accessed_by=DictGetItemGuardAccessor('inplace')
| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['act_fn'].inplace, 21370824)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['up_proj'], accessed_by=DictGetItemGuardAccessor('up_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['up_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['up_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['up_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['up_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['up_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['up_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['up_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['up_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['up_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['down_proj'], accessed_by=DictGetItemGuardAccessor('down_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['down_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['down_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['down_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['down_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['down_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['down_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['down_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['down_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['down_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 14336], stride=[14336, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['gate_proj'], accessed_by=DictGetItemGuardAccessor('gate_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['gate_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['gate_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['gate_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['gate_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['gate_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['gate_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['gate_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['gate_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._modules['gate_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['mlp']._parameters, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn'], accessed_by=DictGetItemGuardAccessor('self_attn')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn'], 866522768)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn'].scaling, accessed_by=DictGetItemGuardAccessor('scaling')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn'].scaling == 0.08838834764831845
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['k_proj'], accessed_by=DictGetItemGuardAccessor('k_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['k_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['k_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['k_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['k_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['k_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['k_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['k_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['k_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['k_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['o_proj'], accessed_by=DictGetItemGuardAccessor('o_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['o_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['o_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['o_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['o_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['o_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['o_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['o_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['o_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['o_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['q_proj'], accessed_by=DictGetItemGuardAccessor('q_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['q_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['q_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['q_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['q_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['q_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['q_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['q_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['q_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['q_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['v_proj'], accessed_by=DictGetItemGuardAccessor('v_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['v_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['v_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['v_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['v_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['v_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['v_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['v_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['v_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._modules['v_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn'].head_dim, accessed_by=DictGetItemGuardAccessor('head_dim')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn'].head_dim == 128
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn'].training, accessed_by=DictGetItemGuardAccessor('training')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn'].training, 21370824)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn'].layer_idx, accessed_by=DictGetItemGuardAccessor('layer_idx')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn'].layer_idx == 28
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn']._parameters, 21447360)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn'].num_key_value_groups, accessed_by=DictGetItemGuardAccessor('num_key_value_groups')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn'].num_key_value_groups == 4
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn'].config, accessed_by=DictGetItemGuardAccessor('config')
| | | | | | | | | | | | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['28']._modules['self_attn'].config
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['input_layernorm'], accessed_by=DictGetItemGuardAccessor('input_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['input_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['input_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['28']._modules['input_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['input_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['28']._modules['input_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['input_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['input_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['input_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['input_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['input_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['input_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['input_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['28']._modules['input_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['input_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['input_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['28']._modules['input_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['input_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['28']._modules['input_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['post_attention_layernorm'], accessed_by=DictGetItemGuardAccessor('post_attention_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['post_attention_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['post_attention_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['28']._modules['post_attention_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['post_attention_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['28']._modules['post_attention_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['post_attention_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['post_attention_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['post_attention_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['post_attention_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['post_attention_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['28']._modules['post_attention_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['post_attention_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['28']._modules['post_attention_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['post_attention_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['post_attention_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['28']._modules['post_attention_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._modules['post_attention_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['28']._modules['post_attention_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['28']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['28']._parameters, 21447360)
| | | | | | | | | | +- KeyValueManager pair at index=29
| | | | | | | | | | | +- KeyManager: GuardManager: source=list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[29]
| | | | | | | | | | | | +- EQUALS_MATCH: list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[29] == '29'
| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']
| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['29'], 866524544)
| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['29'].__dict__)
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['29']._modules, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp'], accessed_by=DictGetItemGuardAccessor('mlp')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp'], 866551056)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['act_fn'], accessed_by=DictGetItemGuardAccessor('act_fn')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['act_fn'], 805311888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['act_fn'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['act_fn'].inplace, accessed_by=DictGetItemGuardAccessor('inplace')
| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['act_fn'].inplace, 21370824)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['up_proj'], accessed_by=DictGetItemGuardAccessor('up_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['up_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['up_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['up_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['up_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['up_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['up_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['up_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['up_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['up_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['down_proj'], accessed_by=DictGetItemGuardAccessor('down_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['down_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['down_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['down_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['down_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['down_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['down_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['down_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['down_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['down_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 14336], stride=[14336, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['gate_proj'], accessed_by=DictGetItemGuardAccessor('gate_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['gate_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['gate_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['gate_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['gate_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['gate_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['gate_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['gate_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['gate_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._modules['gate_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['mlp']._parameters, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn'], accessed_by=DictGetItemGuardAccessor('self_attn')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn'], 866522768)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn'].scaling, accessed_by=DictGetItemGuardAccessor('scaling')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn'].scaling == 0.08838834764831845
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['k_proj'], accessed_by=DictGetItemGuardAccessor('k_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['k_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['k_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['k_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['k_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['k_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['k_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['k_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['k_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['k_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['o_proj'], accessed_by=DictGetItemGuardAccessor('o_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['o_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['o_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['o_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['o_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['o_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['o_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['o_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['o_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['o_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['q_proj'], accessed_by=DictGetItemGuardAccessor('q_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['q_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['q_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['q_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['q_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['q_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['q_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['q_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['q_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['q_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['v_proj'], accessed_by=DictGetItemGuardAccessor('v_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['v_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['v_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['v_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['v_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['v_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['v_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['v_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['v_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._modules['v_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn'].head_dim, accessed_by=DictGetItemGuardAccessor('head_dim')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn'].head_dim == 128
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn'].training, accessed_by=DictGetItemGuardAccessor('training')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn'].training, 21370824)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn'].layer_idx, accessed_by=DictGetItemGuardAccessor('layer_idx')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn'].layer_idx == 29
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn']._parameters, 21447360)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn'].num_key_value_groups, accessed_by=DictGetItemGuardAccessor('num_key_value_groups')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn'].num_key_value_groups == 4
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn'].config, accessed_by=DictGetItemGuardAccessor('config')
| | | | | | | | | | | | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['29']._modules['self_attn'].config
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['input_layernorm'], accessed_by=DictGetItemGuardAccessor('input_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['input_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['input_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['29']._modules['input_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['input_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['29']._modules['input_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['input_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['input_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['input_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['input_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['input_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['input_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['input_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['29']._modules['input_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['input_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['input_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['29']._modules['input_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['input_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['29']._modules['input_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['post_attention_layernorm'], accessed_by=DictGetItemGuardAccessor('post_attention_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['post_attention_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['post_attention_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['29']._modules['post_attention_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['post_attention_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['29']._modules['post_attention_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['post_attention_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['post_attention_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['post_attention_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['post_attention_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['post_attention_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['29']._modules['post_attention_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['post_attention_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['29']._modules['post_attention_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['post_attention_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['post_attention_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['29']._modules['post_attention_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._modules['post_attention_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['29']._modules['post_attention_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['29']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['29']._parameters, 21447360)
| | | | | | | | | | +- KeyValueManager pair at index=30
| | | | | | | | | | | +- KeyManager: GuardManager: source=list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[30]
| | | | | | | | | | | | +- EQUALS_MATCH: list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[30] == '30'
| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']
| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['30'], 866524544)
| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['30'].__dict__)
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['30']._modules, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp'], accessed_by=DictGetItemGuardAccessor('mlp')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp'], 866551056)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['act_fn'], accessed_by=DictGetItemGuardAccessor('act_fn')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['act_fn'], 805311888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['act_fn'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['act_fn'].inplace, accessed_by=DictGetItemGuardAccessor('inplace')
| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['act_fn'].inplace, 21370824)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['up_proj'], accessed_by=DictGetItemGuardAccessor('up_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['up_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['up_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['up_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['up_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['up_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['up_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['up_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['up_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['up_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['down_proj'], accessed_by=DictGetItemGuardAccessor('down_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['down_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['down_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['down_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['down_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['down_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['down_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['down_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['down_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['down_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 14336], stride=[14336, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['gate_proj'], accessed_by=DictGetItemGuardAccessor('gate_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['gate_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['gate_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['gate_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['gate_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['gate_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['gate_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['gate_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['gate_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._modules['gate_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['mlp']._parameters, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn'], accessed_by=DictGetItemGuardAccessor('self_attn')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn'], 866522768)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn'].scaling, accessed_by=DictGetItemGuardAccessor('scaling')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn'].scaling == 0.08838834764831845
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['k_proj'], accessed_by=DictGetItemGuardAccessor('k_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['k_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['k_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['k_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['k_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['k_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['k_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['k_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['k_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['k_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['o_proj'], accessed_by=DictGetItemGuardAccessor('o_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['o_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['o_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['o_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['o_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['o_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['o_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['o_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['o_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['o_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['q_proj'], accessed_by=DictGetItemGuardAccessor('q_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['q_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['q_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['q_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['q_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['q_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['q_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['q_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['q_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['q_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['v_proj'], accessed_by=DictGetItemGuardAccessor('v_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['v_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['v_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['v_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['v_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['v_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['v_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['v_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['v_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._modules['v_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn'].head_dim, accessed_by=DictGetItemGuardAccessor('head_dim')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn'].head_dim == 128
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn'].training, accessed_by=DictGetItemGuardAccessor('training')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn'].training, 21370824)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn'].layer_idx, accessed_by=DictGetItemGuardAccessor('layer_idx')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn'].layer_idx == 30
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn']._parameters, 21447360)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn'].num_key_value_groups, accessed_by=DictGetItemGuardAccessor('num_key_value_groups')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn'].num_key_value_groups == 4
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn'].config, accessed_by=DictGetItemGuardAccessor('config')
| | | | | | | | | | | | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['30']._modules['self_attn'].config
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['input_layernorm'], accessed_by=DictGetItemGuardAccessor('input_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['input_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['input_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['30']._modules['input_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['input_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['30']._modules['input_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['input_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['input_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['input_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['input_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['input_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['input_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['input_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['30']._modules['input_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['input_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['input_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['30']._modules['input_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['input_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['30']._modules['input_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['post_attention_layernorm'], accessed_by=DictGetItemGuardAccessor('post_attention_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['post_attention_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['post_attention_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['30']._modules['post_attention_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['post_attention_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['30']._modules['post_attention_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['post_attention_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['post_attention_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['post_attention_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['post_attention_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['post_attention_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['30']._modules['post_attention_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['post_attention_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['30']._modules['post_attention_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['post_attention_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['post_attention_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['30']._modules['post_attention_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._modules['post_attention_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['30']._modules['post_attention_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['30']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['30']._parameters, 21447360)
| | | | | | | | | | +- KeyValueManager pair at index=31
| | | | | | | | | | | +- KeyManager: GuardManager: source=list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[31]
| | | | | | | | | | | | +- EQUALS_MATCH: list(dict.keys(L['self']._modules['model']._modules['layers']._modules))[31] == '31'
| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']
| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['31'], 866524544)
| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['31'].__dict__)
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['31']._modules, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp'], accessed_by=DictGetItemGuardAccessor('mlp')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp'], 866551056)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['act_fn'], accessed_by=DictGetItemGuardAccessor('act_fn')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['act_fn'], 805311888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['act_fn'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['act_fn'].inplace, accessed_by=DictGetItemGuardAccessor('inplace')
| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['act_fn'].inplace, 21370824)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['up_proj'], accessed_by=DictGetItemGuardAccessor('up_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['up_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['up_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['up_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['up_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['up_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['up_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['up_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['up_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['up_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['down_proj'], accessed_by=DictGetItemGuardAccessor('down_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['down_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['down_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['down_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['down_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['down_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['down_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['down_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['down_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['down_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 14336], stride=[14336, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['gate_proj'], accessed_by=DictGetItemGuardAccessor('gate_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['gate_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['gate_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['gate_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['gate_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['gate_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['gate_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['gate_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['gate_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._modules['gate_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[14336, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['mlp']._parameters, 21447360)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn'], accessed_by=DictGetItemGuardAccessor('self_attn')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn'], 866522768)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn'].scaling, accessed_by=DictGetItemGuardAccessor('scaling')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn'].scaling == 0.08838834764831845
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['k_proj'], accessed_by=DictGetItemGuardAccessor('k_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['k_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['k_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['k_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['k_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['k_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['k_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['k_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['k_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['k_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['o_proj'], accessed_by=DictGetItemGuardAccessor('o_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['o_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['o_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['o_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['o_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['o_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['o_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['o_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['o_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['o_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['q_proj'], accessed_by=DictGetItemGuardAccessor('q_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['q_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['q_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['q_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['q_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['q_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['q_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['q_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['q_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['q_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['v_proj'], accessed_by=DictGetItemGuardAccessor('v_proj')
| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['v_proj'], 805673888)
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['v_proj'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['v_proj'].__dict__)
| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['v_proj']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['v_proj']._parameters, 21447360)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['v_proj']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['v_proj']._parameters['bias'], 21458960)
| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['v_proj']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._modules['v_proj']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[1024, 4096], stride=[4096, 1])
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn'].head_dim, accessed_by=DictGetItemGuardAccessor('head_dim')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn'].head_dim == 128
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn'].training, accessed_by=DictGetItemGuardAccessor('training')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn'].training, 21370824)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn'].layer_idx, accessed_by=DictGetItemGuardAccessor('layer_idx')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn'].layer_idx == 31
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn']._parameters, 21447360)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn'].num_key_value_groups, accessed_by=DictGetItemGuardAccessor('num_key_value_groups')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn'].num_key_value_groups == 4
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn'].config, accessed_by=DictGetItemGuardAccessor('config')
| | | | | | | | | | | | | | | | | +- OBJECT_ALIASING: L['self']._modules['model'].config is L['self']._modules['model']._modules['layers']._modules['31']._modules['self_attn'].config
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['input_layernorm'], accessed_by=DictGetItemGuardAccessor('input_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['input_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['input_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['31']._modules['input_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['input_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['31']._modules['input_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['input_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['input_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['input_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['input_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['input_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['input_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['input_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['31']._modules['input_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['input_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['input_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['31']._modules['input_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['input_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['31']._modules['input_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['post_attention_layernorm'], accessed_by=DictGetItemGuardAccessor('post_attention_layernorm')
| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['post_attention_layernorm'], 865890160)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['post_attention_layernorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['layers']._modules['31']._modules['post_attention_layernorm'].__dict__)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['post_attention_layernorm'].offset, accessed_by=DictGetItemGuardAccessor('offset')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['31']._modules['post_attention_layernorm'].offset == 0.0
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['post_attention_layernorm'].in_place, accessed_by=DictGetItemGuardAccessor('in_place')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['post_attention_layernorm'].in_place, 21370792)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['post_attention_layernorm'].row_mode, accessed_by=DictGetItemGuardAccessor('row_mode')
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['post_attention_layernorm'].row_mode, 21458960)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['post_attention_layernorm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['31']._modules['post_attention_layernorm']._parameters, 21447360)
| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['post_attention_layernorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['layers']._modules['31']._modules['post_attention_layernorm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[4096], stride=[1])
| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['post_attention_layernorm']._parameters['weight'].contiguous, accessed_by=GetAttrGuardAccessor(contiguous)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['post_attention_layernorm'].casting_mode, accessed_by=DictGetItemGuardAccessor('casting_mode')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['31']._modules['post_attention_layernorm'].casting_mode == 'llama'
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._modules['post_attention_layernorm'].variance_epsilon, accessed_by=DictGetItemGuardAccessor('variance_epsilon')
| | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['layers']._modules['31']._modules['post_attention_layernorm'].variance_epsilon == 1e-05
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['layers']._modules['31']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['layers']._modules['31']._parameters, 21447360)
| | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['rotary_emb'], accessed_by=DictGetItemGuardAccessor('rotary_emb')
| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['rotary_emb'], 866137360)
| | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['rotary_emb'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['rotary_emb'].__dict__)
| | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['rotary_emb']._buffers, accessed_by=DictGetItemGuardAccessor('_buffers')
| | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['rotary_emb']._buffers, 21447360)
| | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['rotary_emb']._buffers['inv_freq'], accessed_by=DictGetItemGuardAccessor('inv_freq')
| | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['rotary_emb']._buffers['inv_freq'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float32, device=0, requires_grad=False, size=[64], stride=[1])
| | | | | | | | | | | +- NO_TENSOR_ALIASING: check_no_aliasing(L['input_ids'], L['position_ids'], L['attention_mask'], L['cache_position'], L['past_key_values'].layers[0].keys, L['past_key_values'].layers[1].keys, L['past_key_values'].layers[2].keys, L['past_key_values'].layers[3].keys, L['past_key_values'].layers[4].keys, L['past_key_values'].layers[5].keys, L['past_key_values'].layers[6].keys, L['past_key_values'].layers[7].keys, L['past_key_values'].layers[8].keys, L['past_key_values'].layers[9].keys, L['past_key_values'].layers[10].keys, L['past_key_values'].layers[11].keys, L['past_key_values'].layers[12].keys, L['past_key_values'].layers[13].keys, L['past_key_values'].layers[14].keys, L['past_key_values'].layers[15].keys, L['past_key_values'].layers[16].keys, L['past_key_values'].layers[17].keys, L['past_key_values'].layers[18].keys, L['past_key_values'].layers[19].keys, L['past_key_values'].layers[20].keys, L['past_key_values'].layers[21].keys, L['past_key_values'].layers[22].keys, L['past_key_values'].layers[23].keys, L['past_key_values'].layers[24].keys, L['past_key_values'].layers[25].keys, L['past_key_values'].layers[26].keys, L['past_key_values'].layers[27].keys, L['past_key_values'].layers[28].keys, L['past_key_values'].layers[29].keys, L['past_key_values'].layers[30].keys, L['past_key_values'].layers[31].keys, L['past_key_values'].layers[0].values, L['past_key_values'].layers[1].values, L['past_key_values'].layers[2].values, L['past_key_values'].layers[3].values, L['past_key_values'].layers[4].values, L['past_key_values'].layers[5].values, L['past_key_values'].layers[6].values, L['past_key_values'].layers[7].values, L['past_key_values'].layers[8].values, L['past_key_values'].layers[9].values, L['past_key_values'].layers[10].values, L['past_key_values'].layers[11].values, L['past_key_values'].layers[12].values, L['past_key_values'].layers[13].values, L['past_key_values'].layers[14].values, L['past_key_values'].layers[15].values, L['past_key_values'].layers[16].values, L['past_key_values'].layers[17].values, L['past_key_values'].layers[18].values, L['past_key_values'].layers[19].values, L['past_key_values'].layers[20].values, L['past_key_values'].layers[21].values, L['past_key_values'].layers[22].values, L['past_key_values'].layers[23].values, L['past_key_values'].layers[24].values, L['past_key_values'].layers[25].values, L['past_key_values'].layers[26].values, L['past_key_values'].layers[27].values, L['past_key_values'].layers[28].values, L['past_key_values'].layers[29].values, L['past_key_values'].layers[30].values, L['past_key_values'].layers[31].values, L['self']._modules['model']._modules['rotary_emb']._buffers['inv_freq'])
| | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['rotary_emb']._modules, accessed_by=DictGetItemGuardAccessor('_modules')
| | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['rotary_emb']._modules, 21447360)
| | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['rotary_emb'].rope_type, accessed_by=DictGetItemGuardAccessor('rope_type')
| | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['rotary_emb'].rope_type == 'llama3'
| | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['rotary_emb']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['rotary_emb']._parameters, 21447360)
| | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['rotary_emb'].attention_scaling, accessed_by=DictGetItemGuardAccessor('attention_scaling')
| | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['rotary_emb'].attention_scaling == 1.0
| | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['rotary_emb'].__class__, accessed_by=GetAttrGuardAccessor(__class__)
| | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['rotary_emb'].__class__.forward, accessed_by=GetAttrGuardAccessor(forward)
| | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['rotary_emb'].__class__.forward.__closure__, accessed_by=GetAttrGuardAccessor(__closure__)
| | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['rotary_emb'].__class__.forward.__closure__[0], accessed_by=TupleGetItemGuardAccessor(0)
| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['rotary_emb'].__class__.forward.__closure__[0].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents)
| | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['rotary_emb'].__class__.forward.__closure__[0].cell_contents, 21380576)
| | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['rotary_emb'].__class__.forward.__closure__[1], accessed_by=TupleGetItemGuardAccessor(1)
| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['rotary_emb'].__class__.forward.__closure__[1].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents)
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['rotary_emb'].__class__.forward.__closure__[1].cell_contents.__code__, accessed_by=GetAttrGuardAccessor(__code__)
| | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['rotary_emb'].__class__.forward.__closure__[1].cell_contents.__code__, 131212301590848)
| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['rotary_emb'].__class__.forward.__closure__[1].cell_contents.__closure__, accessed_by=GetAttrGuardAccessor(__closure__)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['rotary_emb'].__class__.forward.__closure__[1].cell_contents.__closure__[0], accessed_by=TupleGetItemGuardAccessor(0)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['rotary_emb'].__class__.forward.__closure__[1].cell_contents.__closure__[0].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['rotary_emb'].__class__.forward.__closure__[1].cell_contents.__closure__[0].cell_contents.__code__, accessed_by=GetAttrGuardAccessor(__code__)
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['rotary_emb'].__class__.forward.__closure__[1].cell_contents.__closure__[0].cell_contents.__code__, 866555104)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['rotary_emb'].__class__.forward.__closure__[1].cell_contents.__closure__[1], accessed_by=TupleGetItemGuardAccessor(1)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['rotary_emb'].__class__.forward.__closure__[1].cell_contents.__closure__[1].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['rotary_emb'].__class__.forward.__closure__[1].cell_contents.__closure__[1].cell_contents.__code__, accessed_by=GetAttrGuardAccessor(__code__)
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['rotary_emb'].__class__.forward.__closure__[1].cell_contents.__closure__[1].cell_contents.__code__, 866267568)
| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['rotary_emb'].__class__.forward.__closure__[1].cell_contents.__closure__[2], accessed_by=TupleGetItemGuardAccessor(2)
| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['rotary_emb'].__class__.forward.__closure__[1].cell_contents.__closure__[2].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents)
| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['rotary_emb'].__class__.forward.__closure__[1].cell_contents.__closure__[2].cell_contents.__code__, accessed_by=GetAttrGuardAccessor(__code__)
| | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['rotary_emb'].__class__.forward.__closure__[1].cell_contents.__closure__[2].cell_contents.__code__, 829768464)
| | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['embed_tokens'], accessed_by=DictGetItemGuardAccessor('embed_tokens')
| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['embed_tokens'], 806935360)
| | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['embed_tokens'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['model']._modules['embed_tokens'].__dict__)
| | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['embed_tokens'].sparse, accessed_by=DictGetItemGuardAccessor('sparse')
| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['embed_tokens'].sparse, 21370824)
| | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['embed_tokens'].max_norm, accessed_by=DictGetItemGuardAccessor('max_norm')
| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['embed_tokens'].max_norm, 21458960)
| | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['embed_tokens'].norm_type, accessed_by=DictGetItemGuardAccessor('norm_type')
| | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['embed_tokens'].norm_type == 2.0
| | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['embed_tokens']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._modules['embed_tokens']._parameters, 21447360)
| | | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['embed_tokens']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['model']._modules['embed_tokens']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[128256, 4096], stride=[4096, 1])
| | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['embed_tokens'].padding_idx, accessed_by=DictGetItemGuardAccessor('padding_idx')
| | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['model']._modules['embed_tokens'].padding_idx == 128004
| | | | | | | | | +- GuardManager: source=L['self']._modules['model']._modules['embed_tokens'].scale_grad_by_freq, accessed_by=DictGetItemGuardAccessor('scale_grad_by_freq')
| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['model']._modules['embed_tokens'].scale_grad_by_freq, 21370824)
| | | | | | +- GuardManager: source=L['self']._modules['model']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['model']._parameters, 21447360)
| | | | +- GuardManager: source=L['self']._modules['lm_head'], accessed_by=DictGetItemGuardAccessor('lm_head')
| | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['lm_head'], 805673888)  
| | | | | +- GuardManager: source=L['self']._modules['lm_head'].__dict__, accessed_by=GetGenericDictGuardAccessor
| | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['lm_head'].__dict__)
| | | | | | +- GuardManager: source=L['self']._modules['lm_head']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['lm_head']._parameters, 21447360)
| | | | | | | +- GuardManager: source=L['self']._modules['lm_head']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias')
| | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['lm_head']._parameters['bias'], 21458960)
| | | | | | | +- GuardManager: source=L['self']._modules['lm_head']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight')
| | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['lm_head']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView), torch.float16, device=0, requires_grad=True, size=[128256, 4096], stride=[4096, 1])
| | | +- GuardManager: source=L['self']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters')
| | | | +- TYPE_MATCH: ___check_type_id(L['self']._parameters, 21447360)           
| +- GuardManager: source=L['kwargs'], accessed_by=FrameLocalsGuardAccessor(key='kwargs', framelocals_idx=10)
| | +- TYPE_MATCH: ___check_type_id(L['kwargs'], 21447360)                     
| | +- DICT_LENGTH: len(L['kwargs']) == 1                                       
| | +- GuardManager: source=L['kwargs']['return_dict'], accessed_by=DictGetItemGuardAccessor('return_dict')
| +- GuardManager: source=L['labels'], accessed_by=FrameLocalsGuardAccessor(key='labels', framelocals_idx=6)
| | +- ID_MATCH: ___check_obj_id(L['labels'], 21458960)                      
| +- GuardManager: source=L['input_ids'], accessed_by=FrameLocalsGuardAccessor(key='input_ids', framelocals_idx=1)
| | +- TENSOR_MATCH: check_tensor(L['input_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect), torch.int64, device=0, requires_grad=False, size=[1, None], stride=[None, 1])
| | +- NO_HASATTR: hasattr(L['input_ids'], '_dynamo_dynamic_indices') == False 
| | +- NO_TENSOR_ALIASING
| +- GuardManager: source=L['use_cache'], accessed_by=FrameLocalsGuardAccessor(key='use_cache', framelocals_idx=7)
| | +- ID_MATCH: ___check_obj_id(L['use_cache'], 21370792)                   
| +- GuardManager: source=L['position_ids'], accessed_by=FrameLocalsGuardAccessor(key='position_ids', framelocals_idx=3)
| | +- TYPE_MATCH: ___check_type_id(L['position_ids'], 798132240)              
| | +- TENSOR_MATCH: check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect), torch.int64, device=0, requires_grad=False, size=[1, None], stride=[None, 1])
| | +- NO_HASATTR: hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False
| | +- NO_TENSOR_ALIASING
| +- GuardManager: source=L['inputs_embeds'], accessed_by=FrameLocalsGuardAccessor(key='inputs_embeds', framelocals_idx=5)
| | +- ID_MATCH: ___check_obj_id(L['inputs_embeds'], 21458960)               
| +- GuardManager: source=L['attention_mask'], accessed_by=FrameLocalsGuardAccessor(key='attention_mask', framelocals_idx=2)
| | +- TYPE_MATCH: ___check_type_id(L['attention_mask'], 798132240)            
| | +- TENSOR_MATCH: check_tensor(L['attention_mask'], Tensor, DispatchKeySet(CUDA, BackendSelect), torch.bool, device=0, requires_grad=False, size=[1, 1, None, None], stride=[None, None, None, 1])
| | +- NO_HASATTR: hasattr(L['attention_mask'], '_dynamo_dynamic_indices') == False
| | +- NO_TENSOR_ALIASING
| +- GuardManager: source=L['cache_position'], accessed_by=FrameLocalsGuardAccessor(key='cache_position', framelocals_idx=8)
| | +- TENSOR_MATCH: check_tensor(L['cache_position'], Tensor, DispatchKeySet(CUDA, BackendSelect), torch.int64, device=0, requires_grad=False, size=[None], stride=[1])
| | +- NO_HASATTR: hasattr(L['cache_position'], '_dynamo_dynamic_indices') == False
| | +- NO_TENSOR_ALIASING
| +- GuardManager: source=L['logits_to_keep'], accessed_by=FrameLocalsGuardAccessor(key='logits_to_keep', framelocals_idx=9)
| | +- TYPE_MATCH: ___check_type_id(L['logits_to_keep'], 21441248)             
| +- GuardManager: source=L['past_key_values'], accessed_by=FrameLocalsGuardAccessor(key='past_key_values', framelocals_idx=4)
| | +- TYPE_MATCH: ___check_type_id(L['past_key_values'], 866327472)           
| | +- GuardManager: source=L['past_key_values'].layers, accessed_by=GetAttrGuardAccessor(layers)
| | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers, 21438672)     
| | | +- LENGTH_CHECK: len(L['past_key_values'].layers) == 32                      
| | | +- GuardManager: source=L['past_key_values'].layers[0], accessed_by=ListGetItemGuardAccessor(0)
| | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[0], 866454256) 
| | | | +- GuardManager: source=L['past_key_values'].layers[0].keys, accessed_by=GetAttrGuardAccessor(keys)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[0].keys, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[0].keys, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[0].keys, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[0].keys.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | | +- GuardManager: source=L['past_key_values'].layers[0].values, accessed_by=GetAttrGuardAccessor(values)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[0].values, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[0].values, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[0].values, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[0].values.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | +- GuardManager: source=L['past_key_values'].layers[1], accessed_by=ListGetItemGuardAccessor(1)
| | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[1], 866454256) 
| | | | +- GuardManager: source=L['past_key_values'].layers[1].keys, accessed_by=GetAttrGuardAccessor(keys)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[1].keys, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[1].keys, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[1].keys, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[1].keys.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | | +- GuardManager: source=L['past_key_values'].layers[1].values, accessed_by=GetAttrGuardAccessor(values)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[1].values, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[1].values, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[1].values, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[1].values.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | +- GuardManager: source=L['past_key_values'].layers[2], accessed_by=ListGetItemGuardAccessor(2)
| | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[2], 866454256) 
| | | | +- GuardManager: source=L['past_key_values'].layers[2].keys, accessed_by=GetAttrGuardAccessor(keys)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[2].keys, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[2].keys, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[2].keys, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[2].keys.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | | +- GuardManager: source=L['past_key_values'].layers[2].values, accessed_by=GetAttrGuardAccessor(values)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[2].values, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[2].values, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[2].values, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[2].values.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | +- GuardManager: source=L['past_key_values'].layers[3], accessed_by=ListGetItemGuardAccessor(3)
| | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[3], 866454256) 
| | | | +- GuardManager: source=L['past_key_values'].layers[3].keys, accessed_by=GetAttrGuardAccessor(keys)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[3].keys, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[3].keys, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[3].keys, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[3].keys.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | | +- GuardManager: source=L['past_key_values'].layers[3].values, accessed_by=GetAttrGuardAccessor(values)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[3].values, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[3].values, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[3].values, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[3].values.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | +- GuardManager: source=L['past_key_values'].layers[4], accessed_by=ListGetItemGuardAccessor(4)
| | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[4], 866454256) 
| | | | +- GuardManager: source=L['past_key_values'].layers[4].keys, accessed_by=GetAttrGuardAccessor(keys)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[4].keys, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[4].keys, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[4].keys, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[4].keys.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | | +- GuardManager: source=L['past_key_values'].layers[4].values, accessed_by=GetAttrGuardAccessor(values)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[4].values, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[4].values, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[4].values, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[4].values.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | +- GuardManager: source=L['past_key_values'].layers[5], accessed_by=ListGetItemGuardAccessor(5)
| | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[5], 866454256) 
| | | | +- GuardManager: source=L['past_key_values'].layers[5].keys, accessed_by=GetAttrGuardAccessor(keys)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[5].keys, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[5].keys, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[5].keys, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[5].keys.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | | +- GuardManager: source=L['past_key_values'].layers[5].values, accessed_by=GetAttrGuardAccessor(values)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[5].values, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[5].values, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[5].values, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[5].values.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | +- GuardManager: source=L['past_key_values'].layers[6], accessed_by=ListGetItemGuardAccessor(6)
| | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[6], 866454256) 
| | | | +- GuardManager: source=L['past_key_values'].layers[6].keys, accessed_by=GetAttrGuardAccessor(keys)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[6].keys, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[6].keys, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[6].keys, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[6].keys.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | | +- GuardManager: source=L['past_key_values'].layers[6].values, accessed_by=GetAttrGuardAccessor(values)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[6].values, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[6].values, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[6].values, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[6].values.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | +- GuardManager: source=L['past_key_values'].layers[7], accessed_by=ListGetItemGuardAccessor(7)
| | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[7], 866454256) 
| | | | +- GuardManager: source=L['past_key_values'].layers[7].keys, accessed_by=GetAttrGuardAccessor(keys)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[7].keys, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[7].keys, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[7].keys, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[7].keys.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | | +- GuardManager: source=L['past_key_values'].layers[7].values, accessed_by=GetAttrGuardAccessor(values)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[7].values, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[7].values, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[7].values, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[7].values.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | +- GuardManager: source=L['past_key_values'].layers[8], accessed_by=ListGetItemGuardAccessor(8)
| | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[8], 866454256) 
| | | | +- GuardManager: source=L['past_key_values'].layers[8].keys, accessed_by=GetAttrGuardAccessor(keys)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[8].keys, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[8].keys, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[8].keys, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[8].keys.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | | +- GuardManager: source=L['past_key_values'].layers[8].values, accessed_by=GetAttrGuardAccessor(values)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[8].values, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[8].values, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[8].values, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[8].values.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | +- GuardManager: source=L['past_key_values'].layers[9], accessed_by=ListGetItemGuardAccessor(9)
| | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[9], 866454256) 
| | | | +- GuardManager: source=L['past_key_values'].layers[9].keys, accessed_by=GetAttrGuardAccessor(keys)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[9].keys, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[9].keys, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[9].keys, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[9].keys.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | | +- GuardManager: source=L['past_key_values'].layers[9].values, accessed_by=GetAttrGuardAccessor(values)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[9].values, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[9].values, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[9].values, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[9].values.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | +- GuardManager: source=L['past_key_values'].layers[10], accessed_by=ListGetItemGuardAccessor(10)
| | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[10], 866454256)
| | | | +- GuardManager: source=L['past_key_values'].layers[10].keys, accessed_by=GetAttrGuardAccessor(keys)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[10].keys, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[10].keys, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[10].keys, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[10].keys.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | | +- GuardManager: source=L['past_key_values'].layers[10].values, accessed_by=GetAttrGuardAccessor(values)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[10].values, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[10].values, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[10].values, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[10].values.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | +- GuardManager: source=L['past_key_values'].layers[11], accessed_by=ListGetItemGuardAccessor(11)
| | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[11], 866454256)
| | | | +- GuardManager: source=L['past_key_values'].layers[11].keys, accessed_by=GetAttrGuardAccessor(keys)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[11].keys, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[11].keys, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[11].keys, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[11].keys.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | | +- GuardManager: source=L['past_key_values'].layers[11].values, accessed_by=GetAttrGuardAccessor(values)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[11].values, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[11].values, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[11].values, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[11].values.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | +- GuardManager: source=L['past_key_values'].layers[12], accessed_by=ListGetItemGuardAccessor(12)
| | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[12], 866454256)
| | | | +- GuardManager: source=L['past_key_values'].layers[12].keys, accessed_by=GetAttrGuardAccessor(keys)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[12].keys, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[12].keys, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[12].keys, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[12].keys.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | | +- GuardManager: source=L['past_key_values'].layers[12].values, accessed_by=GetAttrGuardAccessor(values)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[12].values, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[12].values, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[12].values, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[12].values.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | +- GuardManager: source=L['past_key_values'].layers[13], accessed_by=ListGetItemGuardAccessor(13)
| | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[13], 866454256)
| | | | +- GuardManager: source=L['past_key_values'].layers[13].keys, accessed_by=GetAttrGuardAccessor(keys)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[13].keys, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[13].keys, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[13].keys, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[13].keys.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | | +- GuardManager: source=L['past_key_values'].layers[13].values, accessed_by=GetAttrGuardAccessor(values)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[13].values, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[13].values, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[13].values, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[13].values.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | +- GuardManager: source=L['past_key_values'].layers[14], accessed_by=ListGetItemGuardAccessor(14)
| | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[14], 866454256)
| | | | +- GuardManager: source=L['past_key_values'].layers[14].keys, accessed_by=GetAttrGuardAccessor(keys)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[14].keys, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[14].keys, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[14].keys, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[14].keys.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | | +- GuardManager: source=L['past_key_values'].layers[14].values, accessed_by=GetAttrGuardAccessor(values)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[14].values, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[14].values, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[14].values, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[14].values.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | +- GuardManager: source=L['past_key_values'].layers[15], accessed_by=ListGetItemGuardAccessor(15)
| | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[15], 866454256)
| | | | +- GuardManager: source=L['past_key_values'].layers[15].keys, accessed_by=GetAttrGuardAccessor(keys)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[15].keys, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[15].keys, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[15].keys, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[15].keys.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | | +- GuardManager: source=L['past_key_values'].layers[15].values, accessed_by=GetAttrGuardAccessor(values)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[15].values, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[15].values, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[15].values, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[15].values.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | +- GuardManager: source=L['past_key_values'].layers[16], accessed_by=ListGetItemGuardAccessor(16)
| | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[16], 866454256)
| | | | +- GuardManager: source=L['past_key_values'].layers[16].keys, accessed_by=GetAttrGuardAccessor(keys)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[16].keys, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[16].keys, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[16].keys, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[16].keys.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | | +- GuardManager: source=L['past_key_values'].layers[16].values, accessed_by=GetAttrGuardAccessor(values)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[16].values, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[16].values, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[16].values, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[16].values.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | +- GuardManager: source=L['past_key_values'].layers[17], accessed_by=ListGetItemGuardAccessor(17)
| | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[17], 866454256)
| | | | +- GuardManager: source=L['past_key_values'].layers[17].keys, accessed_by=GetAttrGuardAccessor(keys)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[17].keys, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[17].keys, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[17].keys, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[17].keys.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | | +- GuardManager: source=L['past_key_values'].layers[17].values, accessed_by=GetAttrGuardAccessor(values)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[17].values, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[17].values, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[17].values, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[17].values.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | +- GuardManager: source=L['past_key_values'].layers[18], accessed_by=ListGetItemGuardAccessor(18)
| | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[18], 866454256)
| | | | +- GuardManager: source=L['past_key_values'].layers[18].keys, accessed_by=GetAttrGuardAccessor(keys)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[18].keys, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[18].keys, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[18].keys, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[18].keys.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | | +- GuardManager: source=L['past_key_values'].layers[18].values, accessed_by=GetAttrGuardAccessor(values)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[18].values, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[18].values, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[18].values, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[18].values.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | +- GuardManager: source=L['past_key_values'].layers[19], accessed_by=ListGetItemGuardAccessor(19)
| | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[19], 866454256)
| | | | +- GuardManager: source=L['past_key_values'].layers[19].keys, accessed_by=GetAttrGuardAccessor(keys)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[19].keys, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[19].keys, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[19].keys, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[19].keys.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | | +- GuardManager: source=L['past_key_values'].layers[19].values, accessed_by=GetAttrGuardAccessor(values)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[19].values, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[19].values, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[19].values, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[19].values.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | +- GuardManager: source=L['past_key_values'].layers[20], accessed_by=ListGetItemGuardAccessor(20)
| | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[20], 866454256)
| | | | +- GuardManager: source=L['past_key_values'].layers[20].keys, accessed_by=GetAttrGuardAccessor(keys)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[20].keys, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[20].keys, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[20].keys, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[20].keys.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | | +- GuardManager: source=L['past_key_values'].layers[20].values, accessed_by=GetAttrGuardAccessor(values)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[20].values, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[20].values, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[20].values, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[20].values.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | +- GuardManager: source=L['past_key_values'].layers[21], accessed_by=ListGetItemGuardAccessor(21)
| | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[21], 866454256)
| | | | +- GuardManager: source=L['past_key_values'].layers[21].keys, accessed_by=GetAttrGuardAccessor(keys)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[21].keys, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[21].keys, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[21].keys, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[21].keys.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | | +- GuardManager: source=L['past_key_values'].layers[21].values, accessed_by=GetAttrGuardAccessor(values)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[21].values, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[21].values, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[21].values, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[21].values.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | +- GuardManager: source=L['past_key_values'].layers[22], accessed_by=ListGetItemGuardAccessor(22)
| | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[22], 866454256)
| | | | +- GuardManager: source=L['past_key_values'].layers[22].keys, accessed_by=GetAttrGuardAccessor(keys)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[22].keys, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[22].keys, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[22].keys, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[22].keys.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | | +- GuardManager: source=L['past_key_values'].layers[22].values, accessed_by=GetAttrGuardAccessor(values)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[22].values, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[22].values, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[22].values, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[22].values.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | +- GuardManager: source=L['past_key_values'].layers[23], accessed_by=ListGetItemGuardAccessor(23)
| | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[23], 866454256)
| | | | +- GuardManager: source=L['past_key_values'].layers[23].keys, accessed_by=GetAttrGuardAccessor(keys)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[23].keys, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[23].keys, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[23].keys, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[23].keys.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | | +- GuardManager: source=L['past_key_values'].layers[23].values, accessed_by=GetAttrGuardAccessor(values)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[23].values, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[23].values, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[23].values, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[23].values.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | +- GuardManager: source=L['past_key_values'].layers[24], accessed_by=ListGetItemGuardAccessor(24)
| | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[24], 866454256)
| | | | +- GuardManager: source=L['past_key_values'].layers[24].keys, accessed_by=GetAttrGuardAccessor(keys)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[24].keys, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[24].keys, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[24].keys, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[24].keys.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | | +- GuardManager: source=L['past_key_values'].layers[24].values, accessed_by=GetAttrGuardAccessor(values)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[24].values, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[24].values, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[24].values, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[24].values.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | +- GuardManager: source=L['past_key_values'].layers[25], accessed_by=ListGetItemGuardAccessor(25)
| | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[25], 866454256)
| | | | +- GuardManager: source=L['past_key_values'].layers[25].keys, accessed_by=GetAttrGuardAccessor(keys)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[25].keys, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[25].keys, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[25].keys, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[25].keys.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | | +- GuardManager: source=L['past_key_values'].layers[25].values, accessed_by=GetAttrGuardAccessor(values)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[25].values, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[25].values, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[25].values, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[25].values.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | +- GuardManager: source=L['past_key_values'].layers[26], accessed_by=ListGetItemGuardAccessor(26)
| | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[26], 866454256)
| | | | +- GuardManager: source=L['past_key_values'].layers[26].keys, accessed_by=GetAttrGuardAccessor(keys)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[26].keys, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[26].keys, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[26].keys, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[26].keys.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | | +- GuardManager: source=L['past_key_values'].layers[26].values, accessed_by=GetAttrGuardAccessor(values)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[26].values, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[26].values, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[26].values, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[26].values.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | +- GuardManager: source=L['past_key_values'].layers[27], accessed_by=ListGetItemGuardAccessor(27)
| | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[27], 866454256)
| | | | +- GuardManager: source=L['past_key_values'].layers[27].keys, accessed_by=GetAttrGuardAccessor(keys)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[27].keys, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[27].keys, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[27].keys, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[27].keys.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | | +- GuardManager: source=L['past_key_values'].layers[27].values, accessed_by=GetAttrGuardAccessor(values)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[27].values, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[27].values, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[27].values, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[27].values.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | +- GuardManager: source=L['past_key_values'].layers[28], accessed_by=ListGetItemGuardAccessor(28)
| | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[28], 866454256)
| | | | +- GuardManager: source=L['past_key_values'].layers[28].keys, accessed_by=GetAttrGuardAccessor(keys)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[28].keys, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[28].keys, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[28].keys, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[28].keys.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | | +- GuardManager: source=L['past_key_values'].layers[28].values, accessed_by=GetAttrGuardAccessor(values)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[28].values, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[28].values, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[28].values, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[28].values.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | +- GuardManager: source=L['past_key_values'].layers[29], accessed_by=ListGetItemGuardAccessor(29)
| | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[29], 866454256)
| | | | +- GuardManager: source=L['past_key_values'].layers[29].keys, accessed_by=GetAttrGuardAccessor(keys)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[29].keys, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[29].keys, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[29].keys, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[29].keys.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | | +- GuardManager: source=L['past_key_values'].layers[29].values, accessed_by=GetAttrGuardAccessor(values)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[29].values, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[29].values, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[29].values, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[29].values.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | +- GuardManager: source=L['past_key_values'].layers[30], accessed_by=ListGetItemGuardAccessor(30)
| | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[30], 866454256)
| | | | +- GuardManager: source=L['past_key_values'].layers[30].keys, accessed_by=GetAttrGuardAccessor(keys)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[30].keys, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[30].keys, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[30].keys, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[30].keys.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | | +- GuardManager: source=L['past_key_values'].layers[30].values, accessed_by=GetAttrGuardAccessor(values)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[30].values, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[30].values, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[30].values, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[30].values.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | +- GuardManager: source=L['past_key_values'].layers[31], accessed_by=ListGetItemGuardAccessor(31)
| | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[31], 866454256)
| | | | +- GuardManager: source=L['past_key_values'].layers[31].keys, accessed_by=GetAttrGuardAccessor(keys)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[31].keys, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[31].keys, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[31].keys, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[31].keys.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | | | +- GuardManager: source=L['past_key_values'].layers[31].values, accessed_by=GetAttrGuardAccessor(values)
| | | | | +- TYPE_MATCH: ___check_type_id(L['past_key_values'].layers[31].values, 798132240)
| | | | | +- TENSOR_MATCH: check_tensor(L['past_key_values'].layers[31].values, Tensor, DispatchKeySet(CUDA, BackendSelect), torch.float16, device=0, requires_grad=False, size=[1, 8, None, 128], stride=[None, None, 128, 1])
| | | | | +- NO_HASATTR: hasattr(L['past_key_values'].layers[31].values, '_dynamo_dynamic_indices') == False
| | | | | +- NO_TENSOR_ALIASING
| | | | | +- GuardManager: source=L['past_key_values'].layers[31].values.index_copy_, accessed_by=GetAttrGuardAccessor(index_copy_)
| | +- GuardManager: source=L['past_key_values'].offloading, accessed_by=GetAttrGuardAccessor(offloading)
| | | +- ID_MATCH: ___check_obj_id(L['past_key_values'].offloading, 21370824)  
| | +- GuardManager: source=L['past_key_values'].layer_class_to_replicate, accessed_by=GetAttrGuardAccessor(layer_class_to_replicate)
| | | +- ID_MATCH: ___check_obj_id(L['past_key_values'].layer_class_to_replicate, 21458960)
| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
| | +- GuardManager: source=G['rotate_half'], accessed_by=DictGetItemGuardAccessor('rotate_half')
| | | +- GuardManager: source=G['rotate_half'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
| | | | +- ID_MATCH: ___check_obj_id(G['rotate_half'].__code__, 131212303113488) 
| | +- GuardManager: source=G['create_causal_mask'], accessed_by=DictGetItemGuardAccessor('create_causal_mask')
| | | +- GuardManager: source=G['create_causal_mask'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
| | | | +- ID_MATCH: ___check_obj_id(G['create_causal_mask'].__code__, 865900272)
| | +- GuardManager: source=G['apply_rotary_pos_emb'], accessed_by=DictGetItemGuardAccessor('apply_rotary_pos_emb')
| | | +- GuardManager: source=G['apply_rotary_pos_emb'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
| | | | +- ID_MATCH: ___check_obj_id(G['apply_rotary_pos_emb'].__code__, 131212303113840)
| | | +- GuardManager: source=G['apply_rotary_pos_emb'], accessed_by=FuncDefaultsGuardAccessor
| | | | +- GuardManager: source=G['apply_rotary_pos_emb'].__defaults__[1], accessed_by=GetItemGuardAccessor(1)
| | | | | +- EQUALS_MATCH: G['apply_rotary_pos_emb'].__defaults__[1] == 1              
| | +- GuardManager: source=G['CausalLMOutputWithPast'], accessed_by=DictGetItemGuardAccessor('CausalLMOutputWithPast')
| | | +- ID_MATCH: ___check_obj_id(G['CausalLMOutputWithPast'], 866459680)     
| | +- GuardManager: source=G['ALL_ATTENTION_FUNCTIONS'], accessed_by=DictGetItemGuardAccessor('ALL_ATTENTION_FUNCTIONS')
| | | +- TYPE_MATCH: ___check_type_id(G['ALL_ATTENTION_FUNCTIONS'], 924953120)   
| | | +- GuardManager: source=G['ALL_ATTENTION_FUNCTIONS']._local_mapping, accessed_by=GetAttrGuardAccessor(_local_mapping)
| | | | +- TYPE_MATCH: ___check_type_id(G['ALL_ATTENTION_FUNCTIONS']._local_mapping, 21447360)
| | | | +- DICT_LENGTH: not G['ALL_ATTENTION_FUNCTIONS']._local_mapping             
| | | +- GuardManager: source=G['ALL_ATTENTION_FUNCTIONS']._global_mapping, accessed_by=GetAttrGuardAccessor(_global_mapping)
| | | | +- TYPE_MATCH: ___check_type_id(G['ALL_ATTENTION_FUNCTIONS']._global_mapping, 21447360)
| | | | +- GuardManager: source=G['ALL_ATTENTION_FUNCTIONS']._global_mapping['sdpa'], accessed_by=DictGetItemGuardAccessor('sdpa')
| | | | | +- GuardManager: source=G['ALL_ATTENTION_FUNCTIONS']._global_mapping['sdpa'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
| | | | | | +- ID_MATCH: ___check_obj_id(G['ALL_ATTENTION_FUNCTIONS']._global_mapping['sdpa'].__code__, 867852736)
| | | | | +- GuardManager: source=G['ALL_ATTENTION_FUNCTIONS']._global_mapping['sdpa'], accessed_by=FuncDefaultsGuardAccessor
| | | | | | +- GuardManager: source=G['ALL_ATTENTION_FUNCTIONS']._global_mapping['sdpa'].__defaults__[2], accessed_by=GetItemGuardAccessor(2)
| | | | | | | +- ID_MATCH: ___check_obj_id(G['ALL_ATTENTION_FUNCTIONS']._global_mapping['sdpa'].__defaults__[2], 21458960)
| | +- GuardManager: source=G['BaseModelOutputWithPast'], accessed_by=DictGetItemGuardAccessor('BaseModelOutputWithPast')
| | | +- ID_MATCH: ___check_obj_id(G['BaseModelOutputWithPast'], 866449600)    
| | +- GuardManager: source=G['eager_attention_forward'], accessed_by=DictGetItemGuardAccessor('eager_attention_forward')
| | | +- GuardManager: source=G['eager_attention_forward'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
| | | | +- ID_MATCH: ___check_obj_id(G['eager_attention_forward'].__code__, 865888304)
| | +- GuardManager: source=G['__builtins_dict___4'], accessed_by=DictGetItemGuardAccessor('__builtins_dict___4')
| | | +- GuardManager: source=G['__builtins_dict___4']['all'], accessed_by=DictGetItemGuardAccessor('all')
| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___4']['all'], 131217361732528)
| | | +- GuardManager: source=G['__builtins_dict___4']['int'], accessed_by=DictGetItemGuardAccessor('int')
| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___4']['int'], 21441248)  
| | | +- GuardManager: source=G['__builtins_dict___4']['len'], accessed_by=DictGetItemGuardAccessor('len')
| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___4']['len'], 131217361734528)
| | | +- GuardManager: source=G['__builtins_dict___4']['set'], accessed_by=DictGetItemGuardAccessor('set')
| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___4']['set'], 21464880)  
| | | +- GuardManager: source=G['__builtins_dict___4']['str'], accessed_by=DictGetItemGuardAccessor('str')
| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___4']['str'], 21487744)  
| | | +- GuardManager: source=G['__builtins_dict___4']['bool'], accessed_by=DictGetItemGuardAccessor('bool')
| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___4']['bool'], 21370376) 
| | | +- GuardManager: source=G['__builtins_dict___4']['iter'], accessed_by=DictGetItemGuardAccessor('iter')
| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___4']['iter'], 131217361734368)
| | | +- GuardManager: source=G['__builtins_dict___4']['list'], accessed_by=DictGetItemGuardAccessor('list')
| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___4']['list'], 21438672) 
| | | +- GuardManager: source=G['__builtins_dict___4']['slice'], accessed_by=DictGetItemGuardAccessor('slice')
| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___4']['slice'], 21466048)
| | | +- GuardManager: source=G['__builtins_dict___4']['super'], accessed_by=DictGetItemGuardAccessor('super')
| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___4']['super'], 21475840)
| | | +- GuardManager: source=G['__builtins_dict___4']['getattr'], accessed_by=DictGetItemGuardAccessor('getattr')
| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___4']['getattr'], 131217361733648)
| | | +- GuardManager: source=G['__builtins_dict___4']['hasattr'], accessed_by=DictGetItemGuardAccessor('hasattr')
| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___4']['hasattr'], 131217361733808)
| | | +- GuardManager: source=G['__builtins_dict___4']['enumerate'], accessed_by=DictGetItemGuardAccessor('enumerate')
| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___4']['enumerate'], 21391040)
| | | +- GuardManager: source=G['__builtins_dict___4']['isinstance'], accessed_by=DictGetItemGuardAccessor('isinstance')
| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___4']['isinstance'], 131217361734208)
| | +- GuardManager: source=G['__import_torch_dot__dynamo_dot_polyfills'], accessed_by=DictGetItemGuardAccessor('__import_torch_dot__dynamo_dot_polyfills')
| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot__dynamo_dot_polyfills'], 131212456369008)
| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_linear'], accessed_by=DictGetItemGuardAccessor('__import_torch_dot_nn_dot_modules_dot_linear')
| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_linear'], 131212668863808)
| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_linear'].F, accessed_by=GetAttrGuardAccessor(F)
| | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_torch_dot_nn_dot_modules_dot_linear'].F
| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module'], accessed_by=DictGetItemGuardAccessor('__import_torch_dot_nn_dot_modules_dot_module')
| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_module'], 131212827879488)
| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module'].Module, accessed_by=GetAttrGuardAccessor(Module)
| | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_module'].Module, 803392944)
| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module'].OrderedDict, accessed_by=GetAttrGuardAccessor(OrderedDict)
| | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_module'].OrderedDict, 21451216)
| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, accessed_by=GetAttrGuardAccessor(_global_forward_hooks)
| | | | +- TYPE_MATCH: ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 21451216)
| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, accessed_by=GetAttrGuardAccessor(_global_backward_hooks)
| | | | +- TYPE_MATCH: ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 21451216)
| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, accessed_by=GetAttrGuardAccessor(_global_forward_pre_hooks)
| | | | +- TYPE_MATCH: ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 21451216)
| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, accessed_by=GetAttrGuardAccessor(_global_backward_pre_hooks)
| | | | +- TYPE_MATCH: ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 21451216)
| | | +- DictGuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_module_registration_hooks, accessed_by=GetAttrGuardAccessor(_global_module_registration_hooks)
| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module'].torch, accessed_by=GetAttrGuardAccessor(torch)
| | | | +- OBJECT_ALIASING: G['__import_low_bit_inference_dot_optims_dot_masking_optim'].torch is G['__import_torch_dot_nn_dot_modules_dot_module'].torch
| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_sparse'], accessed_by=DictGetItemGuardAccessor('__import_torch_dot_nn_dot_modules_dot_sparse')
| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_sparse'], 131212663408816)
| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_sparse'].F, accessed_by=GetAttrGuardAccessor(F)
| | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_sparse'].F, 131212668863968)
| | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_torch_dot_nn_dot_modules_dot_linear'].F
| | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_torch_dot_nn_dot_modules_dot_activation'].F
| | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_low_bit_inference_dot_optims_dot_masking_optim'].torch.nn.functional
| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.silu, accessed_by=GetAttrGuardAccessor(silu)
| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.silu, 131212665902304)
| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.linear, accessed_by=GetAttrGuardAccessor(linear)
| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.linear, 131214339777664)
| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.embedding, accessed_by=GetAttrGuardAccessor(embedding)
| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.embedding, 131212665902944)
| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.scaled_dot_product_attention, accessed_by=GetAttrGuardAccessor(scaled_dot_product_attention)
| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.scaled_dot_product_attention, 131214339779984)
| | +- GuardManager: source=G['__import_transformers_dot_configuration_utils'], accessed_by=DictGetItemGuardAccessor('__import_transformers_dot_configuration_utils')
| | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_configuration_utils'], 131212623881984)
| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_container'], accessed_by=DictGetItemGuardAccessor('__import_torch_dot_nn_dot_modules_dot_container')
| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_container'], 131212664495040)
| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_container'].container_abcs, accessed_by=GetAttrGuardAccessor(container_abcs)
| | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_container'].container_abcs, 131217359234256)
| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_container'].container_abcs.Iterable, accessed_by=GetAttrGuardAccessor(Iterable)
| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_container'].container_abcs.Iterable, 722210176)
| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_activation'], accessed_by=DictGetItemGuardAccessor('__import_torch_dot_nn_dot_modules_dot_activation')
| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_activation'], 131212666399984)
| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_activation'].F, accessed_by=GetAttrGuardAccessor(F)
| | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_torch_dot_nn_dot_modules_dot_activation'].F
| | +- GuardManager: source=G['__import_torch_dot__dynamo_dot_polyfills_dot_builtins'], accessed_by=DictGetItemGuardAccessor('__import_torch_dot__dynamo_dot_polyfills_dot_builtins')
| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot__dynamo_dot_polyfills_dot_builtins'], 131212448491264)
| | +- GuardManager: source=G['__import_low_bit_inference_dot_utils_dot_generic_utils'], accessed_by=DictGetItemGuardAccessor('__import_low_bit_inference_dot_utils_dot_generic_utils')
| | | +- ID_MATCH: ___check_obj_id(G['__import_low_bit_inference_dot_utils_dot_generic_utils'], 131212301809392)
| | | +- GuardManager: source=G['__import_low_bit_inference_dot_utils_dot_generic_utils'].fields, accessed_by=GetAttrGuardAccessor(fields)
| | | | +- ID_MATCH: ___check_obj_id(G['__import_low_bit_inference_dot_utils_dot_generic_utils'].fields, 131213064153312)
| | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_masking_optim'], accessed_by=DictGetItemGuardAccessor('__import_low_bit_inference_dot_optims_dot_masking_optim')
| | | +- ID_MATCH: ___check_obj_id(G['__import_low_bit_inference_dot_optims_dot_masking_optim'], 131212301620848)
| | | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_masking_optim'].torch, accessed_by=GetAttrGuardAccessor(torch)
| | | | +- ID_MATCH: ___check_obj_id(G['__import_low_bit_inference_dot_optims_dot_masking_optim'].torch, 131217359807856)
| | | | +- OBJECT_ALIASING: G['__import_low_bit_inference_dot_optims_dot_masking_optim'].torch is G['torch']
| | | | +- OBJECT_ALIASING: G['__import_low_bit_inference_dot_optims_dot_masking_optim'].torch is G['__import_torch_dot_nn_dot_modules_dot_module'].torch
| | | | +- OBJECT_ALIASING: G['__import_low_bit_inference_dot_optims_dot_masking_optim'].torch is G['__import_transformers_dot_integrations_dot_sdpa_attention'].torch
| | | | +- OBJECT_ALIASING: G['__import_low_bit_inference_dot_optims_dot_masking_optim'].torch is G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm'].torch
| | | | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_masking_optim'].torch._C, accessed_by=GetAttrGuardAccessor(_C)
| | | | | +- ID_MATCH: ___check_obj_id(G['__import_low_bit_inference_dot_optims_dot_masking_optim'].torch._C, 131217355104928)
| | | | | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_masking_optim'].torch._C._log_api_usage_once, accessed_by=GetAttrGuardAccessor(_log_api_usage_once)
| | | | | | +- ID_MATCH: ___check_obj_id(G['__import_low_bit_inference_dot_optims_dot_masking_optim'].torch._C._log_api_usage_once, 131214339968992)
| | | | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_masking_optim'].torch.nn, accessed_by=GetAttrGuardAccessor(nn)
| | | | | +- ID_MATCH: ___check_obj_id(G['__import_low_bit_inference_dot_optims_dot_masking_optim'].torch.nn, 131212827873888)
| | | | | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_masking_optim'].torch.nn.functional, accessed_by=GetAttrGuardAccessor(functional)
| | | | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_low_bit_inference_dot_optims_dot_masking_optim'].torch.nn.functional
| | | | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_masking_optim'].torch.cat, accessed_by=GetAttrGuardAccessor(cat)
| | | | | +- ID_MATCH: ___check_obj_id(G['__import_low_bit_inference_dot_optims_dot_masking_optim'].torch.cat, 131217355501504)
| | | | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_masking_optim'].torch.jit, accessed_by=GetAttrGuardAccessor(jit)
| | | | | +- ID_MATCH: ___check_obj_id(G['__import_low_bit_inference_dot_optims_dot_masking_optim'].torch.jit, 131212663266240)
| | | | | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_masking_optim'].torch.jit.is_tracing, accessed_by=GetAttrGuardAccessor(is_tracing)
| | | | | | +- ID_MATCH: ___check_obj_id(G['__import_low_bit_inference_dot_optims_dot_masking_optim'].torch.jit.is_tracing, 131212661979104)
| | | | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_masking_optim'].torch.empty, accessed_by=GetAttrGuardAccessor(empty)
| | | | | +- ID_MATCH: ___check_obj_id(G['__import_low_bit_inference_dot_optims_dot_masking_optim'].torch.empty, 131217355503424)
| | | | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_masking_optim'].torch.Tensor, accessed_by=GetAttrGuardAccessor(Tensor)
| | | | | +- ID_MATCH: ___check_obj_id(G['__import_low_bit_inference_dot_optims_dot_masking_optim'].torch.Tensor, 798132240)
| | | | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_masking_optim'].torch.float32, accessed_by=GetAttrGuardAccessor(float32)
| | | | | +- EQUALS_MATCH: G['__import_low_bit_inference_dot_optims_dot_masking_optim'].torch.float32 == torch.float32
| | | | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_masking_optim'].torch.autocast, accessed_by=GetAttrGuardAccessor(autocast)
| | | | | +- ID_MATCH: ___check_obj_id(G['__import_low_bit_inference_dot_optims_dot_masking_optim'].torch.autocast, 796465152)
| | | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_masking_optim'].BlockMask, accessed_by=GetAttrGuardAccessor(BlockMask)
| | | | +- ID_MATCH: ___check_obj_id(G['__import_low_bit_inference_dot_optims_dot_masking_optim'].BlockMask, 866107888)
| | | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_masking_optim']._preprocess_mask_arguments, accessed_by=GetAttrGuardAccessor(_preprocess_mask_arguments)
| | | | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_masking_optim']._preprocess_mask_arguments.__code__, accessed_by=GetAttrGuardAccessor(__code__)
| | | | | +- ID_MATCH: ___check_obj_id(G['__import_low_bit_inference_dot_optims_dot_masking_optim']._preprocess_mask_arguments.__code__, 865787632)
| | +- GuardManager: source=G['__import_transformers_dot_integrations_dot_sdpa_attention'], accessed_by=DictGetItemGuardAccessor('__import_transformers_dot_integrations_dot_sdpa_attention')
| | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_integrations_dot_sdpa_attention'], 131211380954176)
| | | +- GuardManager: source=G['__import_transformers_dot_integrations_dot_sdpa_attention'].repeat_kv, accessed_by=GetAttrGuardAccessor(repeat_kv)
| | | | +- GuardManager: source=G['__import_transformers_dot_integrations_dot_sdpa_attention'].repeat_kv.__code__, accessed_by=GetAttrGuardAccessor(__code__)
| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_integrations_dot_sdpa_attention'].repeat_kv.__code__, 131212279949792)
| | | +- GuardManager: source=G['__import_transformers_dot_integrations_dot_sdpa_attention'].torch, accessed_by=GetAttrGuardAccessor(torch)
| | | | +- OBJECT_ALIASING: G['__import_low_bit_inference_dot_optims_dot_masking_optim'].torch is G['__import_transformers_dot_integrations_dot_sdpa_attention'].torch
| | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm'], accessed_by=DictGetItemGuardAccessor('__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm')
| | | +- ID_MATCH: ___check_obj_id(G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm'], 131212303628816)
| | | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm'].triton, accessed_by=GetAttrGuardAccessor(triton)
| | | | +- ID_MATCH: ___check_obj_id(G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm'].triton, 131212592299152)
| | | | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm'].triton.next_power_of_2, accessed_by=GetAttrGuardAccessor(next_power_of_2)
| | | | | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm'].triton.next_power_of_2.__code__, accessed_by=GetAttrGuardAccessor(__code__)
| | | | | | +- ID_MATCH: ___check_obj_id(G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm'].triton.next_power_of_2.__code__, 131212593589552)
| | | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm'].rms_norm_forward, accessed_by=GetAttrGuardAccessor(rms_norm_forward)
| | | | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm'].rms_norm_forward.__code__, accessed_by=GetAttrGuardAccessor(__code__)
| | | | | +- ID_MATCH: ___check_obj_id(G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm'].rms_norm_forward.__code__, 866024080)
| | | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm'].calculate_settings, accessed_by=GetAttrGuardAccessor(calculate_settings)
| | | | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm'].calculate_settings.__code__, accessed_by=GetAttrGuardAccessor(__code__)
| | | | | +- ID_MATCH: ___check_obj_id(G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm'].calculate_settings.__code__, 131212301583856)
| | | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm']._CASTING_MODE_GEMMA, accessed_by=GetAttrGuardAccessor(_CASTING_MODE_GEMMA)
| | | | +- TYPE_MATCH: ___check_type_id(G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm']._CASTING_MODE_GEMMA, 844094912)
| | | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm']._CASTING_MODE_LLAMA, accessed_by=GetAttrGuardAccessor(_CASTING_MODE_LLAMA)
| | | | +- TYPE_MATCH: ___check_type_id(G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm']._CASTING_MODE_LLAMA, 844094912)
| | | | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm']._CASTING_MODE_LLAMA.value, accessed_by=GetAttrGuardAccessor(value)
| | | | | +- EQUALS_MATCH: G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm']._CASTING_MODE_LLAMA.value == 0
| | | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm'].LigerRMSNormFunction, accessed_by=GetAttrGuardAccessor(LigerRMSNormFunction)
| | | | +- ID_MATCH: ___check_obj_id(G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm'].LigerRMSNormFunction, 866022704)
| | | | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm'].LigerRMSNormFunction.forward, accessed_by=GetAttrGuardAccessor(forward)
| | | | | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm'].LigerRMSNormFunction.forward.__closure__, accessed_by=GetAttrGuardAccessor(__closure__)
| | | | | | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm'].LigerRMSNormFunction.forward.__closure__[0], accessed_by=TupleGetItemGuardAccessor(0)
| | | | | | | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm'].LigerRMSNormFunction.forward.__closure__[0].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents)
| | | | | | | | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm'].LigerRMSNormFunction.forward.__closure__[0].cell_contents.__code__, accessed_by=GetAttrGuardAccessor(__code__)
| | | | | | | | | +- ID_MATCH: ___check_obj_id(G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm'].LigerRMSNormFunction.forward.__closure__[0].cell_contents.__code__, 131212301584224)
| | | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm']._str_to_casting_mode, accessed_by=GetAttrGuardAccessor(_str_to_casting_mode)
| | | | +- TYPE_MATCH: ___check_type_id(G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm']._str_to_casting_mode, 21447360)
| | | | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm']._str_to_casting_mode['llama'], accessed_by=DictGetItemGuardAccessor('llama')
| | | | | +- EQUALS_MATCH: G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm']._str_to_casting_mode['llama'] == 0
| | | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm']._rms_norm_forward_kernel, accessed_by=GetAttrGuardAccessor(_rms_norm_forward_kernel)
| | | | +- ID_MATCH: ___check_obj_id(G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm']._rms_norm_forward_kernel, 131212301634256)
| | | +- GuardManager: source=G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm'].torch, accessed_by=GetAttrGuardAccessor(torch)
| | | | +- OBJECT_ALIASING: G['__import_low_bit_inference_dot_optims_dot_masking_optim'].torch is G['__import_low_bit_inference_dot_optims_dot_rms_norm_kernels_dot_liger_rms_norm'].torch
| | +- GuardManager: source=G['torch'], accessed_by=DictGetItemGuardAccessor('torch')
| | | +- OBJECT_ALIASING: G['__import_low_bit_inference_dot_optims_dot_masking_optim'].torch is G['torch']
+- LAMBDA_GUARD: L['input_ids'].stride()[0] == L['input_ids'].size()[1]  # (unknown source L['input_ids'].stride()[0], please file a bug)
+- LAMBDA_GUARD: L['position_ids'].size()[1] == L['input_ids'].size()[1]  # q_embed = (q * cos) + (rotate_half(q) * sin)  # low_bit_inference/model.py:107 in apply_rotary_pos_emb (_subclasses/fake_impls.py:881 in infer_size)
+- LAMBDA_GUARD: L['position_ids'].stride()[0] == L['input_ids'].size()[1]  # (unknown source L['position_ids'].stride()[0], please file a bug)
+- LAMBDA_GUARD: L['attention_mask'].size()[2] == L['input_ids'].size()[1]  # attn_output = torch.nn.functional.scaled_dot_product_attention(  # transformers/integrations/sdpa_attention.py:54 in sdpa_attention_forward (_refs/__init__.py:3011 in expand)
+- LAMBDA_GUARD: L['attention_mask'].stride()[0] == L['input_ids'].size()[1]*L['attention_mask'].size()[3]  # (unknown source L['attention_mask'].stride()[0], please file a bug)
+- LAMBDA_GUARD: L['attention_mask'].stride()[1] == L['input_ids'].size()[1]*L['attention_mask'].size()[3]  # (unknown source L['attention_mask'].stride()[1], please file a bug)
+- LAMBDA_GUARD: L['attention_mask'].stride()[2] == L['attention_mask'].size()[3]  # (unknown source L['attention_mask'].stride()[2], please file a bug)
+- LAMBDA_GUARD: object.__getattribute__(L['self']._modules['model'].config, 'num_hidden_layers') == 32  # return self.__class__(list(self._modules.values())[idx])  # nn/modules/container.py:322 in __getitem__ (_dynamo/variables/tensor.py:1245 in evaluate_expr)
+- LAMBDA_GUARD: L['past_key_values'].layers[0].keys.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[0].keys.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[0].keys.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[0].keys.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[0].keys.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[0].values.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[0].values.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[0].values.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[0].values.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[0].values.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[1].keys.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[1].keys.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[1].keys.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[1].keys.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[1].keys.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[1].values.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[1].values.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[1].values.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[1].values.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[1].values.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[2].keys.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[2].keys.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[2].keys.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[2].keys.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[2].keys.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[2].values.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[2].values.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[2].values.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[2].values.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[2].values.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[3].keys.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[3].keys.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[3].keys.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[3].keys.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[3].keys.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[3].values.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[3].values.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[3].values.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[3].values.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[3].values.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[4].keys.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[4].keys.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[4].keys.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[4].keys.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[4].keys.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[4].values.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[4].values.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[4].values.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[4].values.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[4].values.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[5].keys.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[5].keys.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[5].keys.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[5].keys.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[5].keys.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[5].values.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[5].values.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[5].values.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[5].values.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[5].values.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[6].keys.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[6].keys.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[6].keys.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[6].keys.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[6].keys.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[6].values.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[6].values.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[6].values.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[6].values.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[6].values.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[7].keys.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[7].keys.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[7].keys.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[7].keys.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[7].keys.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[7].values.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[7].values.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[7].values.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[7].values.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[7].values.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[8].keys.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[8].keys.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[8].keys.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[8].keys.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[8].keys.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[8].values.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[8].values.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[8].values.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[8].values.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[8].values.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[9].keys.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[9].keys.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[9].keys.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[9].keys.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[9].keys.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[9].values.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[9].values.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[9].values.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[9].values.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[9].values.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[10].keys.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[10].keys.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[10].keys.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[10].keys.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[10].keys.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[10].values.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[10].values.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[10].values.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[10].values.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[10].values.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[11].keys.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[11].keys.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[11].keys.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[11].keys.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[11].keys.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[11].values.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[11].values.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[11].values.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[11].values.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[11].values.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[12].keys.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[12].keys.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[12].keys.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[12].keys.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[12].keys.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[12].values.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[12].values.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[12].values.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[12].values.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[12].values.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[13].keys.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[13].keys.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[13].keys.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[13].keys.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[13].keys.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[13].values.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[13].values.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[13].values.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[13].values.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[13].values.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[14].keys.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[14].keys.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[14].keys.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[14].keys.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[14].keys.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[14].values.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[14].values.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[14].values.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[14].values.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[14].values.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[15].keys.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[15].keys.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[15].keys.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[15].keys.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[15].keys.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[15].values.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[15].values.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[15].values.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[15].values.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[15].values.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[16].keys.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[16].keys.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[16].keys.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[16].keys.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[16].keys.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[16].values.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[16].values.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[16].values.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[16].values.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[16].values.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[17].keys.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[17].keys.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[17].keys.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[17].keys.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[17].keys.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[17].values.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[17].values.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[17].values.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[17].values.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[17].values.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[18].keys.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[18].keys.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[18].keys.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[18].keys.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[18].keys.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[18].values.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[18].values.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[18].values.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[18].values.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[18].values.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[19].keys.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[19].keys.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[19].keys.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[19].keys.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[19].keys.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[19].values.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[19].values.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[19].values.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[19].values.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[19].values.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[20].keys.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[20].keys.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[20].keys.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[20].keys.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[20].keys.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[20].values.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[20].values.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[20].values.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[20].values.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[20].values.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[21].keys.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[21].keys.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[21].keys.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[21].keys.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[21].keys.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[21].values.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[21].values.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[21].values.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[21].values.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[21].values.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[22].keys.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[22].keys.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[22].keys.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[22].keys.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[22].keys.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[22].values.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[22].values.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[22].values.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[22].values.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[22].values.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[23].keys.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[23].keys.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[23].keys.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[23].keys.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[23].keys.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[23].values.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[23].values.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[23].values.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[23].values.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[23].values.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[24].keys.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[24].keys.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[24].keys.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[24].keys.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[24].keys.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[24].values.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[24].values.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[24].values.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[24].values.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[24].values.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[25].keys.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[25].keys.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[25].keys.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[25].keys.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[25].keys.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[25].values.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[25].values.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[25].values.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[25].values.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[25].values.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[26].keys.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[26].keys.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[26].keys.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[26].keys.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[26].keys.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[26].values.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[26].values.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[26].values.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[26].values.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[26].values.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[27].keys.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[27].keys.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[27].keys.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[27].keys.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[27].keys.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[27].values.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[27].values.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[27].values.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[27].values.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[27].values.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[28].keys.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[28].keys.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[28].keys.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[28].keys.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[28].keys.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[28].values.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[28].values.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[28].values.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[28].values.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[28].values.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[29].keys.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[29].keys.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[29].keys.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[29].keys.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[29].keys.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[29].values.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[29].values.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[29].values.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[29].values.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[29].values.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[30].keys.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[30].keys.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[30].keys.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[30].keys.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[30].keys.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[30].values.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[30].values.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[30].values.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[30].values.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[30].values.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[31].keys.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[31].keys.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[31].keys.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[31].keys.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[31].keys.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[31].values.size()[2] == L['attention_mask'].size()[3]  # duck sizing added this equality because these variables had the same size 2048 (to avoid this specialization, set torch.fx.experimental._config.use_duck_shape = False)
+- LAMBDA_GUARD: L['past_key_values'].layers[31].values.stride()[0] == 1024*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[31].values.stride()[0], please file a bug)
+- LAMBDA_GUARD: L['past_key_values'].layers[31].values.stride()[1] == 128*L['attention_mask'].size()[3]  # (unknown source L['past_key_values'].layers[31].values.stride()[1], please file a bug)
+- LAMBDA_GUARD: L['logits_to_keep'] == 1  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:125 in forward (_decomp/decompositions.py:4398 in <genexpr>)
+- LAMBDA_GUARD: ((L['input_ids'].size()[1]*L['attention_mask'].size()[3]) % 8) == 0  # attn_output = torch.nn.functional.scaled_dot_product_attention(  # transformers/integrations/sdpa_attention.py:54 in sdpa_attention_forward (_ops.py:799 in decompose)
+- LAMBDA_GUARD: (L['attention_mask'].size()[3] % 8) == 0  # attn_output = torch.nn.functional.scaled_dot_product_attention(  # transformers/integrations/sdpa_attention.py:54 in sdpa_attention_forward (_ops.py:799 in decompose)
+- LAMBDA_GUARD: 7*L['input_ids'].size()[1] < 1048576  # (_inductor/codegen/simd.py:1347 in can_use_32bit_indexing)
+- LAMBDA_GUARD: L['input_ids'].size()[1]*L['attention_mask'].size()[3] < 2147483648  # (_inductor/codegen/simd.py:1347 in can_use_32bit_indexing)
+- LAMBDA_GUARD: L['attention_mask'].size()[3] + 8*L['input_ids'].size()[1]*((7 + L['attention_mask'].size()[3]) // 8) < 2147483648 + 8*((7 + L['attention_mask'].size()[3]) // 8)  # (_inductor/codegen/simd.py:1349 in can_use_32bit_indexing)
+- LAMBDA_GUARD: 2 <= L['input_ids'].size()[1] <= 524287  # if (input_ids is None) ^ (inputs_embeds is not None):  # low_bit_inference/model.py:342 in forward (user code shown is first use of this value--the guard itself is not due user code but due to 0/1 specialization in the framework; to avoid specialization try torch._dynamo.mark_unbacked(tensor, dim)) and (_inductor/codegen/simd.py:1347 in can_use_32bit_indexing)
+- LAMBDA_GUARD: 2 <= L['cache_position'].size()[0] <= 2097151  # if cache_position is None:  # low_bit_inference/model.py:351 in forward (user code shown is first use of this value--the guard itself is not due user code but due to 0/1 specialization in the framework; to avoid specialization try torch._dynamo.mark_unbacked(tensor, dim)) and (_inductor/codegen/simd.py:1347 in can_use_32bit_indexing)
+- LAMBDA_GUARD: 2 <= L['attention_mask'].size()[3] <= 524287  # if isinstance(attention_mask, (torch.Tensor, BlockMask)) and len(attention_mask.shape) == 4:  # low_bit_inference/optims/masking_optim.py:521 in _preprocess_mask_arguments (user code shown is first use of this value--the guard itself is not due user code but due to 0/1 specialization in the framework; to avoid specialization try torch._dynamo.mark_unbacked(tensor, dim)) and (_inductor/codegen/simd.py:1347 in can_use_32bit_indexing)

Guard latency = 277.44 us