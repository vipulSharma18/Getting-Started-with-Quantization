Quantization works now, but it does autotune for prefill stage and then decode stage.
We should only do it for the decode stage to ensure gemv is used instead of gemm for prefill stage.

Also, quantization leads to skipping cudagraphs error for kv cache due to mutated inputs.

Note: use autoquant_v2 which specializes for batch size 1?

(low-bit-inference) root@c61c0f80798d:/app# python -m low_bit_inference.torchinductor_autoquant configs/profile_inductor_torchao.yaml tps_only=True


WARNING:gemlite.core:Loaded /app/.venv/lib/python3.12/site-packages/gemlite/configs/a6000.json config.
config used -- 
device: cuda:0
compute_dtype: fp16
model_id: unsloth/Meta-Llama-3.1-8B-Instruct
cache_dir: /root/.cache/huggingface/hub
profiling_dir: log/inductor/09_15_21_28_59
skip_first: 1
wait: 1
warmup: 3
active: 5
repeat: 0
tps_only: true
profile_compile: false
prompt: Write an essay about large language models.
max_new_tokens: 1000
chat_template: ''
do_sample: false
top_k: null
top_p: null
temperature: null
use_cache: true
cache_implementation: static
attn_implementation: sdpa
compile_prefill: false
compile_decode: true
quantize: true
padding_side: left

PyTorch sees 1 devices, current device: 0
Loading pretrained model and tokenizer: unsloth/Meta-Llama-3.1-8B-Instruct.
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.33it/s]
Number of parameters in model: 8030261248
Using prompt: ['Write an essay about large language models.']
Model loaded unsloth/Meta-Llama-3.1-8B-Instruct.
Model moved to GPU, starting profiling.
Compile config: decode True,     prefill False. Quantize status: True
Profiling iteration 0 out of total 10
Compiled module path: /tmp/torchinductor_root/u3/cu3v5kpew5o5mbjk3u4zxragb4vqjdpaxt6trnjketn4udu4kf7y.py
activation_shapes: torch.Size([9, 4096]), times_seen: 1
weight_shape: torch.Size([4096, 4096]), dtype: torch.float16, bias_shape: None
AUTOTUNE mm(9x4096, 4096x4096)
  triton_mm_4 0.0583 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
  triton_mm_1 0.0584 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2
  triton_mm_7 0.0584 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_8 0.0584 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
  triton_mm_11 0.0584 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_16 0.0584 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
  triton_mm_3 0.0594 ms 98.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
  mm 0.0604 ms 96.6% 
  triton_mm_2 0.0604 ms 96.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
  triton_mm_14 0.0614 ms 94.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.5735 seconds and 0.5753 seconds precompiling for 18 choices
Compiled module path: /tmp/torchinductor_root/6r/c6rh7t2zyxpdvy6tmb6675gvwmmotemqfclcjwynh4nvkwoktbfm.py
>>time: 0.057ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
AUTOTUNE mm(9x4096, 4096x4096)
  triton_mm_24 0.0563 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_18 0.0573 ms 98.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2
  triton_mm_19 0.0573 ms 98.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
  triton_mm_20 0.0573 ms 98.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
  triton_mm_27 0.0573 ms 98.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
  triton_mm_28 0.0573 ms 98.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_31 0.0573 ms 98.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
  triton_mm_33 0.0573 ms 98.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
  triton_mm_25 0.0584 ms 96.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
  triton_mm_26 0.0584 ms 96.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.2880 seconds and 0.5534 seconds precompiling for 18 choices
Compiled module path: /tmp/torchinductor_root/zf/czf2ofnzcuweapi3ntp3hebcbm3ouyunrj6xs26efhvxo6vgbma3.py
>>time: 0.046ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.057ms 
Compiled module path: /tmp/torchinductor_root/q7/cq7hlgmaf5gothzk6ozvnhcvj326xpdwkhmmvh7ucjiflll6nbvw.py
>>time: 0.091ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.046ms 
AUTOTUNE int_mm(9x4096, 4096x4096)
  triton_mm_43 0.0348 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=256, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
  triton_mm_44 0.0358 ms 97.1% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
  triton_mm_42 0.0379 ms 91.9% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_39 0.0410 ms 85.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
  triton_mm_40 0.0440 ms 79.1% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
  triton_mm_38 0.0481 ms 72.3% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
  triton_mm_36 0.0635 ms 54.8% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_35 0.0686 ms 50.7% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_37 0.1126 ms 30.9% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
  triton_mm_41 0.1137 ms 30.6% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8
SingleProcess AUTOTUNE benchmarking takes 0.1913 seconds and 0.4249 seconds precompiling for 12 choices
Compiled module path: /tmp/torchinductor_root/nn/cnn3i6rssuv47ckhrctaun7kl6xslcvb4cpfmagnehjmezukwb6w.py
>>time: 0.035ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.046ms
Compiled module path: /tmp/torchinductor_root/qe/cqehurm2byxkfquy6p72d32dgijhyaectfroqil7rp3idp7rqyes.py
>>time: 0.039ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>, to_beat: 0.110ms 
>>time: 0.038ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> interpolated, breakeven constant: 2.75
best_cls=<class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>

activation_shapes: torch.Size([9, 4096]), times_seen: 1
weight_shape: torch.Size([1024, 4096]), dtype: torch.float16, bias_shape: None
AUTOTUNE mm(9x4096, 4096x1024)
  triton_mm_60 0.0276 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
  triton_mm_64 0.0285 ms 96.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
  triton_mm_72 0.0328 ms 84.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
  triton_mm_59 0.0347 ms 79.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
  triton_mm_57 0.0348 ms 79.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2
  triton_mm_58 0.0348 ms 79.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
  triton_mm_63 0.0348 ms 79.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_67 0.0358 ms 77.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_70 0.0358 ms 77.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
  mm 0.0399 ms 69.2% 
SingleProcess AUTOTUNE benchmarking takes 0.2700 seconds and 0.5550 seconds precompiling for 18 choices
Compiled module path: /tmp/torchinductor_root/np/cnpagb7zdnvzmv3u6k4izegk76jxidb7mepyhhw3jfktxbqhfbiv.py
>>time: 0.020ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
AUTOTUNE mm(9x4096, 4096x1024)
  triton_mm_81 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
  triton_mm_77 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
  triton_mm_76 0.0317 ms 83.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
  triton_mm_75 0.0328 ms 81.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
  triton_mm_89 0.0328 ms 81.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
  triton_mm_74 0.0338 ms 78.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2
  triton_mm_80 0.0338 ms 78.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_83 0.0348 ms 76.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
  triton_mm_84 0.0358 ms 74.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_87 0.0358 ms 74.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.2656 seconds and 0.5168 seconds precompiling for 18 choices
Compiled module path: /tmp/torchinductor_root/vl/cvlbpmkrtijnsrpzqawdy4whu43qnfodb7nyjbozr2djv3mkea36.py
>>time: 0.021ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.020ms 
Compiled module path: /tmp/torchinductor_root/d2/cd2o3m4cbnmzas4ybuvzzzl4jx26f5lf4wieykzmskgzvzb7hfat.py
>>time: 0.025ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.020ms 
AUTOTUNE int_mm(9x4096, 4096x1024)
  triton_mm_100 0.0236 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
  triton_mm_98 0.0297 ms 79.3% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_99 0.0297 ms 79.3% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=256, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
  triton_mm_95 0.0307 ms 76.7% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
  triton_mm_94 0.0328 ms 71.9% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
  triton_mm_96 0.0328 ms 71.9% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
  triton_mm_92 0.0420 ms 56.1% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_91 0.0471 ms 50.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_90 0.0686 ms 34.3% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
  triton_mm_93 0.0758 ms 31.1% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
SingleProcess AUTOTUNE benchmarking takes 0.1740 seconds and 0.4388 seconds precompiling for 12 choices
Compiled module path: /tmp/torchinductor_root/vc/cvcpyiavijluoai4vc7lovnk4l5d4i5wotimd3vhivxxxtadetd6.py
>>time: 0.017ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.020ms
Compiled module path: /tmp/torchinductor_root/ib/cibwby6dey6io7ard6pr3cnfyjnoyxio3dobujsx2ri3dlzormzw.py
>>time: 0.021ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>, to_beat: 0.037ms 
>>time: 0.020ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> interpolated, breakeven constant: 0.94
best_cls=<class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>

activation_shapes: torch.Size([9, 4096]), times_seen: 1
weight_shape: torch.Size([14336, 4096]), dtype: torch.float16, bias_shape: None
AUTOTUNE mm(9x4096, 4096x14336)
  triton_mm_113 0.1751 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2
  triton_mm_119 0.1761 ms 99.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_123 0.1761 ms 99.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_116 0.1772 ms 98.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
  triton_mm_120 0.1772 ms 98.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
  triton_mm_128 0.1772 ms 98.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
  mm 0.1811 ms 96.7% 
  triton_mm_125 0.2417 ms 72.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_126 0.2437 ms 71.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
  triton_mm_122 0.2591 ms 67.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
SingleProcess AUTOTUNE benchmarking takes 0.5648 seconds and 0.5146 seconds precompiling for 18 choices
Compiled module path: /tmp/torchinductor_root/mi/cmibuqcqm4g5p435me6buq3hwgfkanizpljbuboxft2pwussyeo2.py
>>time: 0.175ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
AUTOTUNE mm(9x4096, 4096x14336)
  triton_mm_131 0.1741 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
  triton_mm_138 0.1741 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_139 0.1741 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
  triton_mm_130 0.1751 ms 99.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2
  triton_mm_135 0.1751 ms 99.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
  triton_mm_136 0.1751 ms 99.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_140 0.1751 ms 99.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_142 0.1751 ms 99.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_143 0.1751 ms 99.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
  triton_mm_144 0.1751 ms 99.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8
SingleProcess AUTOTUNE benchmarking takes 0.4877 seconds and 0.5466 seconds precompiling for 18 choices
Compiled module path: /tmp/torchinductor_root/f2/cf2ilakl7vdfg74cn34ue7soxtsg54oi5c22fingokjnfpzty4g3.py
>>time: 0.264ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.175ms 
Compiled module path: /tmp/torchinductor_root/6c/c6czfjyalgyhzbtkvayppuim4wqp7g56k7x5lhfqpvxvztdgtwbv.py
>>time: 0.752ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.175ms 
AUTOTUNE int_mm(9x4096, 4096x14336)
  triton_mm_155 0.0932 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=256, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
  triton_mm_156 0.0932 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
  triton_mm_154 0.1300 ms 71.7% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_150 0.2365 ms 39.4% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
  triton_mm_148 0.2376 ms 39.2% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_147 0.2436 ms 38.3% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_149 0.2458 ms 37.9% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
  triton_mm_151 0.2529 ms 36.8% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
  triton_mm_152 0.2591 ms 36.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
  triton_mm_146 0.3113 ms 29.9% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.3569 seconds and 0.4401 seconds precompiling for 12 choices
Compiled module path: /tmp/torchinductor_root/2n/c2nuorub6mcc5kbwb7izwvrjsi3ockios2eslub4jleevvtbxog4.py
>>time: 0.095ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.175ms
Compiled module path: /tmp/torchinductor_root/ke/ckenv3p76fcm6ii6nwqgwekl7vh4ovafplkkf2e5s5mns3wepmzc.py
>>time: 0.097ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>, to_beat: 0.627ms 
>>time: 0.097ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> interpolated, breakeven constant: 37.10
best_cls=<class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>

activation_shapes: torch.Size([9, 14336]), times_seen: 1
weight_shape: torch.Size([4096, 14336]), dtype: torch.float16, bias_shape: None
AUTOTUNE mm(9x14336, 14336x4096)
  triton_mm_169 0.1761 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2
  triton_mm_175 0.1761 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_184 0.1761 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
  triton_mm_179 0.1772 ms 99.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_171 0.1782 ms 98.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
  mm 0.1792 ms 98.3% 
  triton_mm_170 0.1792 ms 98.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
  triton_mm_176 0.1792 ms 98.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
  triton_mm_172 0.1823 ms 96.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
  triton_mm_182 0.2099 ms 83.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.5476 seconds and 0.5231 seconds precompiling for 18 choices
Compiled module path: /tmp/torchinductor_root/ru/cru7cb5ghsdykldoa6yjpabsm4quyjhhejuxao5d6c6jiknwodh4.py
>>time: 0.176ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
AUTOTUNE mm(9x14336, 14336x4096)
  triton_mm_195 0.1751 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
  triton_mm_196 0.1751 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_201 0.1751 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
  triton_mm_186 0.1761 ms 99.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2
  triton_mm_187 0.1761 ms 99.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
  triton_mm_192 0.1761 ms 99.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_199 0.1761 ms 99.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
  triton_mm_188 0.1782 ms 98.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
  triton_mm_193 0.1782 ms 98.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
  triton_mm_198 0.1782 ms 98.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.5169 seconds and 0.5139 seconds precompiling for 18 choices
Compiled module path: /tmp/torchinductor_root/t7/ct74wymyb72fryxbtraqasgczd34osz2aw6yr5vp7oodyghf26wm.py
>>time: 0.259ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.176ms 
Compiled module path: /tmp/torchinductor_root/mh/cmhxwx3i3qlw3ktdyuudr7thvcjinpy5ngkigmtx5vz72uao6te6.py
>>time: 0.281ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.176ms 
AUTOTUNE int_mm(9x14336, 14336x4096)
  triton_mm_212 0.0952 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
  triton_mm_211 0.0993 ms 95.9% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=256, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
  triton_mm_210 0.1137 ms 83.8% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_207 0.1208 ms 78.8% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
  triton_mm_208 0.1423 ms 66.9% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
  triton_mm_206 0.1669 ms 57.1% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
  triton_mm_204 0.2150 ms 44.3% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_203 0.2355 ms 40.4% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_202 0.3901 ms 24.4% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
  triton_mm_209 0.3953 ms 24.1% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8
SingleProcess AUTOTUNE benchmarking takes 0.3239 seconds and 0.3877 seconds precompiling for 12 choices
Compiled module path: /tmp/torchinductor_root/bh/cbh35pmdq3vxzfh2zwtmivk5rhfykvxlohf3cybqpt2jbrknmg4k.py
>>time: 0.094ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.176ms
Compiled module path: /tmp/torchinductor_root/2d/c2dpde3frheqj7gsm54gx3wtcxuouncsjwutaogqu3at7aagmxi6.py
>>time: 0.103ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>, to_beat: 0.640ms 
>>time: 0.102ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> interpolated, breakeven constant: 8.89
best_cls=<class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>

activation_shapes: torch.Size([1, 4096]), times_seen: 1
weight_shape: torch.Size([128256, 4096]), dtype: torch.float16, bias_shape: None
Compiled module path: /tmp/torchinductor_root/qt/cqtov3s2kjiefl43mqsmd6nhc7hmf664lqd3hbltu6k2yxagrg43.py
>>time: 1.477ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
Compiled module path: /tmp/torchinductor_root/ld/cldqijbsaycz3fxffrspqcaeshh65pca4lsysgv7bn4ftfyedk2f.py
>>time: 0.756ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 1.477ms 
Compiled module path: /tmp/torchinductor_root/mb/cmbskzil3ro7ifjexkvnjfled6pz75463dnlfcufbvjc7ze4nyoj.py
>>time: 0.756ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.756ms 
AUTOTUNE int_mm(1x4096, 4096x128256)
  triton_mm_233 0.7506 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=256, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
  triton_mm_234 0.7506 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
  triton_mm_232 1.2093 ms 62.1% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_229 2.3920 ms 31.4% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
  triton_mm_226 2.3962 ms 31.3% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_228 2.4085 ms 31.2% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
  triton_mm_230 2.4146 ms 31.1% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
  triton_mm_225 2.4187 ms 31.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_227 2.4207 ms 31.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
  triton_mm_231 2.4238 ms 31.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8
SingleProcess AUTOTUNE benchmarking takes 0.5007 seconds and 0.4694 seconds precompiling for 12 choices
Compiled module path: /tmp/torchinductor_root/5q/c5qxmlyigmnewtrf5utimz6bqw6gfw24ehsydclji4caoddgkz2b.py
>>time: 0.812ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.756ms
best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>

E0915 21:39:07.496000 11726 .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:2100] [0/0] Runtime error during autotuning: 
E0915 21:39:07.496000 11726 .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:2100] [0/0] self.size(0) needs to be greater than 16, but got 1. 
E0915 21:39:07.496000 11726 .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:2100] [0/0] Ignoring this choice.
AUTOTUNE int_mm(1x4096, 4096x4096)
  triton_mm_277 0.0369 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=256, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
  triton_mm_278 0.0369 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
  triton_mm_276 0.0379 ms 97.3% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_273 0.0399 ms 92.3% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
  triton_mm_274 0.0420 ms 87.8% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
  triton_mm_272 0.0481 ms 76.6% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
  triton_mm_270 0.0635 ms 58.1% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_269 0.0655 ms 56.3% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_268 0.1137 ms 32.4% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
  triton_mm_271 0.1137 ms 32.4% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
SingleProcess AUTOTUNE benchmarking takes 0.1958 seconds and 0.0002 seconds precompiling for 12 choices
E0915 21:39:09.384000 11726 .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:2100] [0/0] Runtime error during autotuning: 
E0915 21:39:09.384000 11726 .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:2100] [0/0] self.size(0) needs to be greater than 16, but got 1. 
E0915 21:39:09.384000 11726 .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:2100] [0/0] Ignoring this choice.
AUTOTUNE int_mm(1x14336, 14336x4096)
  triton_mm_311 0.0932 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
  triton_mm_310 0.0983 ms 94.8% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=256, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
  triton_mm_309 0.1126 ms 82.7% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_306 0.1208 ms 77.1% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
  triton_mm_307 0.1333 ms 69.9% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
  triton_mm_305 0.1628 ms 57.2% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
  triton_mm_303 0.2130 ms 43.8% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_302 0.2263 ms 41.2% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_301 0.3860 ms 24.1% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
  triton_mm_308 0.3912 ms 23.8% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8
SingleProcess AUTOTUNE benchmarking takes 0.3209 seconds and 0.0002 seconds precompiling for 12 choices
E0915 21:40:18.811000 11726 .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:2100] [0/0] Runtime error during autotuning: 
E0915 21:40:18.811000 11726 .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:2100] [0/0] self.size(0) needs to be greater than 16, but got 1. 
E0915 21:40:18.811000 11726 .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:2100] [0/0] Ignoring this choice.
AUTOTUNE int_mm(1x4096, 4096x4096)
  triton_mm_244 0.0952 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=256, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
  triton_mm_245 0.0952 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
  triton_mm_243 0.0962 ms 99.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_239 0.0973 ms 97.9% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
  triton_mm_240 0.0973 ms 97.9% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
  triton_mm_241 0.0983 ms 96.9% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
  triton_mm_237 0.1012 ms 94.1% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_236 0.1034 ms 92.1% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_235 0.1505 ms 63.3% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
  triton_mm_242 0.1515 ms 62.9% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8
SingleProcess AUTOTUNE benchmarking takes 0.3219 seconds and 0.0002 seconds precompiling for 12 choices
E0915 21:40:19.133000 11726 .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:2100] [0/0] Runtime error during autotuning: 
E0915 21:40:19.133000 11726 .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:2100] [0/0] self.size(0) needs to be greater than 16, but got 1. 
E0915 21:40:19.133000 11726 .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:2100] [0/0] Ignoring this choice.
AUTOTUNE int_mm(1x4096, 4096x1024)
  triton_mm_252 0.0943 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
  triton_mm_254 0.0952 ms 99.1% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_255 0.0952 ms 99.1% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=256, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
  triton_mm_256 0.0953 ms 99.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
  triton_mm_251 0.0954 ms 98.9% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
  triton_mm_247 0.0961 ms 98.1% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_248 0.0961 ms 98.1% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_250 0.0963 ms 98.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
  triton_mm_246 0.1044 ms 90.3% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
  triton_mm_249 0.1116 ms 84.5% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
SingleProcess AUTOTUNE benchmarking takes 0.3204 seconds and 0.0002 seconds precompiling for 12 choices
E0915 21:40:19.455000 11726 .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:2100] [0/0] Runtime error during autotuning: 
E0915 21:40:19.455000 11726 .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:2100] [0/0] self.size(0) needs to be greater than 16, but got 1. 
E0915 21:40:19.455000 11726 .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:2100] [0/0] Ignoring this choice.
AUTOTUNE int_mm(1x4096, 4096x14336)
  triton_mm_289 0.1300 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
  triton_mm_288 0.1311 ms 99.2% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=256, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
  triton_mm_287 0.1638 ms 79.4% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_283 0.2314 ms 56.2% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
  triton_mm_282 0.2417 ms 53.8% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
  triton_mm_281 0.2437 ms 53.4% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_280 0.2488 ms 52.3% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_284 0.2488 ms 52.3% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
  triton_mm_285 0.2529 ms 51.4% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
  triton_mm_279 0.3142 ms 41.4% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.3867 seconds and 0.0002 seconds precompiling for 12 choices
Compiled module path: /tmp/torchinductor_root/lf/clfse3bklrst5htfzu6q3g6nxyh26e4nrz6huprdtx46xipdsbrd.py
skipping cudagraphs due to mutated inputs (64 instances). Found from : 
   File "/app/low_bit_inference/model.py", line 446, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/app/low_bit_inference/model.py", line 372, in forward
    hidden_states = decoder_layer(
  File "/app/low_bit_inference/model.py", line 262, in forward
    hidden_states, _ = self.self_attn(
  File "/app/low_bit_inference/model.py", line 215, in forward
    key_states, value_states = past_key_values.update(key_states, value_states, self.layer_idx, cache_kwargs)
  File "/app/low_bit_inference/optims/cache_optim.py", line 197, in update
    keys, values = self.layers[layer_idx].update(key_states, value_states, cache_kwargs)
  File "/app/low_bit_inference/optims/cache_optim.py", line 134, in update
    self.keys[:, :, cache_position] = key_states

Generated tokens (last 5): ['.', ' Also', ',', ' make', ' sure'], len: 1009, time: 783.5975s
Profiling step_num: 0, curr action: ProfilerAction.NONE, or in reality NONE if tps_only is True.
Profiling iteration 1 out of total 10
Compiled module path: /tmp/torchinductor_root/lq/clqljcsyslsomuy74wmc4b6hpbvvrt7iphy6mjp633otc3am57bu.py
Compiled module path: /tmp/torchinductor_root/ja/cjazkfbcvjlv5g3vlycphnmaiu3f2icj5mgncnm3nmwxm2urttuw.py
skipping cudagraphs due to mutated inputs (64 instances). Found from : 
   File "/app/low_bit_inference/model.py", line 446, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/app/low_bit_inference/model.py", line 372, in forward
    hidden_states = decoder_layer(
  File "/app/low_bit_inference/model.py", line 262, in forward
    hidden_states, _ = self.self_attn(
  File "/app/low_bit_inference/model.py", line 215, in forward
    key_states, value_states = past_key_values.update(key_states, value_states, self.layer_idx, cache_kwargs)
  File "/app/low_bit_inference/optims/cache_optim.py", line 197, in update
    keys, values = self.layers[layer_idx].update(key_states, value_states, cache_kwargs)
  File "/app/low_bit_inference/optims/cache_optim.py", line 134, in update
    self.keys[:, :, cache_position] = key_states

Generated tokens (last 5): ['.', ' Also', ',', ' make', ' sure'], len: 1009, time: 185.785203125s
Profiling step_num: 1, curr action: ProfilerAction.NONE, or in reality NONE if tps_only is True.
Profiling iteration 2 out of total 10
Compiled module path: /tmp/torchinductor_root/4s/c4sf4milqbz7u56cpywrrd3ersef2vscehklkwxss3kigkviab5w.py
Compiled module path: /tmp/torchinductor_root/lv/clvpynaj4gjhv5pbzkmi3g3gousi5xolcebasswkmuqheraxkedq.py
skipping cudagraphs due to mutated inputs (64 instances). Found from : 
   File "/app/low_bit_inference/model.py", line 446, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/app/low_bit_inference/model.py", line 372, in forward
    hidden_states = decoder_layer(
  File "/app/low_bit_inference/model.py", line 262, in forward
    hidden_states, _ = self.self_attn(
  File "/app/low_bit_inference/model.py", line 215, in forward
    key_states, value_states = past_key_values.update(key_states, value_states, self.layer_idx, cache_kwargs)
  File "/app/low_bit_inference/optims/cache_optim.py", line 197, in update
    keys, values = self.layers[layer_idx].update(key_states, value_states, cache_kwargs)
  File "/app/low_bit_inference/optims/cache_optim.py", line 134, in update
    self.keys[:, :, cache_position] = key_states

Generated tokens (last 5): ['.', ' Also', ',', ' make', ' sure'], len: 1009, time: 185.1201875s
Profiling step_num: 2, curr action: ProfilerAction.WARMUP, or in reality NONE if tps_only is True.
Profiling iteration 3 out of total 10
Compiled module path: /tmp/torchinductor_root/g5/cg5w4d4bkt4oomlpy7cbijehlqhks6y56j5abzbvvdctwbm35j7d.py
Compiled module path: /tmp/torchinductor_root/ic/cicmlph6tj5xlqgnlp4ihrkivzr4b4hr4uz5l34rdpnm4vyeilrm.py
skipping cudagraphs due to mutated inputs (64 instances). Found from : 
   File "/app/low_bit_inference/model.py", line 446, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/app/low_bit_inference/model.py", line 372, in forward
    hidden_states = decoder_layer(
  File "/app/low_bit_inference/model.py", line 262, in forward
    hidden_states, _ = self.self_attn(
  File "/app/low_bit_inference/model.py", line 215, in forward
    key_states, value_states = past_key_values.update(key_states, value_states, self.layer_idx, cache_kwargs)
  File "/app/low_bit_inference/optims/cache_optim.py", line 197, in update
    keys, values = self.layers[layer_idx].update(key_states, value_states, cache_kwargs)
  File "/app/low_bit_inference/optims/cache_optim.py", line 134, in update
    self.keys[:, :, cache_position] = key_states

Generated tokens (last 5): ['.', ' Also', ',', ' make', ' sure'], len: 1009, time: 185.55871875s
Profiling step_num: 3, curr action: ProfilerAction.WARMUP, or in reality NONE if tps_only is True.
Profiling iteration 4 out of total 10
Compiled module path: /tmp/torchinductor_root/4k/c4kgbliihqxqclvbx5eyktnk5pyi7cqr6lbi7abht4nva4acuokf.py
^CTraceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/app/low_bit_inference/torchinductor_autoquant.py", line 60, in <module>
    profile_model(model, tokenizer, prompt, config, past_key_values, cache_init)
  File "/app/low_bit_inference/utils/profile_utils.py", line 77, in profile_model
    generated_token_ids = model.generate(
                          ^^^^^^^^^^^^^^^
  File "/app/low_bit_inference/optims/generation_optim.py", line 257, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/app/low_bit_inference/optims/generation_optim.py", line 305, in _sample
    outputs = self.compiled_forward_decode(**model_inputs, return_dict=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 655, in _fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py", line 1432, in __call__
    return self._torchdynamo_orig_callable(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py", line 598, in __call__
    return _compile(
           ^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py", line 1059, in _compile
    guarded_code = compile_inner(code, one_graph, hooks, transform)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_utils_internal.py", line 97, in wrapper_function
    return function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py", line 761, in compile_inner
    return _compile_inner(code, one_graph, hooks, transform)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py", line 797, in _compile_inner
    out_code = transform_code_object(code, transform)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/bytecode_transformation.py", line 1422, in transform_code_object
    transformations(instructions, code_options)
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py", line 257, in _fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py", line 715, in transform
    tracer.run()
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 3498, in run
    super().run()
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 1337, in run
    while self.step():
          ^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 1246, in step
    self.dispatch_table[inst.opcode](self, inst)
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 819, in wrapper
    return inner_fn(self, inst)
           ^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 2264, in CALL_FUNCTION_EX
    self.call_function(fn, argsvars.items, kwargsvars)
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 1170, in call_function
    self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/lazy.py", line 201, in realize_and_forward
    return getattr(self.realize(), name)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/nn_module.py", line 952, in call_function
    return variables.UserFunctionVariable(fn, source=source).call_function(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py", line 414, in call_function
    return super().call_function(tx, args, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py", line 184, in call_function
    return tx.inline_user_function_return(self, [*self.self_args(), *args], kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 1187, in inline_user_function_return
    return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 3724, in inline_call
    return tracer.inline_call_()
           ^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 3903, in inline_call_
    self.run()
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 1337, in run
    while self.step():
          ^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 1246, in step
    self.dispatch_table[inst.opcode](self, inst)
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 819, in wrapper
    return inner_fn(self, inst)
           ^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 2264, in CALL_FUNCTION_EX
    self.call_function(fn, argsvars.items, kwargsvars)
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 1170, in call_function
    self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/nn_module.py", line 952, in call_function
    return variables.UserFunctionVariable(fn, source=source).call_function(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py", line 414, in call_function
    return super().call_function(tx, args, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py", line 184, in call_function
    return tx.inline_user_function_return(self, [*self.self_args(), *args], kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 1187, in inline_user_function_return
    return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 3724, in inline_call
    return tracer.inline_call_()
           ^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 3903, in inline_call_
    self.run()
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 1337, in run
    while self.step():
          ^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 1246, in step
    self.dispatch_table[inst.opcode](self, inst)
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 819, in wrapper
    return inner_fn(self, inst)
           ^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 2264, in CALL_FUNCTION_EX
    self.call_function(fn, argsvars.items, kwargsvars)
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 1170, in call_function
    self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/lazy.py", line 201, in realize_and_forward
    return getattr(self.realize(), name)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/nn_module.py", line 952, in call_function
    return variables.UserFunctionVariable(fn, source=source).call_function(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py", line 414, in call_function
    return super().call_function(tx, args, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py", line 184, in call_function
    return tx.inline_user_function_return(self, [*self.self_args(), *args], kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 1187, in inline_user_function_return
    return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 3724, in inline_call
    return tracer.inline_call_()
           ^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 3903, in inline_call_
    self.run()
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 1337, in run
    while self.step():
          ^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 1246, in step
    self.dispatch_table[inst.opcode](self, inst)
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 819, in wrapper
    return inner_fn(self, inst)
           ^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 2931, in CALL
    self._call(inst)
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 2925, in _call
    self.call_function(fn, args, kwargs)
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 1170, in call_function
    self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/lazy.py", line 201, in realize_and_forward
    return getattr(self.realize(), name)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/nn_module.py", line 952, in call_function
    return variables.UserFunctionVariable(fn, source=source).call_function(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py", line 414, in call_function
    return super().call_function(tx, args, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py", line 184, in call_function
    return tx.inline_user_function_return(self, [*self.self_args(), *args], kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 1187, in inline_user_function_return
    return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 3724, in inline_call
    return tracer.inline_call_()
           ^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 3903, in inline_call_
    self.run()
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 1337, in run
    while self.step():
          ^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 1246, in step
    self.dispatch_table[inst.opcode](self, inst)
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 819, in wrapper
    return inner_fn(self, inst)
           ^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 2931, in CALL
    self._call(inst)
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 2925, in _call
    self.call_function(fn, args, kwargs)
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py", line 1170, in call_function
    self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py", line 1181, in call_function
    tensor_variable = wrap_fx_proxy(
                      ^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py", line 2302, in wrap_fx_proxy
    return wrap_fx_proxy_cls(target_cls=TensorVariable, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py", line 2368, in wrap_fx_proxy_cls
    return _wrap_fx_proxy(
           ^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py", line 2464, in _wrap_fx_proxy
    example_value = get_fake_value(proxy.node, tx, allow_non_graph_fake=True)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py", line 3127, in get_fake_value
    ret_val = wrap_fake_exception(
              ^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py", line 2641, in wrap_fake_exception
    return fn()
           ^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py", line 3128, in <lambda>
    lambda: run_node(tx.output, node, args, kwargs, nnmodule)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py", line 3284, in run_node
    return node.target(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torchao/utils.py", line 430, in _dispatch__torch_function__
    return cls._ATEN_OP_OR_TORCH_FN_TABLE[func](func, types, args, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torchao/utils.py", line 409, in wrapper
    return func(f, types, args, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torchao/quantization/linear_activation_quantized_tensor.py", line 145, in _
    return weight_tensor._quantized_linear_op(input_tensor, weight_tensor, bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torchao/quantization/linear_activation_quantized_tensor.py", line 91, in _quantized_linear_op
    return torch.nn.functional.linear(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torchao/utils.py", line 430, in _dispatch__torch_function__
    return cls._ATEN_OP_OR_TORCH_FN_TABLE[func](func, types, args, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torchao/utils.py", line 409, in wrapper
    return func(f, types, args, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torchao/dtypes/affine_quantized_tensor_ops.py", line 282, in _
    return weight_tensor._quantized_linear_op(input_tensor, weight_tensor, bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torchao/dtypes/affine_quantized_tensor_ops.py", line 176, in _quantized_linear_op
    return impl(input_tensor, weight_tensor, bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torchao/dtypes/uintx/plain_layout.py", line 302, in _linear_int8_act_int8_weight_impl
    tmp, w_vals_int8_t, x_scales.reshape(-1, 1).to(intermediate_dtype)
                        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/utils/_stats.py", line 27, in wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py", line 1282, in __torch_dispatch__
    return self.dispatch(func, types, args, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py", line 1823, in dispatch
    return self._cached_dispatch_impl(func, types, args, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py", line 1393, in _cached_dispatch_impl
    output = self._dispatch_impl(func, types, args, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py", line 2152, in _dispatch_impl
    args, kwargs = pytree.tree_unflatten(flat_args, args_spec)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/torch/utils/_pytree.py", line 1059, in tree_unflatten
    def tree_unflatten(leaves: Iterable[Any], treespec: TreeSpec) -> PyTree:
    
KeyboardInterrupt
^C^CException ignored in atexit callback: <function shutdown_compile_workers at 0x7f0d5dc44720>
Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/torch/_inductor/async_compile.py", line 113, in shutdown_compile_workers
    pool.shutdown()
  File "/app/.venv/lib/python3.12/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 239, in shutdown
    self.process.wait(300)
  File "/root/.local/share/uv/python/cpython-3.12.11-linux-x86_64-gnu/lib/python3.12/subprocess.py", line 1277, in wait
    self._wait(timeout=sigint_timeout)
  File "/root/.local/share/uv/python/cpython-3.12.11-linux-x86_64-gnu/lib/python3.12/subprocess.py", line 2047, in _wait
    time.sleep(delay)
KeyboardInterrupt: 
^CException ignored in atexit callback: <bound method finalize._exitfunc of <class 'weakref.finalize'>>
Traceback (most recent call last):
  File "/root/.local/share/uv/python/cpython-3.12.11-linux-x86_64-gnu/lib/python3.12/weakref.py", line 666, in _exitfunc
    f()
KeyboardInterrupt: 
^C^C^C^C^C^C^C^C^C^C^C^C^C
(low-bit-inference) root@c61c0f80798d:/app# 
(low-bit-inference) root@c61c0f80798d:/app# 
(low-bit-inference) root@c61c0f80798d:/app# git status
On branch main
Your branch is up to date with 'origin/main'.

nothing to commit, working tree clean
(low-bit-inference) root@c61c0f80798d:/app# git add .
(low-bit-inference) root@c61c0f80798d:/app# git status
On branch main
Your branch is up to date with 'origin/main'.

nothing to commit, working tree clean
(low-bit-inference) root@c61c0f80798d:/app# 
(low-bit-inference) root@c61c0f80798d:/app# 
(low-bit-inference) root@c61c0f80798d:/app# 
(low-bit-inference) root@c61c0f80798d:/app# git status
On branch main
Your branch is up to date with 'origin/main'.

Untracked files:
  (use "git add <file>..." to include in what will be committed)
        wip.txt

nothing added to commit but untracked files present (use "git add" to track)
(low-bit-inference) root@c61c0f80798d:/app# 